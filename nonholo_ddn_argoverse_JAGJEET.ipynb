{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.append(\"/Users/shashanks./Downloads/Installations/ddn/\")\n",
    "sys.path.append(\"./ddn/\")\n",
    "sys.path.append(\"./\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bernstein import bernstein_coeff_order10_new\n",
    "from ddn.pytorch.node import AbstractDeclarativeNode\n",
    "\n",
    "from utils.viz_helpers import plot_traj\n",
    "from utils.metrics import get_ade, get_fde\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(gt_x, gt_y, w = 7):\n",
    "    # denoising\n",
    "    w = w\n",
    "    gt_x_t = []\n",
    "    gt_y_t = []\n",
    "    for iq in range(len(gt_x)):\n",
    "        if iq >= w and iq + w <= len(gt_x):\n",
    "            gt_x_t.append(np.average(gt_x[iq: iq + w]))\n",
    "            gt_y_t.append(np.average(gt_y[iq: iq + w]))\n",
    "        elif iq < w:\n",
    "            okx = np.average(gt_x[w: w + w])\n",
    "            gt_x_t.append(gt_x[0] + (okx - gt_x[0]) * (iq) / w)\n",
    "            oky = np.average(gt_y[w: w + w])\n",
    "            gt_y_t.append(gt_y[0] + (oky - gt_y[0]) * (iq) / w)\n",
    "        else:\n",
    "            okx = np.average(gt_x[len(gt_x) - w:len(gt_x) - w  + w])\n",
    "            oky = np.average(gt_y[len(gt_x) - w: len(gt_x) - w + w])\n",
    "            gt_x_t.append(okx + (gt_x[-1] - okx) * (w - (len(gt_x) - iq)) / w)\n",
    "            gt_y_t.append(oky + (gt_y[-1] - oky) * (w - (len(gt_y) - iq)) / w)                   \n",
    "\n",
    "    gt_x = gt_x_t\n",
    "    gt_y = gt_y_t\n",
    "    return gt_x, gt_y\n",
    "\n",
    "def rotate(gt_x, gt_y,theta):\n",
    "    gt_x_x = [ (gt_x[k] * np.cos(theta) - gt_y[k] * np.sin(theta))  for k in range(len(gt_x))]\n",
    "    gt_y_y = [ (gt_x[k] * np.sin(theta) + gt_y[k] * np.cos(theta))  for k in range(len(gt_x))]\n",
    "    gt_x = gt_x_x\n",
    "    gt_y = gt_y_y\n",
    "    return gt_x, gt_y\n",
    "\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    def __init__(self, data_path, t_obs=16, dt=0.125,centerline_dir=None, include_centerline = False):\n",
    "        self.data = np.load(data_path)\n",
    "        self.data_path = data_path\n",
    "        self.t_obs = t_obs\n",
    "        self.dt = dt\n",
    "        self.include_centerline = include_centerline\n",
    "        self.centerline_dir = centerline_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dt = self.dt\n",
    "        traj = self.data[idx]\n",
    "        x_traj = traj[:, 0]\n",
    "        y_traj = traj[:, 1]\n",
    "        \n",
    "        x_traj -= x_traj[0]\n",
    "        y_traj -= y_traj[0]\n",
    "        \n",
    "        gt_x = x_traj\n",
    "        gt_y = y_traj\n",
    "        \n",
    "        ind = 1\n",
    "        \n",
    "        if idx == ind:\n",
    "            plt.axis('equal')\n",
    "#             plt.scatter(gt_x, gt_y, color='blue', label='noisy')\n",
    "        \n",
    "        gt_x, gt_y = denoise(gt_x, gt_y)\n",
    "        v_x = [ (gt_x[k + 1] - gt_x[k])/dt  for k in range(len(gt_x) - 1)]\n",
    "        v_y = [ (gt_y[k + 1] - gt_y[k])/dt  for k in range(len(gt_y) - 1)]\n",
    "        psi = [ np.arctan2(v_y[k], v_x[k]) for k in range(len(v_x))]  \n",
    "        \n",
    "        if idx == ind:\n",
    "            plt.axis('equal')\n",
    "#             plt.scatter(gt_x, gt_y, color='purple',label='before')\n",
    "        \n",
    "        # till here, gt-> (50, 1), v -> (49, 1), psi -> (31, 1)\n",
    "        \n",
    "        # obtain this -psi\n",
    "        theta = -psi[self.t_obs - 1]\n",
    "        \n",
    "        # rotate by theta\n",
    "        gt_x, gt_y = rotate(gt_x, gt_y, theta)\n",
    "#         gt_x_x = [ (gt_x[k] * np.cos(theta) - gt_y[k] * np.sin(theta))  for k in range(len(gt_x))]\n",
    "#         gt_y_y = [ (gt_x[k] * np.sin(theta) + gt_y[k] * np.cos(theta))  for k in range(len(gt_x))]\n",
    "#         gt_x = gt_x_x\n",
    "#         gt_y = gt_y_y\n",
    "        if idx == ind:\n",
    "            plt.axis('equal')\n",
    "#             plt.scatter(gt_x, gt_y, color='yellow') \n",
    "        v_x = [ (gt_x[k + 1] - gt_x[k])/dt  for k in range(len(gt_x) - 1)]\n",
    "        v_y = [ (gt_y[k + 1] - gt_y[k])/dt  for k in range(len(gt_y) - 1)]\n",
    "        psi = [ np.arctan2(v_y[k], v_x[k]) for k in range(len(v_x))]\n",
    "        psidot = [ (psi[k + 1] - psi[k])/dt for k in range(len(psi) - 1) ]\n",
    "        psi_traj = [i.item() for i in psi]\n",
    "        psidot_traj = [i.item() for i in psidot]\n",
    "    \n",
    "        \n",
    "        x_traj = gt_x\n",
    "        y_traj = gt_y\n",
    "\n",
    "        x_inp = x_traj[:self.t_obs]\n",
    "        y_inp = y_traj[:self.t_obs]\n",
    "        x_fut = x_traj[self.t_obs:]\n",
    "        y_fut = y_traj[self.t_obs:]\n",
    "#         psi_fut = psi_traj[self.t_obs:]\n",
    "#         psidot_fut = psidot_traj[self.t_obs:]\n",
    "\n",
    "        # till here, gt-> (32, 1), v -> (31, 1), psi -> (31, 1), psidot -> (30, 1)\n",
    "        psi_fut = psi_traj[self.t_obs - 1:]\n",
    "        psidot_fut = psi_traj[self.t_obs - 2:]\n",
    "        \n",
    "        vx_traj = v_x\n",
    "        vy_traj = v_y\n",
    "        \n",
    "        vx_beg = vx_traj[self.t_obs]\n",
    "        vy_beg = vy_traj[self.t_obs]\n",
    "        \n",
    "        vx_beg_prev = vx_traj[self.t_obs - 1]\n",
    "        vy_beg_prev = vy_traj[self.t_obs - 1]\n",
    "        \n",
    "        ax_beg = (vx_beg - vx_beg_prev) / self.dt\n",
    "        ay_beg = (vy_beg - vy_beg_prev) / self.dt\n",
    "\n",
    "        vx_fin = v_x[-1]\n",
    "        vy_fin = v_y[-1]\n",
    "        \n",
    "        vx_fin_prev = v_x[-2]\n",
    "        vy_fin_prev = v_y[-2]\n",
    "\n",
    "        ax_fin = (vx_fin - vx_fin_prev) / self.dt\n",
    "        ay_fin = (vy_fin - vy_fin_prev) / self.dt\n",
    "\n",
    "        x_fut = x_traj[self.t_obs:]\n",
    "        y_fut = y_traj[self.t_obs:]\n",
    "        \n",
    "#         traj_inp = np.dstack((x_inp, y_inp)).flatten()  \n",
    "        traj_inp = np.vstack((x_inp, y_inp))\n",
    "        traj_inp = np.swapaxes(traj_inp, 0, 1)\n",
    "        \n",
    "        if self.include_centerline:\n",
    "            cs = np.load(self.centerline_dir)[idx]\n",
    "            data = np.load(self.data_path)\n",
    "\n",
    "            c_x = cs[:, 0]            \n",
    "            c_y = cs[:, 1]\n",
    "            c_x -= data[idx][0,0]\n",
    "            c_y -= data[idx][0,1]\n",
    "            c_x, c_y = denoise(c_x, c_y)\n",
    "#             if idx == ind:\n",
    "#                 plt.plot(c_x, c_y, color='black', label='grey')\n",
    "            \n",
    "            # rotate by theta\n",
    "            c_x, c_y = rotate(c_x, c_y, theta)\n",
    "            c_x -= c_x[0]\n",
    "            c_y -= c_y[0]\n",
    "            c_x += x_inp[-1]\n",
    "            c_y += y_inp[-1]\n",
    "        \n",
    "#             c_y += y_inp[-1] + 2\n",
    "            c_inp = np.dstack((c_x, c_y)).flatten()\n",
    "            traj_inp = np.hstack((traj_inp, c_inp))\n",
    "            \n",
    "        vx_fut = vx_traj[self.t_obs:]\n",
    "        vy_fut = vy_traj[self.t_obs:]\n",
    "#         traj_out = np.vstack((x_fut, y_fut))#.flatten()\n",
    "#         traj_out = np.swapaxes(traj_out, 0, 1)\n",
    "        traj_out = np.hstack((x_fut, y_fut)).flatten()      \n",
    "#         traj_out = np.hstack((x_fut, y_fut)).flatten()\n",
    "\n",
    "        fixed_params = np.array([x_fut[0], y_fut[0], 0, psi_fut[0], psidot_fut[0]])\n",
    "        var_inp = np.array([x_inp[-1], y_inp[-1], psi_fut[-1]])\n",
    "\n",
    "        return torch.tensor(traj_inp), torch.tensor(traj_out), torch.tensor(fixed_params), torch.tensor(var_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPTNode(AbstractDeclarativeNode):\n",
    "    def __init__(self, rho_eq=1.0, rho_goal=1.0, rho_nonhol=1.0, rho_psi=1.0, maxiter=5000, weight_smoothness=1.0, weight_smoothness_psi=1.0, t_fin=2.0, num=30):\n",
    "        super().__init__()\n",
    "        self.rho_eq = rho_eq\n",
    "        self.rho_goal = rho_goal\n",
    "        self.rho_nonhol = rho_nonhol\n",
    "        self.rho_psi = rho_psi\n",
    "        self.maxiter = maxiter\n",
    "        self.weight_smoothness = weight_smoothness\n",
    "        self.weight_smoothness_psi = weight_smoothness_psi\n",
    "\n",
    "        self.t_fin = t_fin\n",
    "        self.num = num\n",
    "        self.t = self.t_fin / self.num\n",
    "\n",
    "        #self.num_batch = 10\n",
    "        \n",
    "        tot_time = np.linspace(0.0, self.t_fin, self.num)\n",
    "        tot_time_copy = tot_time.reshape(self.num, 1)\n",
    "        self.P, self.Pdot, self.Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "        self.nvar = np.shape(self.P)[1]\n",
    "        \n",
    "        self.cost_smoothness = self.weight_smoothness * np.dot(self.Pddot.T, self.Pddot)\n",
    "        self.cost_smoothness_psi = self.weight_smoothness_psi * np.dot(self.Pddot.T, self.Pddot)\n",
    "        self.lincost_smoothness_psi = np.zeros(self.nvar)\n",
    "\n",
    "        self.A_eq = np.vstack((self.P[0], self.P[-1]))\n",
    "        self.A_eq_psi = np.vstack((self.P[0], self.Pdot[0], self.P[-1]))\n",
    "        \n",
    "        self.P = torch.tensor(self.P, dtype=torch.double).to(device)\n",
    "        self.Pdot = torch.tensor(self.Pdot, dtype=torch.double).to(device)\n",
    "        self.Pddot = torch.tensor(self.Pddot, dtype=torch.double).to(device)\n",
    "        self.A_eq = torch.tensor(self.A_eq, dtype=torch.double).to(device)        \n",
    "        self.A_eq_psi = torch.tensor(self.A_eq_psi, dtype=torch.double).to(device)\n",
    "        self.cost_smoothness = torch.tensor(self.cost_smoothness, dtype=torch.double).to(device)\n",
    "        self.cost_smoothness_psi = torch.tensor(self.cost_smoothness_psi, dtype=torch.double).to(device)\n",
    "        self.lincost_smoothness_psi = torch.tensor(self.lincost_smoothness_psi, dtype=torch.double).to(device)\n",
    "        \n",
    "        self.A_nonhol = self.Pdot\n",
    "        self.A_psi = self.P\n",
    "        \n",
    "        self.lamda_x = None\n",
    "        self.lamda_y = None\n",
    "        self.lamda_psi = None\n",
    "        \n",
    "    def compute_x(self, v, psi, b_eq_x, b_eq_y):\n",
    "        b_nonhol_x = v * torch.cos(psi)\n",
    "        b_nonhol_y = v * torch.sin(psi)\n",
    "    \n",
    "        cost = self.cost_smoothness + self.rho_nonhol * torch.matmul(self.A_nonhol.T, self.A_nonhol) + self.rho_eq * torch.matmul(self.A_eq.T, self.A_eq)\n",
    "        lincost_x = -self.lamda_x - self.rho_nonhol * torch.matmul(self.A_nonhol.T, b_nonhol_x.T).T - self.rho_eq * torch.matmul(self.A_eq.T, b_eq_x.T).T\n",
    "        lincost_y = -self.lamda_y - self.rho_nonhol * torch.matmul(self.A_nonhol.T, b_nonhol_y.T).T - self.rho_eq * torch.matmul(self.A_eq.T, b_eq_y.T).T\n",
    "\n",
    "        cost_inv = torch.linalg.inv(cost)\n",
    "\n",
    "        sol_x = torch.matmul(-cost_inv, lincost_x.T).T\n",
    "        sol_y = torch.matmul(-cost_inv, lincost_y.T).T\n",
    "\n",
    "        x = torch.matmul(self.P, sol_x.T).T\n",
    "        xdot = torch.matmul(self.Pdot, sol_x.T).T\n",
    "\n",
    "        y = torch.matmul(self.P, sol_y.T).T\n",
    "        ydot = torch.matmul(self.Pdot, sol_y.T).T\n",
    "         \n",
    "        return sol_x, sol_y, x, xdot, y, ydot\n",
    "    \n",
    "    def compute_psi(self, psi, lamda_psi, psi_temp, b_eq_psi):\n",
    "        cost = self.cost_smoothness_psi + self.rho_psi * torch.matmul(self.A_psi.T, self.A_psi) + self.rho_eq * torch.matmul(self.A_eq_psi.T, self.A_eq_psi)\n",
    "        lincost_psi = -self.lamda_psi - self.rho_psi * torch.matmul(self.A_psi.T, psi_temp.T).T - self.rho_eq * torch.matmul(self.A_eq_psi.T, b_eq_psi.T).T\n",
    "\n",
    "        cost_inv = torch.linalg.inv(cost)\n",
    "\n",
    "        sol_psi = torch.matmul(-cost_inv, lincost_psi.T).T\n",
    "\n",
    "        psi = torch.matmul(self.P, sol_psi.T).T\n",
    "\n",
    "        res_psi = torch.matmul(self.A_psi, sol_psi.T).T - psi_temp\n",
    "        res_eq_psi = torch.matmul(self.A_eq_psi, sol_psi.T).T - b_eq_psi\n",
    "\n",
    "        self.lamda_psi = self.lamda_psi - self.rho_psi * torch.matmul(self.A_psi.T, res_psi.T).T - self.rho_eq * torch.matmul(self.A_eq_psi.T, res_eq_psi.T).T\n",
    "\n",
    "        return sol_psi, np.linalg.norm(res_psi), np.linalg.norm(res_eq_psi), psi\n",
    "\n",
    "    \n",
    "    def solve(self, fixed_params, variable_params):\n",
    "        batch_size, _ = fixed_params.size()\n",
    "        x_init, y_init, v_init, psi_init, psidot_init = torch.chunk(fixed_params, 5, dim=1)\n",
    "        x_fin, y_fin, psi_fin = torch.chunk(variable_params, 3, dim=1)\n",
    "        \n",
    "        b_eq_x = torch.cat((x_init, x_fin), dim=1)\n",
    "        b_eq_y = torch.cat((y_init, y_fin), dim=1)\n",
    "        b_eq_psi = torch.cat((psi_init, psidot_init, psi_fin), dim=1)\n",
    "        \n",
    "        v = torch.ones(batch_size, self.num, dtype=torch.double).to(device) * v_init\n",
    "        psi = torch.ones(batch_size, self.num, dtype=torch.double).to(device) * psi_init\n",
    "        xdot = v * torch.cos(psi)\n",
    "        ydot = v * torch.sin(psi)\n",
    "        \n",
    "        self.lamda_x = torch.zeros(batch_size, self.nvar, dtype=torch.double).to(device)\n",
    "        self.lamda_y = torch.zeros(batch_size, self.nvar, dtype=torch.double).to(device)\n",
    "        self.lamda_psi = torch.zeros(batch_size, self.nvar, dtype=torch.double).to(device)\n",
    "        \n",
    "        res_psi_arr = []\n",
    "        res_eq_psi_arr = []\n",
    "        res_eq_arr = []\n",
    "        res_nonhol_arr = []\n",
    "        for i in range(0, self.maxiter):\n",
    "            psi_temp = torch.atan2(ydot, xdot)\n",
    "            c_psi, res_psi, res_eq_psi, psi = self.compute_psi(psi, self.lamda_psi, psi_temp, b_eq_psi)\n",
    "            c_x, c_y, x, xdot, y, ydot = self.compute_x(v, psi, b_eq_x, b_eq_y)\n",
    "            \n",
    "            res_eq_psi_arr.append(res_eq_psi)\n",
    "            res_psi_arr.append(res_psi)\n",
    "            v = torch.sqrt(xdot ** 2 + ydot ** 2)\n",
    "            #v[:, 0] = v_init[:, 0]\n",
    "\n",
    "            res_eq_x = torch.matmul(self.A_eq, c_x.T).T - b_eq_x\n",
    "            res_nonhol_x = xdot - v * torch.cos(psi)\n",
    "\n",
    "            res_eq_y = torch.matmul(self.A_eq, c_y.T).T - b_eq_y\n",
    "            res_nonhol_y = ydot - v * torch.sin(psi)\n",
    "\n",
    "            res_eq_arr.append(np.linalg.norm(np.sqrt(res_eq_x**2 + res_eq_y**2)))\n",
    "            res_nonhol_arr.append(np.linalg.norm(np.sqrt(res_nonhol_x**2 + res_nonhol_y**2)))\n",
    "            \n",
    "            self.lamda_x = self.lamda_x - self.rho_eq * torch.matmul(self.A_eq.T, res_eq_x.T).T - self.rho_nonhol * torch.matmul(self.A_nonhol.T, res_nonhol_x.T).T\n",
    "            self.lamda_y = self.lamda_y - self.rho_eq * torch.matmul(self.A_eq.T, res_eq_y.T).T - self.rho_nonhol * torch.matmul(self.A_nonhol.T, res_nonhol_y.T).T\n",
    "        \n",
    "        primal_sol = torch.hstack((c_x, c_y, c_psi, v))\n",
    "        return primal_sol, None\n",
    "    \n",
    "    def objective(self, fixed_params, variable_params, y):\n",
    "        c_x = y[:, :self.nvar]\n",
    "        c_y = y[:, self.nvar:2*self.nvar]\n",
    "        c_psi = y[:, 2*self.nvar:3*self.nvar]\n",
    "        v = y[:, 3*self.nvar:]\n",
    "        \n",
    "        x_init, y_init, v_init, psi_init, psidot_init = torch.chunk(fixed_params, 5, dim=1)\n",
    "        x_fin, y_fin, psi_fin = torch.chunk(variable_params, 3, dim=1)\n",
    "        \n",
    "        x = torch.matmul(self.P, c_x.T).T\n",
    "        y = torch.matmul(self.P, c_y.T).T\n",
    "        psi = torch.matmul(self.P, c_psi.T).T\n",
    "        xdot = torch.matmul(self.Pdot, c_x.T).T\n",
    "        ydot = torch.matmul(self.Pdot, c_y.T).T\n",
    "        psidot = torch.matmul(self.Pdot, c_psi.T).T\n",
    "        xddot = torch.matmul(self.Pddot, c_x.T).T\n",
    "        yddot = torch.matmul(self.Pddot, c_y.T).T\n",
    "        psiddot = torch.matmul(self.Pddot, c_psi.T).T\n",
    "        \n",
    "        cost_nonhol = 0.5*self.rho_nonhol*torch.sum((xdot - v*torch.cos(psi)) ** 2, 1) + 0.5*self.rho_nonhol*torch.sum((ydot - v*torch.sin(psi)) ** 2, 1)\n",
    "        cost_pos = 0.5*self.rho_eq*(torch.sum((x[:, -1] - x_fin) ** 2, 1) + torch.sum((y[:, -1] - y_fin) ** 2, 1) + torch.sum((x[:, 0] - x_init) ** 2, 1) + torch.sum((y[:, 0] - y_init) ** 2, 1))\n",
    "        cost_psi = 0.5*self.rho_eq*(torch.sum((psi[:, -1] - psi_fin) ** 2, 1) + torch.sum((psi[:, 0] - psi_init) ** 2, 1)\n",
    "                                    + torch.sum((psidot[:, 0] - psidot_init) ** 2, 1))\n",
    "        #cost_v = 0.5*self.rho_eq*torch.sum((v[:, 0] - v_init) ** 2, 1)\n",
    "        cost_cancel = torch.diagonal(torch.matmul(-self.lamda_x, c_x.T) + torch.matmul(-self.lamda_y, c_y.T) + torch.matmul(-self.lamda_psi, c_psi.T))\n",
    "        \n",
    "        cost_smoothness = 0.5*self.weight_smoothness*(torch.sum(xddot**2, 1) + torch.sum(yddot**2, 1)) + 0.5*self.weight_smoothness_psi*torch.sum(psiddot**2, 1)\n",
    "        return cost_nonhol + cost_pos + cost_psi + cost_smoothness + cost_cancel #+ cost_v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeclarativeFunction(torch.autograd.Function):\n",
    "    \"\"\"Generic declarative autograd function.\n",
    "    Defines the forward and backward functions. Saves all inputs and outputs,\n",
    "    which may be memory-inefficient for the specific problem.\n",
    "    \n",
    "    Assumptions:\n",
    "    * All inputs are PyTorch tensors\n",
    "    * All inputs have a single batch dimension (b, ...)\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, problem, *inputs):\n",
    "        output, solve_ctx = torch.no_grad()(problem.solve)(*inputs)\n",
    "        ctx.save_for_backward(output, *inputs)\n",
    "        ctx.problem = problem\n",
    "        ctx.solve_ctx = solve_ctx\n",
    "        return output.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output, *inputs = ctx.saved_tensors\n",
    "        problem = ctx.problem\n",
    "        solve_ctx = ctx.solve_ctx\n",
    "        output.requires_grad = True\n",
    "        inputs = tuple(inputs)\n",
    "        grad_inputs = problem.gradient(*inputs, y=output, v=grad_output,\n",
    "            ctx=solve_ctx)\n",
    "        return (None, *grad_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeclarativeLayer(torch.nn.Module):\n",
    "    \"\"\"Generic declarative layer.\n",
    "    \n",
    "    Assumptions:\n",
    "    * All inputs are PyTorch tensors\n",
    "    * All inputs have a single batch dimension (b, ...)\n",
    "    Usage:\n",
    "        problem = <derived class of *DeclarativeNode>\n",
    "        declarative_layer = DeclarativeLayer(problem)\n",
    "        y = declarative_layer(x1, x2, ...)\n",
    "    \"\"\"\n",
    "    def __init__(self, problem):\n",
    "        super(DeclarativeLayer, self).__init__()\n",
    "        self.problem = problem\n",
    "        \n",
    "    def forward(self, *inputs):\n",
    "        return DeclarativeFunction.apply(self.problem, *inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajNetLSTMSimple(nn.Module):\n",
    "    def __init__(self, opt_layer, P, Pdot, input_size=2, hidden_size=16, embedding_size = 128, output_size=2, nvar=11, t_obs=8, num_layers = 1):\n",
    "        super(TrajNetLSTMSimple, self).__init__()\n",
    "        self.nvar = nvar\n",
    "        self.t_obs = t_obs\n",
    "        self.P = torch.tensor(P, dtype=torch.double).to(device)\n",
    "        self.Pdot = torch.tensor(Pdot, dtype=torch.double).to(device)        \n",
    "        self.opt_layer = opt_layer\n",
    "        self.linear1 = nn.Linear(input_size, embedding_size)\n",
    "#         self.linear2 = nn.Linear(embedding_size, output_size)\n",
    "        self.linear2 = nn.Linear(output_size, embedding_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "        self.lstm1 = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.lstm2 = nn.LSTMCell(embedding_size, hidden_size)        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dtype=torch.float64\n",
    "        self.mask = torch.tensor([[0.0, 0.0, 1.0]], dtype=torch.double).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, fixed_params, var_inp):\n",
    "        batch_size, _, _ = x.size()\n",
    "        out = x\n",
    "        encoder_hidden = (torch.zeros(batch_size, self.hidden_size, dtype=self.dtype), torch.zeros(batch_size, self.hidden_size, dtype=self.dtype))\n",
    "#         hidden = self.lstm1(embedded, hidden)\n",
    "        \n",
    "        for i in range(20):\n",
    "            encoder_input = x[:, i, :]\n",
    "            embedded = self.activation(self.linear1(encoder_input))\n",
    "            encoder_hidden = self.lstm1(embedded, encoder_hidden)\n",
    "        \n",
    "        decoder_input = encoder_input[:, :2]\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        decoder_outputs = torch.zeros(20, 30, 2)\n",
    "        for i in range(30):\n",
    "            embedded = self.activation(self.linear2(decoder_input))\n",
    "            decoder_hidden = self.lstm2(embedded, decoder_hidden)\n",
    "            decoder_output = self.linear3(decoder_hidden[0])\n",
    "            decoder_input = decoder_output\n",
    "            decoder_outputs[:, i, :] = decoder_output\n",
    "        # Run optimization\n",
    "        pad_zero = torch.zeros(decoder_output.shape[0], 1)\n",
    "        variable_params = torch.cat((decoder_output, pad_zero), axis=1)\n",
    "        # Run optimization\n",
    "        variable_params = self.mask * var_inp + (1-self.mask) * variable_params\n",
    "\n",
    "        sol = self.opt_layer(fixed_params, variable_params)\n",
    "         \n",
    "        # Compute final trajectory\n",
    "        x_pred = torch.matmul(self.P, sol[:, :self.nvar].transpose(0, 1))\n",
    "        y_pred = torch.matmul(self.P, sol[:, self.nvar:2*self.nvar].transpose(0, 1))\n",
    "        x_pred = x_pred.transpose(0, 1)\n",
    "        y_pred = y_pred.transpose(0, 1)\n",
    "#         print(x_pred.shape, y_pred.shape)\n",
    "        x_pred = x_pred.reshape(x_pred.shape[0], x_pred.shape[1], 1)\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0], y_pred.shape[1], 1)\n",
    "#         x_pred = x_pred.reshape(x_pred.size[0], x_pred.size[1], 1).shape\n",
    "#         y_pred = y_pred.reshape(x_pred.size[0], x_pred.size[1], 1).shape\n",
    "        out = torch.cat([x_pred, y_pred], dim=2)\n",
    "#         print(out.shape)\n",
    "#         print(torch.cat([x_pred, y_pred]).shape)\n",
    "        return out\n",
    "\n",
    "class TrajNet(nn.Module):\n",
    "    def __init__(self, opt_layer, P, Pdot, input_size=2, hidden_size=16, embedding_size = 128, output_size=2, nvar=11, t_obs=8, num_layers = 1):\n",
    "        super(TrajNet, self).__init__()\n",
    "        self.nvar = nvar\n",
    "        self.t_obs = t_obs\n",
    "        self.P = torch.tensor(P, dtype=torch.double).to(device)\n",
    "        self.Pdot = torch.tensor(Pdot, dtype=torch.double).to(device)\n",
    "        self.linear1 = nn.Linear(input_size, embedding_size)\n",
    "        self.linear2 = nn.Linear(embedding_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size + 1)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.opt_layer = opt_layer\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dtype=torch.float64        \n",
    "        self.mask = torch.tensor([[0.0, 0.0, 1.0]], dtype=torch.double).to(device)\n",
    "    \n",
    "    def forward(self, x, fixed_params, var_inp):\n",
    "        batch_size, _, __ = x.size()\n",
    "        x = x.reshape(batch_size, _ * __)\n",
    "        out1 = self.activation(self.linear1(x)) # 40 to 128\n",
    "        out2 = self.activation(self.linear2(out1)) # 128 to 16\n",
    "        variable_params = self.linear3(out2) # 16 to 3\n",
    "        # to shape (b, 3)\n",
    "\n",
    "        # Run optimization\n",
    "        variable_params = self.mask * var_inp + (1-self.mask) * variable_params\n",
    "\n",
    "        sol = self.opt_layer(fixed_params, variable_params)\n",
    "         \n",
    "        # Compute final trajectory\n",
    "        x_pred = torch.matmul(self.P, sol[:, :self.nvar].transpose(0, 1))\n",
    "        y_pred = torch.matmul(self.P, sol[:, self.nvar:2*self.nvar].transpose(0, 1))\n",
    "        x_pred = x_pred.transpose(0, 1)\n",
    "        y_pred = y_pred.transpose(0, 1)\n",
    "        out = torch.cat([x_pred, y_pred], dim=1)\n",
    "        return out\n",
    "    \n",
    "class TrajNetLSTM(nn.Module):\n",
    "    def __init__(self, opt_layer, P, Pdot, input_size=2, hidden_size=16, embedding_size = 2, output_size = 2, nvar=11, t_obs=8, num_layers = 1):\n",
    "        super(TrajNetLSTM, self).__init__()\n",
    "        self.nvar = nvar\n",
    "        self.t_obs = t_obs\n",
    "        self.P = torch.tensor(P, dtype=torch.double).to(device)\n",
    "        self.Pdot = torch.tensor(Pdot, dtype=torch.double).to(device)\n",
    "        self.linear1 = nn.Linear(input_size, embedding_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        self.linear3 = nn.Linear(embedding_size, 60)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size + 1)\n",
    "        self.encoderlstm = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.decoderlstm = nn.LSTM(hidden_size, output_size, num_layers, batch_first=True)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.opt_layer = opt_layer\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dtype=torch.float64        \n",
    "        self.mask = torch.tensor([[0.0, 0.0, 1.0]], dtype=torch.double).to(device)\n",
    "    \n",
    "    def forward(self, x, fixed_params, var_inp):\n",
    "#         batch_size, _ = x.size()\n",
    "        batch_size, _, __ = x.size()\n",
    "        out = x\n",
    "        hidden_state = torch.zeros(self.num_layers, out.size(0), self.hidden_size, dtype=self.dtype)\n",
    "        cell_state = torch.zeros(self.num_layers, out.size(0), self.hidden_size, dtype=self.dtype)\n",
    "        torch.nn.init.xavier_normal_(hidden_state)\n",
    "        torch.nn.init.xavier_normal_(cell_state)\n",
    "        out, (hidden_state, cell_state) = self.encoderlstm(out, (hidden_state, cell_state))\n",
    "        \n",
    "#         # out of shape (b, 20, 2) -> (b, 30, 2)\n",
    "        pad = torch.zeros(20, 10, self.hidden_size)\n",
    "        out = torch.cat((out, pad), dim=1)\n",
    "        \n",
    "#         # from shape (b, 16) to (b, 2)\n",
    "        hidden_state = self.linear2(hidden_state)\n",
    "        cell_state = self.linear2(cell_state)\n",
    "        out, (hidden_state, cell_state) = self.decoderlstm(out, (hidden_state, cell_state))\n",
    "\n",
    "#         print(out[:,-1].shape)\n",
    "        pad_zeros = torch.zeros(out.shape[0], 1, dtype=self.dtype)\n",
    "        variable_params = torch.cat((out[:, -1],pad_zeros), dim=1)\n",
    "        \n",
    "#         variable_params = self.activation(self.linear(out.reshape(out2.shape[0], -1)))\n",
    "\n",
    "        # Run optimization\n",
    "        variable_params = self.mask * var_inp + (1-self.mask) * variable_params\n",
    "\n",
    "        sol = self.opt_layer(fixed_params, variable_params)\n",
    "         \n",
    "        # Compute final trajectory\n",
    "        x_pred = torch.matmul(self.P, sol[:, :self.nvar].transpose(0, 1))\n",
    "        y_pred = torch.matmul(self.P, sol[:, self.nvar:2*self.nvar].transpose(0, 1))\n",
    "        x_pred = x_pred.transpose(0, 1)\n",
    "        y_pred = y_pred.transpose(0, 1)\n",
    "        out = torch.cat([x_pred, y_pred], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 30\n",
    "t_obs = 20\n",
    "num_elems = 15\n",
    "include_centerline = False\n",
    "name = \"final_without\" if include_centerline else \"final_with\"\n",
    "lr = 0.0001\n",
    "shuffle = True\n",
    "\n",
    "train_dataset = ArgoverseDataset(\"/datasets/argoverse/val_data.npy\", centerline_dir=\"/datasets/argoverse/val_centerlines.npy\", t_obs=20, dt=0.3, include_centerline = include_centerline)\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=shuffle, num_workers=0)\n",
    "\n",
    "test_dataset = ArgoverseDataset(\"/datasets/argoverse/val_test_data.npy\", centerline_dir=\"/datasets/argoverse/val_test_centerlines.npy\", t_obs=20, dt=0.3, include_centerline = include_centerline)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=shuffle, num_workers=0)\n",
    "\n",
    "offsets_train = np.load(\"/datasets/argoverse/val_offsets.npy\")\n",
    "# offsets_test = np.load(\"/datasets/argoverse/val_offsets_test.npy\")\n",
    "\n",
    "problem = OPTNode(rho_eq=10, t_fin=9.0, num=num)\n",
    "opt_layer = DeclarativeLayer(problem)\n",
    "\n",
    "model = TrajNetLSTM(opt_layer, problem.P, problem.Pdot)#, input_size=t_obs * 2 + include_centerline * num_elems * 2)\n",
    "# model = TrajNet(opt_layer, problem.P, problem.Pdot)#, input_size=t_obs * 2 + include_centerline * num_elems * 2)\n",
    "# model = TrajNet(opt_layer, problem.P, problem.Pdot, input_size=t_obs * 2 + include_centerline * num_elems * 2)\n",
    "model = model.double()\n",
    "model = model.to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"./checkpoints/final.ckpt\"))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20, 2]) torch.Size([20, 60])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_num, data in enumerate(train_loader):\n",
    "    traj_inp, traj_out, fixed_params, var_inp = data\n",
    "    torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=False)\n",
    "    print(traj_inp.size(), traj_out.size())\n",
    "    ade = []\n",
    "    fde = []\n",
    "#     out = model(traj_inp.float(), fixed_params.float(), var_inp.float())\n",
    "    out = model(traj_inp, fixed_params, var_inp)\n",
    "#     print(out.shape)\n",
    "#     plt.scatter(traj_inp[1][:40:2], traj_inp[1][1:40:2], label='inp')\n",
    "    plt.scatter(traj_inp[1,:, 0], traj_inp[1, :, 1], label='inp')\n",
    "#     plt.scatter(traj_out[1,:, 0], traj_out[1, :, 1], label='gt')\n",
    "#     plt.scatter(out[1,:, 0].detach(), out[1, :, 1].detach(), label='pred')\n",
    "\n",
    "    plt.scatter(traj_out[1][:30], traj_out[1][30:], label='gt')\n",
    "    plt.scatter(out[1][:30].detach(), out[1][30:].detach(), label='pred')\n",
    "    if include_centerline:\n",
    "        inp_len=t_obs * 2\n",
    "        c_len = t_obs * 2 + num_elems * 2\n",
    "        plt.plot(traj_inp[1][inp_len:c_len:2] , traj_inp[1][inp_len + 1:c_len:2], color='black',label='primary-centerline')\n",
    "    plt.legend()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 662.9842206725792\n",
      "ADE: 29.77078235726639 FDE: 53.929014604663806\n",
      "Epoch: 0, Batch: 10, Loss: 531.6909953189445\n",
      "ADE: 25.449284000711366 FDE: 45.18571011282798\n",
      "Epoch: 0, Batch: 20, Loss: 454.73209674670943\n",
      "ADE: 23.167437374692632 FDE: 43.509019929504454\n",
      "Epoch: 0, Batch: 30, Loss: 537.2437292434994\n",
      "ADE: 26.240295256363673 FDE: 50.287699870517336\n",
      "Epoch: 0, Batch: 40, Loss: 684.9975481124403\n",
      "ADE: 29.675048679910372 FDE: 51.43460896545164\n",
      "Epoch: 0, Mean Loss: 545.8046925807823\n",
      "Mean ADE: 25.703363095156927 Mean FDE: 47.6696212722491\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 1, Batch: 0, Loss: 606.8218123004161\n",
      "ADE: 28.557348992100618 FDE: 53.916469906367524\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-b6338b286477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#         out = model(traj_inp.float(), fixed_params.float(), var_inp.float())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-468db8ca57bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, fixed_params, var_inp)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mvariable_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvar_inp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvariable_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Compute final trajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-15ee3fbabb2a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDeclarativeFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-74-f83e2d5da7f5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, problem, *inputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolve_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-00751a2365d5>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, fixed_params, variable_params)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mres_nonhol_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_nonhol_x\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mres_nonhol_y\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho_eq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_eq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_eq_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho_nonhol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_nonhol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_nonhol_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho_eq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_eq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_eq_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho_nonhol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_nonhol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_nonhol_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_train_loss = []\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    mean_ade = []\n",
    "    mean_fde = []    \n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        traj_inp, traj_out, fixed_params, var_inp = data\n",
    "        traj_inp = traj_inp.to(device)\n",
    "        traj_out = traj_out.to(device)\n",
    "        fixed_params = fixed_params.to(device)\n",
    "        var_inp = var_inp.to(device)\n",
    "\n",
    "        ade = []\n",
    "        fde = []            \n",
    "#         out = model(traj_inp.float(), fixed_params.float(), var_inp.float())\n",
    "        out = model(traj_inp, fixed_params, var_inp)\n",
    "        loss = criterion(out, traj_out)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        for ii in range(traj_inp.size()[0]):\n",
    "            gt = [[out[ii][j].item(),out[ii][j + num].item()] for j in range(len(out[ii])//2)]\n",
    "            pred = [[traj_out[ii][j].item(),traj_out[ii][j + num].item()] for j in range(len(out[ii])//2)]\n",
    "#             ade.append(get_ade(np.array(out[ii].detach()), np.array(traj_out[ii].detach())))\n",
    "#             fde.append(get_fde(np.array(out[ii].detach()), np.array(traj_out[ii].detach())))\n",
    "            ade.append(get_ade(np.array(pred), np.array(gt)))\n",
    "            fde.append(get_fde(np.array(pred), np.array(gt)))                                    \n",
    "#             plot_traj(ii, traj_inp[ii], traj_out[ii], out[ii], {\"x\": [], \"y\": []}, offsets=offsets_train, cities = [], avm=None, center=include_centerline, inp_len=t_obs * 2, c_len = t_obs * 2 + num_elems * 2, num=num, mode=\"test\", batch_num=batch_num)\n",
    "        if batch_num % 10 == 0:\n",
    "            print(\"Epoch: {}, Batch: {}, Loss: {}\".format(epoch, batch_num, loss.item()))\n",
    "            print(\"ADE: {}\".format(np.mean(ade)), \"FDE: {}\".format(np.mean(fde)))\n",
    "\n",
    "        mean_ade.append(np.mean(ade))\n",
    "        mean_fde.append(np.mean(fde))\n",
    "\n",
    "    mean_loss = np.mean(train_loss)\n",
    "    epoch_train_loss.append(mean_loss)\n",
    "    torch.save(model.state_dict(), \"./checkpoints/{}.ckpt\".format(name))\n",
    "    print(\"Epoch: {}, Mean Loss: {}\".format(epoch, mean_loss))\n",
    "    print(\"Mean ADE: {}\".format(np.mean(mean_ade)), \"Mean FDE: {}\".format(np.mean(mean_fde)))\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Loss: 14.400999027443135\n",
      "Batch: 1, Loss: 11.699043619684053\n",
      "Batch: 2, Loss: 8.618406937053239\n",
      "Batch: 3, Loss: 5.229336737043434\n",
      "Batch: 4, Loss: 6.6153500760466\n",
      "Batch: 5, Loss: 7.819490196908543\n",
      "Batch: 6, Loss: 18.122736699381505\n",
      "Batch: 7, Loss: 13.311774520411692\n",
      "Batch: 8, Loss: 21.00286850690768\n",
      "Batch: 9, Loss: 14.720169439894413\n",
      "Epoch Mean Test Loss: 12.15401757607743\n",
      "Mean ADE: 3.391014935577728 Mean FDE: 5.738302015315152\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    cnt = 0\n",
    "    test_loss = []\n",
    "    mean_ade = []\n",
    "    mean_fde = []     \n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        traj_inp, traj_out, fixed_params, var_inp = data\n",
    "        traj_inp = traj_inp.to(device)\n",
    "        traj_out = traj_out.to(device)\n",
    "        fixed_params = fixed_params.to(device)\n",
    "        var_inp = var_inp.to(device)\n",
    "        \n",
    "        ade = []\n",
    "        fde = []        \n",
    "        \n",
    "        out = model(traj_inp, fixed_params, var_inp)\n",
    "        loss = criterion(out, traj_out)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        print(\"Batch: {}, Loss: {}\".format(batch_num, loss.item()))\n",
    "        \n",
    "        for ii in range(traj_inp.size()[0]):\n",
    "            gt = [[out[ii][j],out[ii][j + num]] for j in range(len(out[ii])//2)]\n",
    "            pred = [[traj_out[ii][j],traj_out[ii][j + num]] for j in range(len(out[ii])//2)]\n",
    "            ade.append(get_ade(np.array(pred), np.array(gt)))\n",
    "            fde.append(get_fde(np.array(pred), np.array(gt)))                        \n",
    "            plot_traj(ii, traj_inp[ii], traj_out[ii], out[ii], {\"x\": [], \"y\": []}, offsets=offsets_train, cities = [], avm=None, center=include_centerline, inp_len=num * 2, c_len = num * 2 + num_elems * 2, num=num, mode=\"test\", batch_num=batch_num)\n",
    "\n",
    "        mean_ade.append(np.mean(ade))\n",
    "        mean_fde.append(np.mean(fde))  \n",
    "\n",
    "mean_loss = np.mean(test_loss)\n",
    "print(\"Epoch Mean Test Loss: {}\".format(mean_loss))\n",
    "print(\"Mean ADE: {}\".format(np.mean(mean_ade)), \"Mean FDE: {}\".format(np.mean(mean_fde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(gt_x, gt_y, w = 7):\n",
    "    # denoising\n",
    "    w = w\n",
    "    gt_x_t = []\n",
    "    gt_y_t = []\n",
    "    for iq in range(len(gt_x)):\n",
    "        if iq >= w and iq + w <= len(gt_x):\n",
    "            gt_x_t.append(np.average(gt_x[iq: iq + w]))\n",
    "            gt_y_t.append(np.average(gt_y[iq: iq + w]))\n",
    "        elif iq < w:\n",
    "            okx = np.average(gt_x[w: w + w])\n",
    "            gt_x_t.append(gt_x[0] + (okx - gt_x[0]) * (iq) / w)\n",
    "            oky = np.average(gt_y[w: w + w])\n",
    "            gt_y_t.append(gt_y[0] + (oky - gt_y[0]) * (iq) / w)\n",
    "        else:\n",
    "            okx = np.average(gt_x[len(gt_x) - w:len(gt_x) - w  + w])\n",
    "            oky = np.average(gt_y[len(gt_x) - w: len(gt_x) - w + w])\n",
    "            gt_x_t.append(okx + (gt_x[-1] - okx) * (w - (len(gt_x) - iq)) / w)\n",
    "            gt_y_t.append(oky + (gt_y[-1] - oky) * (w - (len(gt_y) - iq)) / w)                   \n",
    "\n",
    "    gt_x = gt_x_t\n",
    "    gt_y = gt_y_t\n",
    "    return gt_x, gt_y\n",
    "\n",
    "def rotate(gt_x, gt_y,theta):\n",
    "    gt_x_x = [ (gt_x[k] * np.cos(theta) - gt_y[k] * np.sin(theta))  for k in range(len(gt_x))]\n",
    "    gt_y_y = [ (gt_x[k] * np.sin(theta) + gt_y[k] * np.cos(theta))  for k in range(len(gt_x))]\n",
    "    gt_x = gt_x_x\n",
    "    gt_y = gt_y_y\n",
    "    return gt_x, gt_y\n",
    "\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    def __init__(self, data_path, t_obs=16, dt=0.125,centerline_dir=None, include_centerline = False):\n",
    "        self.data = np.load(data_path)\n",
    "        self.data_path = data_path\n",
    "        self.t_obs = t_obs\n",
    "        self.dt = dt\n",
    "        self.include_centerline = include_centerline\n",
    "        self.centerline_dir = centerline_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dt = self.dt\n",
    "        traj = self.data[idx]\n",
    "        x_traj = traj[:, 0]\n",
    "        y_traj = traj[:, 1]\n",
    "        \n",
    "        x_traj -= x_traj[0]\n",
    "        y_traj -= y_traj[0]\n",
    "        \n",
    "        gt_x = x_traj\n",
    "        gt_y = y_traj\n",
    "        \n",
    "        ind = 1\n",
    "        \n",
    "        if idx == ind:\n",
    "            plt.axis('equal')\n",
    "#             plt.scatter(gt_x, gt_y, color='blue', label='noisy')\n",
    "        \n",
    "        gt_x, gt_y = denoise(gt_x, gt_y)\n",
    "        v_x = [ (gt_x[k + 1] - gt_x[k])/dt  for k in range(len(gt_x) - 1)]\n",
    "        v_y = [ (gt_y[k + 1] - gt_y[k])/dt  for k in range(len(gt_y) - 1)]\n",
    "        psi = [ np.arctan2(v_y[k], v_x[k]) for k in range(len(v_x))]  \n",
    "        \n",
    "        if idx == ind:\n",
    "            plt.axis('equal')\n",
    "#             plt.scatter(gt_x, gt_y, color='purple',label='before')\n",
    "        \n",
    "        # till here, gt-> (50, 1), v -> (49, 1), psi -> (31, 1)\n",
    "        \n",
    "        # obtain this -psi\n",
    "        theta = -psi[self.t_obs - 1]\n",
    "        \n",
    "        # rotate by theta\n",
    "        gt_x, gt_y = rotate(gt_x, gt_y, theta)\n",
    "#         gt_x_x = [ (gt_x[k] * np.cos(theta) - gt_y[k] * np.sin(theta))  for k in range(len(gt_x))]\n",
    "#         gt_y_y = [ (gt_x[k] * np.sin(theta) + gt_y[k] * np.cos(theta))  for k in range(len(gt_x))]\n",
    "#         gt_x = gt_x_x\n",
    "#         gt_y = gt_y_y\n",
    "        if idx == ind:\n",
    "            plt.axis('equal')\n",
    "#             plt.scatter(gt_x, gt_y, color='yellow') \n",
    "        v_x = [ (gt_x[k + 1] - gt_x[k])/dt  for k in range(len(gt_x) - 1)]\n",
    "        v_y = [ (gt_y[k + 1] - gt_y[k])/dt  for k in range(len(gt_y) - 1)]\n",
    "        psi = [ np.arctan2(v_y[k], v_x[k]) for k in range(len(v_x))]\n",
    "        psidot = [ (psi[k + 1] - psi[k])/dt for k in range(len(psi) - 1) ]\n",
    "        psi_traj = [i.item() for i in psi]\n",
    "        psidot_traj = [i.item() for i in psidot]\n",
    "    \n",
    "        \n",
    "        x_traj = gt_x\n",
    "        y_traj = gt_y\n",
    "\n",
    "        x_inp = x_traj[:self.t_obs]\n",
    "        y_inp = y_traj[:self.t_obs]\n",
    "        x_fut = x_traj[self.t_obs:]\n",
    "        y_fut = y_traj[self.t_obs:]\n",
    "#         psi_fut = psi_traj[self.t_obs:]\n",
    "#         psidot_fut = psidot_traj[self.t_obs:]\n",
    "\n",
    "        # till here, gt-> (32, 1), v -> (31, 1), psi -> (31, 1), psidot -> (30, 1)\n",
    "        psi_fut = psi_traj[self.t_obs - 1:]\n",
    "        psidot_fut = psi_traj[self.t_obs - 2:]\n",
    "        \n",
    "        vx_traj = v_x\n",
    "        vy_traj = v_y\n",
    "        \n",
    "        vx_beg = vx_traj[self.t_obs]\n",
    "        vy_beg = vy_traj[self.t_obs]\n",
    "        \n",
    "        vx_beg_prev = vx_traj[self.t_obs - 1]\n",
    "        vy_beg_prev = vy_traj[self.t_obs - 1]\n",
    "        \n",
    "        ax_beg = (vx_beg - vx_beg_prev) / self.dt\n",
    "        ay_beg = (vy_beg - vy_beg_prev) / self.dt\n",
    "\n",
    "        vx_fin = v_x[-1]\n",
    "        vy_fin = v_y[-1]\n",
    "        \n",
    "        vx_fin_prev = v_x[-2]\n",
    "        vy_fin_prev = v_y[-2]\n",
    "\n",
    "        ax_fin = (vx_fin - vx_fin_prev) / self.dt\n",
    "        ay_fin = (vy_fin - vy_fin_prev) / self.dt\n",
    "\n",
    "        x_fut = x_traj[self.t_obs:]\n",
    "        y_fut = y_traj[self.t_obs:]\n",
    "        \n",
    "        traj_inp = np.dstack((x_inp, y_inp)).flatten()        \n",
    "        if self.include_centerline:\n",
    "            cs = np.load(self.centerline_dir)[idx]\n",
    "            data = np.load(self.data_path)\n",
    "\n",
    "            c_x = cs[:, 0]            \n",
    "            c_y = cs[:, 1]\n",
    "            c_x -= data[idx][0,0]\n",
    "            c_y -= data[idx][0,1]\n",
    "            c_x, c_y = denoise(c_x, c_y)\n",
    "#             if idx == ind:\n",
    "#                 plt.plot(c_x, c_y, color='black', label='grey')\n",
    "            \n",
    "            # rotate by theta\n",
    "            c_x, c_y = rotate(c_x, c_y, theta)\n",
    "            c_x -= c_x[0]\n",
    "            c_y -= c_y[0]\n",
    "            c_x += x_inp[-1]\n",
    "            c_y += y_inp[-1]\n",
    "        \n",
    "#             c_y += y_inp[-1] + 2\n",
    "            c_inp = np.dstack((c_x, c_y)).flatten()\n",
    "            traj_inp = np.hstack((traj_inp, c_inp))\n",
    "            \n",
    "        vx_fut = vx_traj[self.t_obs:]\n",
    "        vy_fut = vy_traj[self.t_obs:]\n",
    "        traj_out = np.hstack((x_fut, y_fut)).flatten()\n",
    "\n",
    "        fixed_params = np.array([x_fut[0], y_fut[0], 0, psi_fut[0], psidot_fut[0]])\n",
    "        var_inp = np.array([x_inp[-1], y_inp[-1], psi_fut[-1]])\n",
    "\n",
    "#             print(fixed_params)\n",
    "#             print(var_inp)\n",
    "        return torch.tensor(traj_inp), torch.tensor(traj_out), torch.tensor(fixed_params), torch.tensor(var_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_traj(cnt, traj_inp, traj_out, traj_pred, obs, batch_num=0, num = 30, offsets = [], cities = [], avm = None, center = True, mode = \"train\", inp_len=40, c_len=70):\n",
    "    traj_inp = traj_inp.numpy()\n",
    "    traj_out = traj_out.numpy()\n",
    "    traj_pred = traj_pred.detach().numpy()\n",
    "    \n",
    "    lane_centerlines = []\n",
    "    ind = batch_num * 20 + cnt\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    # Get lane centerlines which lie within the range of trajectories\n",
    "    ox = offsets[ind][0] + 2\n",
    "    oy = offsets[ind][1] + 2\n",
    "    ox = 0\n",
    "    oy = 0\n",
    "    if avm is not None:\n",
    "        city = cities[ind]\n",
    "        ox = offsets[ind][0] + 2\n",
    "        oy = offsets[ind][1] + 2\n",
    "        x_max = np.max(np.concatenate((traj_inp[:inp_len:2], traj_out[:num], traj_pred[:num]), axis=0)) + ox\n",
    "        x_min = np.min(np.concatenate((traj_inp[:inp_len:2], traj_out[:num], traj_pred[:num]), axis=0)) + ox\n",
    "        y_max = np.max(np.concatenate((traj_inp[1:inp_len:2], traj_out[num:], traj_pred[num:]), axis=0)) + oy\n",
    "        y_min = np.min(np.concatenate((traj_inp[1:inp_len:2], traj_out[num:], traj_pred[num:]), axis=0)) + oy\n",
    "        \n",
    "        seq_lane_props = avm.city_lane_centerlines_dict[city]\n",
    "        for lane_id, lane_props in seq_lane_props.items():\n",
    "            lane_cl = lane_props.centerline\n",
    "\n",
    "            if (np.min(lane_cl[:, 0]) < x_max and np.min(lane_cl[:, 1]) < y_max and np.max(lane_cl[:, 0]) > x_min and np.max(lane_cl[:, 1]) > y_min):\n",
    "                lane_centerlines.append(lane_cl)\n",
    "\n",
    "        for lane_cl in lane_centerlines:\n",
    "            if True:\n",
    "                ax.plot(lane_cl[:, 0], lane_cl[:, 1], \"--\", color=\"grey\", alpha=1, linewidth=1, zorder=0)\n",
    "\n",
    "    ax.scatter(traj_inp[:inp_len:2] + ox, traj_inp[1:inp_len:2] + oy, color='blue', label='Inp traj')\n",
    "    ax.scatter(traj_out[:num] + ox, traj_out[num:] + oy, color='orange', label='GT')\n",
    "    ax.scatter(traj_pred[:num] + ox, traj_pred[num:] + oy, color='green', label='Pred')\n",
    "\n",
    "    if center:\n",
    "        ax.plot(traj_inp[inp_len:c_len:2] + ox , traj_inp[inp_len + 1:c_len:2] + oy, color='black',label='primary-centerline')\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.axis('equal')\n",
    "    if mode == \"train\":\n",
    "        plt.savefig('./results/{}.png'.format(cnt))\n",
    "    else:\n",
    "        plt.savefig('./results/{}.png'.format(batch_num * 20 + cnt))\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
