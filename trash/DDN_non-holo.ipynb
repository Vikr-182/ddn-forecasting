{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"./ddn/\")\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ddn.pytorch.node import AbstractDeclarativeNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = 129\n",
    "y_init = 202.3-2.0\n",
    "\n",
    "x_fin = 199\n",
    "y_fin = 193.0\n",
    "\n",
    "x_fin = 238\n",
    "y_fin = 139.0-6.0\n",
    "\n",
    "v_init = 20.0\n",
    "v_fin =  16.0\n",
    "\n",
    "\n",
    "vdot_init = 0.0\n",
    "vdot_fin = 0.0\n",
    "\n",
    "psi_init = 0.0\n",
    "psidot_init = 0.0\n",
    "psiddot_init = 0.0\n",
    "\n",
    "\n",
    "psi_fin = -91*np.pi/180\n",
    "psidot_fin = 0.0\n",
    "psiddot_fin = 0.0\n",
    "\n",
    "x_mid = np.hstack(( 162, 198, 228))\n",
    "y_mid = np.hstack(( 202, 193, 170))\n",
    "# prob = OptimizerLane()\n",
    "# primal_sol, dual_sol, res_eq_psi, res_w, c_v = prob.solve(x_init, y_init, x_fin, y_fin, v_init, v_fin, psi_init, psidot_init, psi_fin, psidot_fin, x_mid, y_mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernstein_coeff_order10_new(n, tmin, tmax, t_actual):\n",
    "    \n",
    "    l = tmax - tmin\n",
    "    t = (t_actual - tmin) / l\n",
    "\n",
    "    P0 = scipy.special.binom(n, 0) * ((1 - t) ** (n - 0)) * t ** 0\n",
    "    P1 = scipy.special.binom(n, 1) * ((1 - t) ** (n - 1)) * t ** 1\n",
    "    P2 = scipy.special.binom(n, 2) * ((1 - t) ** (n - 2)) * t ** 2\n",
    "    P3 = scipy.special.binom(n, 3) * ((1 - t) ** (n - 3)) * t ** 3\n",
    "    P4 = scipy.special.binom(n, 4) * ((1 - t) ** (n - 4)) * t ** 4\n",
    "    P5 = scipy.special.binom(n, 5) * ((1 - t) ** (n - 5)) * t ** 5\n",
    "    P6 = scipy.special.binom(n, 6) * ((1 - t) ** (n - 6)) * t ** 6\n",
    "    P7 = scipy.special.binom(n, 7) * ((1 - t) ** (n - 7)) * t ** 7\n",
    "    P8 = scipy.special.binom(n, 8) * ((1 - t) ** (n - 8)) * t ** 8\n",
    "    P9 = scipy.special.binom(n, 9) * ((1 - t) ** (n - 9)) * t ** 9\n",
    "    P10 = scipy.special.binom(n, 10) * ((1 - t) ** (n - 10)) * t ** 10\n",
    "\n",
    "    P0dot = -10.0 * (-t + 1) ** 9\n",
    "    P1dot = -90.0 * t * (-t + 1) ** 8 + 10.0 * (-t + 1) ** 9\n",
    "    P2dot = -360.0 * t ** 2 * (-t + 1) ** 7 + 90.0 * t * (-t + 1) ** 8\n",
    "    P3dot = -840.0 * t ** 3 * (-t + 1) ** 6 + 360.0 * t ** 2 * (-t + 1) ** 7\n",
    "    P4dot = -1260.0 * t ** 4 * (-t + 1) ** 5 + 840.0 * t ** 3 * (-t + 1) ** 6\n",
    "    P5dot = -1260.0 * t ** 5 * (-t + 1) ** 4 + 1260.0 * t ** 4 * (-t + 1) ** 5\n",
    "    P6dot = -840.0 * t ** 6 * (-t + 1) ** 3 + 1260.0 * t ** 5 * (-t + 1) ** 4\n",
    "    P7dot = -360.0 * t ** 7 * (-t + 1) ** 2 + 840.0 * t ** 6 * (-t + 1) ** 3\n",
    "    P8dot = 45.0 * t ** 8 * (2 * t - 2) + 360.0 * t ** 7 * (-t + 1) ** 2\n",
    "    P9dot = -10.0 * t ** 9 + 9 * t ** 8 * (-10.0 * t + 10.0)\n",
    "    P10dot = 10.0 * t ** 9\n",
    "\n",
    "    P0ddot = 90.0 * (-t + 1) ** 8\n",
    "    P1ddot = 720.0 * t * (-t + 1) ** 7 - 180.0 * (-t + 1) ** 8\n",
    "    P2ddot = 2520.0 * t ** 2 * (-t + 1) ** 6 - 1440.0 * t * (-t + 1) ** 7 + 90.0 * (-t + 1) ** 8\n",
    "    P3ddot = 5040.0 * t ** 3 * (-t + 1) ** 5 - 5040.0 * t ** 2 * (-t + 1) ** 6 + 720.0 * t * (-t + 1) ** 7\n",
    "    P4ddot = 6300.0 * t ** 4 * (-t + 1) ** 4 - 10080.0 * t ** 3 * (-t + 1) ** 5 + 2520.0 * t ** 2 * (-t + 1) ** 6\n",
    "    P5ddot = 5040.0 * t ** 5 * (-t + 1) ** 3 - 12600.0 * t ** 4 * (-t + 1) ** 4 + 5040.0 * t ** 3 * (-t + 1) ** 5\n",
    "    P6ddot = 2520.0 * t ** 6 * (-t + 1) ** 2 - 10080.0 * t ** 5 * (-t + 1) ** 3 + 6300.0 * t ** 4 * (-t + 1) ** 4\n",
    "    P7ddot = -360.0 * t ** 7 * (2 * t - 2) - 5040.0 * t ** 6 * (-t + 1) ** 2 + 5040.0 * t ** 5 * (-t + 1) ** 3\n",
    "    P8ddot = 90.0 * t ** 8 + 720.0 * t ** 7 * (2 * t - 2) + 2520.0 * t ** 6 * (-t + 1) ** 2\n",
    "    P9ddot = -180.0 * t ** 8 + 72 * t ** 7 * (-10.0 * t + 10.0)\n",
    "    P10ddot = 90.0 * t ** 8\n",
    "    90.0 * t ** 8\n",
    "\n",
    "    P = np.hstack((P0, P1, P2, P3, P4, P5, P6, P7, P8, P9, P10))\n",
    "    Pdot = np.hstack((P0dot, P1dot, P2dot, P3dot, P4dot, P5dot, P6dot, P7dot, P8dot, P9dot, P10dot)) / l\n",
    "    Pddot = np.hstack((P0ddot, P1ddot, P2ddot, P3ddot, P4ddot, P5ddot, P6ddot, P7ddot, P8ddot, P9ddot, P10ddot)) / (l ** 2)\n",
    "    return P, Pdot, Pddot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPTNode(AbstractDeclarativeNode):\n",
    "    def __init__(self):\n",
    "        self.rho_eq = 1.0\n",
    "        self.rho_goal = 1.0\n",
    "        self.rho_lane = 1.0\n",
    "        self.rho_nonhol = 1.0\n",
    "        self.rho_w_psi = 1.0\n",
    "        self.rho_psi = 1.0\n",
    "        self.maxiter = 500\n",
    "        self.weight_smoothness = 1.0\n",
    "        self.weight_smoothness_psi = 1.0\n",
    "\n",
    "        self.t_fin = 8.0\n",
    "        self.num = 100\n",
    "        self.t = self.t_fin/self.num\n",
    "\n",
    "        tot_time = np.linspace(0.0, self.t_fin, self.num)#.to(device)\n",
    "        tot_time_copy = tot_time.reshape(self.num, 1)\n",
    "        self.P, self.Pdot, self.Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "\n",
    "        self.nvar = np.shape(self.P)[1]\n",
    "        self.A_eq_psi = np.vstack((self.P[0], self.Pdot[0], self.P[-1], self.Pdot[-1]))\n",
    "\n",
    "        self.cost_smoothness = self.weight_smoothness*np.dot(self.Pddot.T, self.Pddot)\n",
    "        self.cost_smoothness_v = self.weight_smoothness*np.dot(self.Pddot.T, self.Pddot)\n",
    "        self.cost_smoothness_psi = self.weight_smoothness_psi*np.dot(self.Pddot.T, self.Pddot)\n",
    "        self.lincost_smoothness_psi = np.zeros(self.nvar)\n",
    "\n",
    "        self.P = torch.tensor(self.P, dtype=torch.double).to(device) # AAAAAAA\n",
    "        self.Pdot = torch.tensor(self.Pdot, dtype=torch.double).to(device)\n",
    "        self.Pddot = torch.tensor(self.Pddot, dtype=torch.double).to(device)\n",
    "        self.A_eq_psi = torch.tensor(self.A_eq_psi, dtype=torch.double).to(device)\n",
    "        self.cost_smoothness = torch.tensor(self.cost_smoothness, dtype=torch.double).to(device)\n",
    "        self.cost_smoothness_v = torch.tensor(self.cost_smoothness_v, dtype=torch.double).to(device)\n",
    "        self.cost_smoothness_psi = torch.tensor(self.cost_smoothness_psi, dtype=torch.double).to(device)\n",
    "        self.lincost_smoothness_psi = torch.tensor(self.lincost_smoothness_psi, dtype=torch.double).to(device)\n",
    "\n",
    "        self.rho_mid = 0.01\n",
    "        self.mid_idx = torch.tensor([ int(self.num/4), int(self.num/2), int(3*self.num/4)]).to(device)\n",
    "    \n",
    "    def compute_w_psi(self, x_init, y_init, x_fin, y_fin, x_mid, y_mid, psi, v, lamda_wc, lamda_ws):\n",
    "\n",
    "        A_w = self.P\n",
    "        A_w_psi = self.P\n",
    "\n",
    "        b_wc_psi = torch.cos(psi).double()\n",
    "        b_ws_psi = torch.sin(psi).double()\n",
    "        \n",
    "        temp_x = torch.cumsum(self.P*(v*self.t)[:, np.newaxis] , axis = 0)\n",
    "        temp_y = torch.cumsum(self.P*(v*self.t)[:, np.newaxis] , axis = 0)\n",
    "\n",
    "        A_x = temp_x[0:self.num-1]\n",
    "        A_y = temp_y[0:self.num-1]\n",
    "\n",
    "        A_x_goal = A_x[-1].reshape(1, self.nvar)\n",
    "        b_x_goal = torch.tensor([x_fin-x_init], dtype=torch.double)\n",
    "\n",
    "        A_y_goal = A_y[-1].reshape(1, self.nvar)\n",
    "        b_y_goal = torch.tensor([y_fin-y_init], dtype=torch.double)\n",
    "\n",
    "\n",
    "        A_x_mid = A_x[self.mid_idx]\n",
    "        A_y_mid = A_y[self.mid_idx]\n",
    "\n",
    "        b_x_mid = x_mid-x_init\n",
    "        b_y_mid = y_mid-y_init\n",
    "\n",
    "        obj_x_goal = self.rho_goal*torch.matmul(A_x_goal.T, A_x_goal)\n",
    "        linterm_augment_x_goal = -self.rho_goal*torch.matmul(A_x_goal.T, b_x_goal)\n",
    "\n",
    "        obj_y_goal = self.rho_goal*torch.matmul(A_y_goal.T, A_y_goal)\n",
    "        linterm_augment_y_goal = -self.rho_goal*torch.matmul(A_y_goal.T, b_y_goal)\n",
    "\n",
    "        obj_x_mid = self.rho_mid*torch.matmul(A_x_mid.T, A_x_mid)\n",
    "        linterm_augment_x_mid = -self.rho_mid*torch.matmul(A_x_mid.T, b_x_mid)\n",
    "\n",
    "        obj_y_mid = self.rho_mid*torch.matmul(A_y_mid.T, A_y_mid)\n",
    "        linterm_augment_y_mid = -self.rho_mid*torch.matmul(A_y_mid.T, b_y_mid)\n",
    "\n",
    "        obj_wc_psi = self.rho_w_psi*torch.matmul(A_w_psi.T, A_w_psi)\n",
    "        linterm_augment_wc_psi = -self.rho_w_psi*torch.matmul(A_w_psi.T, b_wc_psi)\n",
    "\n",
    "        obj_ws_psi = self.rho_w_psi*torch.matmul(A_w_psi.T, A_w_psi)\n",
    "        linterm_augment_ws_psi = -self.rho_w_psi*torch.matmul(A_w_psi.T, b_ws_psi)\n",
    "\n",
    "        cost_wc = obj_wc_psi+obj_x_goal+obj_x_mid\n",
    "        lincost_wc = -lamda_wc+linterm_augment_x_goal+linterm_augment_wc_psi+linterm_augment_x_mid\n",
    "\n",
    "        cost_ws = obj_y_goal+obj_ws_psi+obj_y_mid\n",
    "        lincost_ws = -lamda_ws+linterm_augment_y_goal+linterm_augment_ws_psi+linterm_augment_y_mid\n",
    "\n",
    "        c_wc_psi = torch.linalg.solve(-cost_wc, lincost_wc)\n",
    "        c_ws_psi = torch.linalg.solve(-cost_ws, lincost_ws)\n",
    "\n",
    "        wc = torch.matmul(self.P, c_wc_psi)\n",
    "        ws = torch.matmul(self.P, c_ws_psi)\n",
    "\n",
    "        return wc, ws, c_wc_psi, c_ws_psi\n",
    "\n",
    "    \n",
    "    def compute_psi(self, wc, ws, b_eq_psi, lamda_psi):\n",
    "\n",
    "        A_psi = self.P\n",
    "        b_psi = torch.atan2(ws, wc).double()\n",
    "\n",
    "        obj_psi = self.rho_psi*torch.matmul(A_psi.T, A_psi)\n",
    "        linterm_augment_psi = -self.rho_psi*torch.matmul(A_psi.T, b_psi)\n",
    "\n",
    "        cost_psi = self.cost_smoothness_psi+obj_psi+self.rho_eq*torch.matmul(self.A_eq_psi.T, self.A_eq_psi)\n",
    "        lincost_psi = -lamda_psi+linterm_augment_psi-self.rho_eq*torch.matmul(self.A_eq_psi.T, b_eq_psi)\n",
    "\n",
    "        sol = torch.linalg.solve(-cost_psi, lincost_psi)\n",
    "\n",
    "        c_psi = sol[0:self.nvar]\n",
    "\n",
    "        psi = torch.matmul(self.P, c_psi)\n",
    "        # self.psidot = np.dot(self.Pdot, c_psi)\n",
    "        # self.psiddot = np.dot(self.Pddot, c_psi)\n",
    "\n",
    "\n",
    "        res_psi = torch.matmul(A_psi, c_psi)-b_psi\n",
    "        res_eq_psi = torch.matmul(self.A_eq_psi, c_psi)-b_eq_psi\n",
    "        lamda_psi = lamda_psi-self.rho_psi*torch.matmul(A_psi.T, res_psi)-self.rho_eq*torch.matmul(self.A_eq_psi.T, res_eq_psi)\n",
    "\n",
    "\n",
    "        # self.lamda_psi = self.lamda_psi+0.90*(self.lamda_psi-lamda_psi_old)\n",
    "\n",
    "        return psi, c_psi, np.linalg.norm(res_psi), np.linalg.norm(res_eq_psi), lamda_psi\n",
    "\n",
    "    def compute_v(self, v_init, x_init, x_fin, x_mid, y_mid, psi, lamda_v):\n",
    "        temp_x = torch.cumsum(self.P*(np.cos(psi)*self.t)[:, np.newaxis], axis = 0)\n",
    "        temp_y = torch.cumsum(self.P*(np.sin(psi)*self.t)[:, np.newaxis], axis = 0)\n",
    "\n",
    "        A_x = temp_x[0:self.num-1]\n",
    "        A_y = temp_y[0:self.num-1]\n",
    "\n",
    "        A_x_goal = A_x[-1].reshape(1, self.nvar)\n",
    "        b_x_goal = (x_fin-x_init).unsqueeze(0)\n",
    "            \n",
    "        A_y_goal = A_y[-1].reshape(1, self.nvar)\n",
    "        b_y_goal = (y_fin-y_init).unsqueeze(0)\n",
    "        \n",
    "        A_x_mid = A_x[self.mid_idx]\n",
    "        A_y_mid = A_y[self.mid_idx]\n",
    "\n",
    "        b_x_mid = (x_mid-x_init)\n",
    "        b_y_mid = (y_mid-y_init)\n",
    "\n",
    "        A_vel_init = self.P[0].reshape(1, self.nvar)\n",
    "        b_vel_init = torch.tensor([v_init], dtype=torch.double)\n",
    "\n",
    "\n",
    "\n",
    "        obj_x_goal = self.rho_goal*torch.matmul(A_x_goal.T, A_x_goal)\n",
    "        linterm_augment_x_goal = -self.rho_goal*torch.matmul(A_x_goal.T, b_x_goal)\n",
    "\n",
    "        obj_y_goal = self.rho_goal*torch.matmul(A_y_goal.T, A_y_goal)\n",
    "        linterm_augment_y_goal = -self.rho_goal*torch.matmul(A_y_goal.T, b_y_goal)\n",
    "\n",
    "        obj_x_mid = self.rho_mid*torch.matmul(A_x_mid.T, A_x_mid)\n",
    "        linterm_augment_x_mid = -self.rho_mid*torch.matmul(A_x_mid.T, b_x_mid)\n",
    "\n",
    "        obj_y_mid = self.rho_mid*torch.matmul(A_y_mid.T, A_y_mid)\n",
    "        linterm_augment_y_mid = -self.rho_mid*torch.matmul(A_y_mid.T, b_y_mid)\n",
    "\n",
    "        obj_v_init = self.rho_eq*torch.matmul(A_vel_init.T, A_vel_init)\n",
    "        linterm_augment_v_init = -self.rho_eq*torch.matmul(A_vel_init.T, b_vel_init)\n",
    "\n",
    "        cost = obj_x_goal+obj_y_goal+self.cost_smoothness_v+obj_x_mid+obj_y_mid+obj_v_init\n",
    "        lincost = -lamda_v+linterm_augment_x_goal+linterm_augment_y_goal+linterm_augment_x_mid+linterm_augment_y_mid+linterm_augment_v_init\n",
    "\n",
    "        sol = torch.linalg.solve(-cost, lincost)\n",
    "\n",
    "        # cv = hstack((cv_1, cv_2, sol, cv_10, cv_11))\n",
    "\n",
    "        v = torch.matmul(self.P, sol)\n",
    "        # self.vdot = np.dot(self.Pdot, sol)\n",
    "\n",
    "\n",
    "        res_v_init = torch.matmul(A_vel_init, sol)-b_vel_init\n",
    "        lamda_v = lamda_v-self.rho_eq*torch.matmul(A_vel_init.T, res_v_init)\n",
    "\n",
    "        return sol, lamda_v, v\n",
    "\n",
    "    def optimize(self, x_init, y_init, x_fin, y_fin, v_init, v_fin, psi_init, psidot_init, psi_fin, psidot_fin, x_mid, y_mid):\n",
    "        v = v_init*torch.ones(self.num)\n",
    "        psi = psi_init*torch.ones(self.num)\n",
    "\n",
    "\n",
    "        res_psi = torch.ones(self.maxiter)\n",
    "        res_w_psi = torch.ones(self.maxiter)\n",
    "        res_w = torch.ones(self.maxiter)\n",
    "        res_eq_psi = torch.ones(self.maxiter)\n",
    "        res_eq = torch.ones(self.maxiter)\n",
    "\n",
    "        lamda_wc = torch.zeros(self.nvar)\n",
    "        lamda_ws = torch.zeros(self.nvar)\n",
    "        lamda_psi = torch.zeros(self.nvar)\n",
    "        lamda_v = torch.zeros(self.nvar)\n",
    "\n",
    "        b_eq_psi = torch.hstack((psi_init, psidot_init, psi_fin, psidot_fin))\n",
    "\n",
    "\n",
    "        for i in range(0, self.maxiter):\t\n",
    "\n",
    "\n",
    "            wc, ws, c_wc_psi, c_ws_psi = self.compute_w_psi(x_init, y_init, x_fin, y_fin, x_mid, y_mid, psi, v, lamda_wc, lamda_ws)\n",
    "            psi, c_psi, res_psi[i], res_eq_psi[i], lamda_psi = self.compute_psi(wc, ws, b_eq_psi, lamda_psi)\n",
    "            c_v, lamda_v, v = self.compute_v(v_init, x_init, x_fin, x_mid, y_mid, psi, lamda_v)\n",
    "\n",
    "\n",
    "\n",
    "            res_wc = wc-torch.cos(psi)\n",
    "            res_ws = ws-torch.sin(psi)\n",
    "            self.A_w = self.P\n",
    "\n",
    "            # lamda_wc_old = self.lamda_wc\n",
    "            # lamda_ws_old = self.lamda_ws\n",
    "\n",
    "\n",
    "            lamda_wc = lamda_wc-self.rho_w_psi*torch.matmul(self.A_w.T, res_wc)\n",
    "            lamda_ws = lamda_ws-self.rho_w_psi*torch.matmul(self.A_w.T, res_ws)\n",
    "\n",
    "            # self.lamda_wc = self.lamda_wc+0.90*(self.lamda_wc-lamda_wc_old)\n",
    "            # self.lamda_ws = self.lamda_ws+0.90*(self.lamda_ws-lamda_ws_old)\n",
    "\n",
    "\n",
    "            res_w[i] = torch.linalg.norm( torch.hstack(( res_wc, res_ws ))  )\n",
    "            # res_eq[i] = np.linalg.norm( np.hstack((  res_eq_x_vec, res_eq_y_vec     ))  )\n",
    "            # res_obs_lane[i] = np.linalg.norm( np.hstack(( res_x_obs_vec_lane, res_y_obs_vec_lane         ))  )\n",
    "\n",
    "\n",
    "        primal_sol = torch.hstack(( c_psi, c_v         ))\n",
    "        dual_sol = torch.hstack((  lamda_wc, lamda_ws, lamda_psi, lamda_v       ))\n",
    "\n",
    "        return primal_sol\n",
    "    #, dual_sol, res_eq_psi, res_w, c_v\n",
    "    \n",
    "    def objective(self, b, y):\n",
    "        batch_size, _ = b.size()\n",
    "        cost = 0\n",
    "        mid_size = self.mid_idx.size()[0]\n",
    "        for i in range(batch_size):\n",
    "            x_init, y_init, x_fin, y_fin, v_init, v_fin = b[i][0], b[i][1], b[i][2], b[i][3], b[i][4], b[i][5]\n",
    "            psi_init, psidot_init, psi_fin, psidot_fin = b[i][6], b[i][7], b[i][8], b[i][9]\n",
    "            x_mid = b[i][10:10+mid_size]\n",
    "            y_mid = b[i][10+mid_size:]\n",
    "\n",
    "            c_psi = primal_sol[0:nvar]\n",
    "            c_v = primal_sol[nvar:2*nvar]\n",
    "            v_new = torch.matmul(self.P, c_v)\n",
    "            psi_new = torch.matmul(self.P, c_psi)\n",
    "            psidot_new = torch.matmul(self.Pdot, c_psi)\n",
    "            \n",
    "            x_temp = x_init + torch.cumsum(v_new*torch.cos(psi_new)*self.t, dim=0)\n",
    "            y_temp = y_init + torch.cumsum(v_new*torch.sin(psi_new)*self.t, dim=0)\n",
    "            x = torch.hstack((x_init, x_temp[0:-1]))\n",
    "            y = torch.hstack((y_init, y_temp[0:-1]))\n",
    "\n",
    "            cost_final_pos = 0.5*self.rho_goal*((x[-1]-x_fin)**2+(y[-1]-y_fin)**2)\n",
    "            cost_psi_term = 0.5*self.rho_eq*( ( psi_new[0]-psi_init)**2+( psidot_new[0]-psidot_init)**2+( psi_new[-1]-psi_fin)**2+( psidot_new[-1]-psidot_fin)**2 )\n",
    "            cost_v_term = 0.5*self.rho_eq*(v_new[0]-v_init)**2\n",
    "            cost_mid_term = 0.5*self.rho_mid*( torch.sum(( x[self.mid_idx]-x_mid  )**2)+torch.sum(( y[self.mid_idx]-y_mid  )**2) )\n",
    "\n",
    "            cost += cost_final_pos+cost_psi_term+cost_v_term+cost_mid_term\n",
    "\n",
    "        return cost \n",
    "\n",
    "    def solve(self, b):\n",
    "        batch_size, _ = b.size()\n",
    "        y = torch.zeros(batch_size, 2*self.nvar)\n",
    "        mid_size = self.mid_idx.size()[0]\n",
    "        for i in range(batch_size):\n",
    "            x_init, y_init, x_fin, y_fin, v_init, v_fin = b[i][0], b[i][1], b[i][2], b[i][3], b[i][4], b[i][5]\n",
    "            psi_init, psidot_init, psi_fin, psidot_fin = b[i][6], b[i][7], b[i][8], b[i][9]\n",
    "            x_mid = b[i][10:10+mid_size]\n",
    "            y_mid = b[i][10+mid_size:]\n",
    "            primal_sol = self.optimize(x_init, y_init, x_fin, y_fin, v_init, v_fin, psi_init, psidot_init, psi_fin, psidot_fin, x_mid, y_mid)\n",
    "            \n",
    "#             c_psi = primal_sol[0:nvar]\n",
    "#             c_v = primal_sol[nvar:2*nvar]\n",
    "#             v_new = torch.matmul(self.P, c_v)\n",
    "#             psi_new = torch.matmul(self.P, c_psi)\n",
    "#             x_temp = x_init + torch.cumsum(v_new*torch.cos(psi_new)*self.t, dim=0)\n",
    "#             y_temp = y_init + torch.cumsum(v_new*torch.sin(psi_new)*self.t, dim=0)\n",
    "#             x_ret = torch.hstack((x_init, x_temp[0:-1]))\n",
    "#             y_ret = torch.hstack((y_init, y_temp[0:-1]))\n",
    "            y[i, :] = primal_sol\n",
    "        return y, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = torch.tensor(129, dtype=torch.double)\n",
    "y_init = torch.tensor(202.3-2.0, dtype=torch.double)\n",
    "\n",
    "x_fin = torch.tensor(199, dtype=torch.double)\n",
    "y_fin = torch.tensor(193.0, dtype=torch.double)\n",
    "\n",
    "x_fin = torch.tensor(238, dtype=torch.double)\n",
    "y_fin = torch.tensor(139.0-6.0, dtype=torch.double)\n",
    "\n",
    "# x_init = 0.0\n",
    "# y_init = 0.0\n",
    "\n",
    "# x_fin = 40\n",
    "# y_fin = 30.0\n",
    "\n",
    "\n",
    "v_init = torch.tensor(20.0, dtype=torch.double)\n",
    "v_fin =  torch.tensor(16.0, dtype=torch.double)\n",
    "\n",
    "\n",
    "vdot_init = torch.tensor(0.0, dtype=torch.double)\n",
    "vdot_fin = torch.tensor(0.0, dtype=torch.double)\n",
    "\n",
    "psi_init = torch.tensor(0.0, dtype=torch.double)\n",
    "psidot_init = torch.tensor(0.0, dtype=torch.double)\n",
    "psiddot_init = torch.tensor(0.0, dtype=torch.double)\n",
    "\n",
    "\n",
    "psi_fin = torch.tensor(-91*np.pi/180, dtype=torch.double)\n",
    "psidot_fin = torch.tensor(0.0, dtype=torch.double)\n",
    "psiddot_fin = torch.tensor(0.0, dtype=torch.double)\n",
    "\n",
    "x_mid = np.hstack(( 162, 198, 228))\n",
    "y_mid = np.hstack(( 202, 193, 170))\n",
    "x_mid = torch.tensor(x_mid, dtype=torch.double)\n",
    "y_mid = torch.tensor(y_mid, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 100\n",
    "nvar = 11\n",
    "node = OPTNode()\n",
    "v = v_init*np.ones(num)\n",
    "psi = psi_init*np.ones(num)\n",
    "lamda_wc = torch.zeros(nvar)\n",
    "lamda_ws = torch.zeros(nvar)\n",
    "lamda_psi = torch.zeros(nvar)\n",
    "lamda_v = torch.zeros(nvar)\n",
    "b_eq_psi = np.hstack((psi_init, psidot_init, psi_fin, psidot_fin))\n",
    "b_eq_psi = torch.tensor(b_eq_psi, dtype=torch.double)\n",
    "\n",
    "wc, ws, c_wc_psi, c_ws_psi = node.compute_w_psi(x_init, y_init, x_fin, y_fin, x_mid, y_mid, psi, v, lamda_wc, lamda_ws)\n",
    "psi, c_psi, res_psi, res_eq_psi, lamda_psi = node.compute_psi(wc, ws, b_eq_psi, lamda_psi)\n",
    "c_v, lamda_v, v = node.compute_v(v_init, x_init, x_fin, x_mid, y_mid, psi, lamda_v)\n",
    "\n",
    "b = torch.hstack((x_init, y_init, x_fin, y_fin, v_init, v_fin, psi_init, psidot_init, psi_fin, psidot_fin, x_mid, y_mid)).unsqueeze(1).transpose(0, 1)\n",
    "# res, _ = node.solve(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-2c91ad8ba0ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/core/home/R/goal/code/./ddn/ddn/pytorch/node.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, y, v, ctx, *xs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mfY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfYY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfXY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_objective_derivatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_optimality_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/core/home/R/goal/code/./ddn/ddn/pytorch/node.py\u001b[0m in \u001b[0;36m_get_objective_derivatives\u001b[0;34m(self, xs, y)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# Compute partial derivative of f wrt y at (xs,y):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mfY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mfY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# bxm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if fY is independent of y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         inputs, allow_unused, accumulate_grad=False)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "node.gradient(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "primal_sol = node.optimize(x_init, y_init, x_fin, y_fin, v_init, v_fin, psi_init, psidot_init, psi_fin, psidot_fin, x_mid, y_mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-9c1804b10436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimal_sol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(np.array(x), dtype=torch.double)\n",
    "y = torch.tensor(np.array(y), dtype=torch.double)\n",
    "print(torch.linalg.norm(res[0, :100]-x), torch.linalg.norm(res[0, 100:]-y))\n",
    "print(node.objective(b, primal_sol, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
