{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2daa20f-69c5-45d1-886b-70024a51d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"./ddn\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.bernstein import bernstein_coeff_order10_new\n",
    "from ddn.pytorch.node import AbstractDeclarativeNode\n",
    "\n",
    "#from OPTNode import OPTNode\n",
    "from utils.dataloader import ArgoverseDataset\n",
    "\n",
    "#from models import TrajNet, TrajNetLSTM, TrajNetLSTMSimple\n",
    "from utils.bernstein import bernstein_coeff_order10_new\n",
    "from utils.viz_helpers import plot_traj, plot_trajj\n",
    "from utils.metrics import get_ade, get_fde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf5adf67-9ca7-4234-9631-26ac4a974163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680626bd-6744-4cf2-b32d-8684b7d21671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPTNode(AbstractDeclarativeNode):\n",
    "    def __init__(self, rho_eq=1.0, rho_goal=1.0, rho_nonhol=1.0, rho_psi=1.0, maxiter=500, weight_smoothness=1.0, weight_smoothness_psi=1.0, t_fin=2.0, num=30, device=device):\n",
    "        super().__init__()\n",
    "        self.rho_eq = rho_eq\n",
    "        self.rho_goal = rho_goal\n",
    "        self.rho_nonhol = rho_nonhol\n",
    "        self.rho_psi = rho_psi\n",
    "        self.maxiter = maxiter\n",
    "        self.weight_smoothness = weight_smoothness\n",
    "        self.weight_smoothness_psi = weight_smoothness_psi\n",
    "        self.device = device\n",
    "        \n",
    "        self.t_fin = t_fin\n",
    "        self.num = num\n",
    "        self.t = self.t_fin / self.num\n",
    "\n",
    "        #self.num_batch = 10\n",
    "        \n",
    "        tot_time = np.linspace(0.0, self.t_fin, self.num)\n",
    "        tot_time_copy = tot_time.reshape(self.num, 1)\n",
    "        self.P, self.Pdot, self.Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "        self.nvar = np.shape(self.P)[1]\n",
    "        \n",
    "        self.cost_smoothness = self.weight_smoothness * np.dot(self.Pddot.T, self.Pddot)\n",
    "        self.cost_smoothness_psi = self.weight_smoothness_psi * np.dot(self.Pddot.T, self.Pddot)\n",
    "        self.lincost_smoothness_psi = np.zeros(self.nvar)\n",
    "\n",
    "        self.A_eq = np.vstack((self.P[0], self.P[-1]))\n",
    "        self.A_eq_psi = np.vstack((self.P[0], self.Pdot[0], self.P[-1]))\n",
    "        \n",
    "        self.P = torch.tensor(self.P, dtype=torch.double).to(device)\n",
    "        self.Pdot = torch.tensor(self.Pdot, dtype=torch.double).to(device)\n",
    "        self.Pddot = torch.tensor(self.Pddot, dtype=torch.double).to(device)\n",
    "        self.A_eq = torch.tensor(self.A_eq, dtype=torch.double).to(device)        \n",
    "        self.A_eq_psi = torch.tensor(self.A_eq_psi, dtype=torch.double).to(device)\n",
    "        self.cost_smoothness = torch.tensor(self.cost_smoothness, dtype=torch.double).to(device)\n",
    "        self.cost_smoothness_psi = torch.tensor(self.cost_smoothness_psi, dtype=torch.double).to(device)\n",
    "        self.lincost_smoothness_psi = torch.tensor(self.lincost_smoothness_psi, dtype=torch.double).to(device)\n",
    "    \n",
    "        self.A_nonhol = self.Pdot\n",
    "        self.A_psi = self.P\n",
    "        \n",
    "        self.lamda_x = None\n",
    "        self.lamda_y = None\n",
    "        self.lamda_psi = None\n",
    "        \n",
    "    def compute_x(self, v, psi, b_eq_x, b_eq_y):\n",
    "        b_nonhol_x = v * torch.cos(psi)\n",
    "        b_nonhol_y = v * torch.sin(psi)\n",
    "    \n",
    "        cost = self.cost_smoothness + self.rho_nonhol * torch.matmul(self.A_nonhol.T, self.A_nonhol) + self.rho_eq * torch.matmul(self.A_eq.T, self.A_eq)\n",
    "        lincost_x = -self.lamda_x - self.rho_nonhol * torch.matmul(self.A_nonhol.T, b_nonhol_x.T).T - self.rho_eq * torch.matmul(self.A_eq.T, b_eq_x.T).T\n",
    "        lincost_y = -self.lamda_y - self.rho_nonhol * torch.matmul(self.A_nonhol.T, b_nonhol_y.T).T - self.rho_eq * torch.matmul(self.A_eq.T, b_eq_y.T).T\n",
    "\n",
    "        cost_inv = torch.linalg.inv(cost)\n",
    "\n",
    "        sol_x = torch.matmul(-cost_inv, lincost_x.T).T\n",
    "        sol_y = torch.matmul(-cost_inv, lincost_y.T).T\n",
    "\n",
    "        x = torch.matmul(self.P, sol_x.T).T\n",
    "        xdot = torch.matmul(self.Pdot, sol_x.T).T\n",
    "\n",
    "        y = torch.matmul(self.P, sol_y.T).T\n",
    "        ydot = torch.matmul(self.Pdot, sol_y.T).T\n",
    "         \n",
    "        return sol_x, sol_y, x, xdot, y, ydot\n",
    "    \n",
    "    def compute_psi(self, psi, lamda_psi, psi_temp, b_eq_psi):\n",
    "        cost = self.cost_smoothness_psi + self.rho_psi * torch.matmul(self.A_psi.T, self.A_psi) + self.rho_eq * torch.matmul(self.A_eq_psi.T, self.A_eq_psi)\n",
    "        lincost_psi = -self.lamda_psi - self.rho_psi * torch.matmul(self.A_psi.T, psi_temp.T).T - self.rho_eq * torch.matmul(self.A_eq_psi.T, b_eq_psi.T).T\n",
    "\n",
    "        cost_inv = torch.linalg.inv(cost)\n",
    "\n",
    "        sol_psi = torch.matmul(-cost_inv, lincost_psi.T).T\n",
    "\n",
    "        psi = torch.matmul(self.P, sol_psi.T).T\n",
    "\n",
    "        res_psi = torch.matmul(self.A_psi, sol_psi.T).T - psi_temp\n",
    "        res_eq_psi = torch.matmul(self.A_eq_psi, sol_psi.T).T - b_eq_psi\n",
    "\n",
    "        self.lamda_psi = self.lamda_psi - self.rho_psi * torch.matmul(self.A_psi.T, res_psi.T).T - self.rho_eq * torch.matmul(self.A_eq_psi.T, res_eq_psi.T).T\n",
    "\n",
    "        return sol_psi, torch.linalg.norm(res_psi), torch.linalg.norm(res_eq_psi), psi\n",
    "\n",
    "    \n",
    "    def solve(self, fixed_params, variable_params):\n",
    "        batch_size, _ = fixed_params.size()\n",
    "        x_init, y_init, v_init, psi_init, psidot_init = torch.chunk(fixed_params, 5, dim=1)\n",
    "        x_fin, y_fin, psi_fin = torch.chunk(variable_params, 3, dim=1)\n",
    "        \n",
    "        b_eq_x = torch.cat((x_init, x_fin), dim=1)\n",
    "        b_eq_y = torch.cat((y_init, y_fin), dim=1)\n",
    "        b_eq_psi = torch.cat((psi_init, psidot_init, psi_fin), dim=1)\n",
    "        \n",
    "        v = torch.ones(batch_size, self.num, dtype=torch.double).to(self.device) * v_init\n",
    "        psi = torch.ones(batch_size, self.num, dtype=torch.double).to(self.device) * psi_init\n",
    "        xdot = v * torch.cos(psi)\n",
    "        ydot = v * torch.sin(psi)\n",
    "        \n",
    "        self.lamda_x = torch.zeros(batch_size, self.nvar, dtype=torch.double).to(self.device)\n",
    "        self.lamda_y = torch.zeros(batch_size, self.nvar, dtype=torch.double).to(self.device)\n",
    "        self.lamda_psi = torch.zeros(batch_size, self.nvar, dtype=torch.double).to(self.device)\n",
    "        \n",
    "        res_psi_arr = []\n",
    "        res_eq_psi_arr = []\n",
    "        res_eq_arr = []\n",
    "        res_nonhol_arr = []\n",
    "        for i in range(0, self.maxiter):\n",
    "            psi_temp = torch.atan2(ydot, xdot)\n",
    "            c_psi, res_psi, res_eq_psi, psi = self.compute_psi(psi, self.lamda_psi, psi_temp, b_eq_psi)\n",
    "            c_x, c_y, x, xdot, y, ydot = self.compute_x(v, psi, b_eq_x, b_eq_y)\n",
    "            \n",
    "            res_eq_psi_arr.append(res_eq_psi)\n",
    "            res_psi_arr.append(res_psi)\n",
    "            v = torch.sqrt(xdot ** 2 + ydot ** 2)\n",
    "            #v[:, 0] = v_init[:, 0]\n",
    "\n",
    "            res_eq_x = torch.matmul(self.A_eq, c_x.T).T - b_eq_x\n",
    "            res_nonhol_x = xdot - v * torch.cos(psi)\n",
    "\n",
    "            res_eq_y = torch.matmul(self.A_eq, c_y.T).T - b_eq_y\n",
    "            res_nonhol_y = ydot - v * torch.sin(psi)\n",
    "\n",
    "            res_eq_arr.append(torch.linalg.norm(torch.sqrt(res_eq_x**2 + res_eq_y**2)))\n",
    "            res_nonhol_arr.append(torch.linalg.norm(torch.sqrt(res_nonhol_x**2 + res_nonhol_y**2)))\n",
    "            \n",
    "            self.lamda_x = self.lamda_x - self.rho_eq * torch.matmul(self.A_eq.T, res_eq_x.T).T - self.rho_nonhol * torch.matmul(self.A_nonhol.T, res_nonhol_x.T).T\n",
    "            self.lamda_y = self.lamda_y - self.rho_eq * torch.matmul(self.A_eq.T, res_eq_y.T).T - self.rho_nonhol * torch.matmul(self.A_nonhol.T, res_nonhol_y.T).T\n",
    "        \n",
    "        primal_sol = torch.hstack((c_x, c_y, c_psi, v))\n",
    "        return primal_sol, None\n",
    "    \n",
    "    def objective(self, fixed_params, variable_params, y):\n",
    "        c_x = y[:, :self.nvar]\n",
    "        c_y = y[:, self.nvar:2*self.nvar]\n",
    "        c_psi = y[:, 2*self.nvar:3*self.nvar]\n",
    "        v = y[:, 3*self.nvar:]\n",
    "        \n",
    "        x_init, y_init, v_init, psi_init, psidot_init = torch.chunk(fixed_params, 5, dim=1)\n",
    "        x_fin, y_fin, psi_fin = torch.chunk(variable_params, 3, dim=1)\n",
    "        \n",
    "        x = torch.matmul(self.P, c_x.T).T\n",
    "        y = torch.matmul(self.P, c_y.T).T\n",
    "        psi = torch.matmul(self.P, c_psi.T).T\n",
    "        xdot = torch.matmul(self.Pdot, c_x.T).T\n",
    "        ydot = torch.matmul(self.Pdot, c_y.T).T\n",
    "        psidot = torch.matmul(self.Pdot, c_psi.T).T\n",
    "        xddot = torch.matmul(self.Pddot, c_x.T).T\n",
    "        yddot = torch.matmul(self.Pddot, c_y.T).T\n",
    "        psiddot = torch.matmul(self.Pddot, c_psi.T).T\n",
    "        \n",
    "        cost_nonhol = 0.5*self.rho_nonhol*torch.sum((xdot - v*torch.cos(psi)) ** 2, 1) + 0.5*self.rho_nonhol*torch.sum((ydot - v*torch.sin(psi)) ** 2, 1)\n",
    "        cost_pos = 0.5*self.rho_eq*(torch.sum((x[:, -1] - x_fin) ** 2, 1) + torch.sum((y[:, -1] - y_fin) ** 2, 1) + torch.sum((x[:, 0] - x_init) ** 2, 1) + torch.sum((y[:, 0] - y_init) ** 2, 1))\n",
    "        cost_psi = 0.5*self.rho_eq*(torch.sum((psi[:, -1] - psi_fin) ** 2, 1) + torch.sum((psi[:, 0] - psi_init) ** 2, 1)\n",
    "                                    + torch.sum((psidot[:, 0] - psidot_init) ** 2, 1))\n",
    "        #cost_v = 0.5*self.rho_eq*torch.sum((v[:, 0] - v_init) ** 2, 1)\n",
    "        cost_cancel = torch.diagonal(torch.matmul(-self.lamda_x, c_x.T) + torch.matmul(-self.lamda_y, c_y.T) + torch.matmul(-self.lamda_psi, c_psi.T))\n",
    "        \n",
    "        cost_smoothness = 0.5*self.weight_smoothness*(torch.sum(xddot**2, 1) + torch.sum(yddot**2, 1)) + 0.5*self.weight_smoothness_psi*torch.sum(psiddot**2, 1)\n",
    "        return cost_nonhol + cost_pos + cost_psi + cost_smoothness + cost_cancel #+ cost_v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eeb4f99-364e-4917-a14a-cb150a94984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeclarativeFunction(torch.autograd.Function):\n",
    "    \"\"\"Generic declarative autograd function.\n",
    "    Defines the forward and backward functions. Saves all inputs and outputs,\n",
    "    which may be memory-inefficient for the specific problem.\n",
    "    \n",
    "    Assumptions:\n",
    "    * All inputs are PyTorch tensors\n",
    "    * All inputs have a single batch dimension (b, ...)\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, problem, *inputs):\n",
    "        output, solve_ctx = torch.no_grad()(problem.solve)(*inputs)\n",
    "        ctx.save_for_backward(output, *inputs)\n",
    "        ctx.problem = problem\n",
    "        ctx.solve_ctx = solve_ctx\n",
    "        return output.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output, *inputs = ctx.saved_tensors\n",
    "        problem = ctx.problem\n",
    "        solve_ctx = ctx.solve_ctx\n",
    "        output.requires_grad = True\n",
    "        inputs = tuple(inputs)\n",
    "        grad_inputs = problem.gradient(*inputs, y=output, v=grad_output,\n",
    "            ctx=solve_ctx)\n",
    "        return (None, *grad_inputs)\n",
    "\n",
    "\n",
    "class DeclarativeLayer(torch.nn.Module):\n",
    "    \"\"\"Generic declarative layer.\n",
    "    \n",
    "    Assumptions:\n",
    "    * All inputs are PyTorch tensors\n",
    "    * All inputs have a single batch dimension (b, ...)\n",
    "    Usage:\n",
    "        problem = <derived class of *DeclarativeNode>\n",
    "        declarative_layer = DeclarativeLayer(problem)\n",
    "        y = declarative_layer(x1, x2, ...)\n",
    "    \"\"\"\n",
    "    def __init__(self, problem):\n",
    "        super(DeclarativeLayer, self).__init__()\n",
    "        self.problem = problem\n",
    "        \n",
    "    def forward(self, *inputs):\n",
    "        return DeclarativeFunction.apply(self.problem, *inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80f18d9a-f3bb-48c1-88c9-b09d9d03275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajNetLSTMFinalPred(nn.Module):\n",
    "    def __init__(self, opt_layer, P, Pdot, input_size=40, hidden_size=64, output_size=3, nvar=11, t_obs=8):\n",
    "        super(TrajNetLSTM2, self).__init__()\n",
    "        self.nvar = nvar\n",
    "        self.t_obs = t_obs\n",
    "        self.P = torch.tensor(P, dtype=torch.double).to(device)\n",
    "        self.Pdot = torch.tensor(Pdot, dtype=torch.double).to(device) \n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size + 1)\n",
    "        self.opt_layer = opt_layer\n",
    "        self.activation = nn.PReLU()\n",
    "        self.mask = torch.tensor([[0.0, 0.0, 1.0]], dtype=torch.double).to(device)\n",
    "    \n",
    "    def forward(self, x, fixed_params, var_inp):\n",
    "        batch_size = x.shape[0]\n",
    "        out = self.activation(self.linear1(x))\n",
    "        _, (hn, cn) = self.lstm(out.view(batch_size, 1, -1))\n",
    "        out = self.activation(self.linear2(hn[0]))\n",
    "        variable_params = self.linear3(out)\n",
    "        theta = torch.atan2(variable_params[:, 3] - variable_params[:, 1], variable_params[:, 2] - variable_params[:, 0])\n",
    "        variable_params = torch.cat((variable_params[:,:2], theta.reshape(theta.shape[0], 1)), dim=1)\n",
    "        \n",
    "#         variable_params = self.mask * var_inp + (1-self.mask) * variable_params\n",
    "        \n",
    "        # Run optimization\n",
    "        sol = self.opt_layer(fixed_params, variable_params)\n",
    "         \n",
    "        # Compute final trajectory\n",
    "        x_pred = torch.matmul(self.P, sol[:, :self.nvar].transpose(0, 1))\n",
    "        y_pred = torch.matmul(self.P, sol[:, self.nvar:2*self.nvar].transpose(0, 1))\n",
    "        x_pred = x_pred.transpose(0, 1)\n",
    "        y_pred = y_pred.transpose(0, 1)\n",
    "        out = torch.cat([x_pred, y_pred], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e3653ef-e6a8-4bff-a021-41ba7ec774be",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 30\n",
    "t_obs = 20\n",
    "num_elems = 15\n",
    "include_centerline = False\n",
    "name = \"final_without\" if include_centerline else \"final_with\"\n",
    "lr = 0.0005\n",
    "\n",
    "train_dataset = ArgoverseDataset(\"/datasets/argoverse/val_data.npy\", centerline_dir=\"val_centerlines.npy\", t_obs=20, dt=0.3, include_centerline = include_centerline)\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=False, num_workers=0)\n",
    "\n",
    "# test_dataset = ArgoverseDataset(\"val_test_data.npy\", centerline_dir=\"val_test_centerlines.npy\", t_obs=20, dt=0.3, include_centerline = include_centerline)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=0)\n",
    "\n",
    "offsets_train = np.load(\"/datasets/argoverse/val_offsets.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f519a56e-adca-4f80-86cb-94f7c7c57f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 40]) torch.Size([20, 60]) torch.Size([20, 5]) torch.Size([20, 3])\n"
     ]
    }
   ],
   "source": [
    "for batch_num, data in enumerate(train_loader):\n",
    "    traj_inp, traj_out, fixed_params, var_inp = data\n",
    "    print(traj_inp.size(), traj_out.shape, fixed_params.shape, var_inp.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ab604e7-f8fa-45f2-87f6-4dd99f9ba69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = OPTNode(rho_eq=10, t_fin=9.0, num=num)\n",
    "opt_layer = DeclarativeLayer(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "850d6dcc-474e-4c76-8f61-c571eb6382a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"LSTM\"\n",
    "\n",
    "if model_type == \"MLP\":\n",
    "    Model = TrajNet\n",
    "    model = Model(opt_layer, problem.P, problem.Pdot, input_size=t_obs * 2 + include_centerline * num_elems * 2)\n",
    "else:\n",
    "    Model = TrajNetLSTMFinalPred\n",
    "    model = Model(opt_layer, problem.P, problem.Pdot)\n",
    "\n",
    "# if flatten:\n",
    "    \n",
    "#     model = Model(opt_layer, problem.P, problem.Pdot, input_size=t_obs * 2 + include_centerline * num_elems * 2)\n",
    "# else:\n",
    "#     model = Model(opt_layer, problem.P, problem.Pdot)\n",
    "    \n",
    "model = model.double()\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb151f6e-d401-40dc-ace7-6bd06af00348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 383.120501868299\n",
      "Epoch: 0, Batch: 20, Loss: 504.3867598757597\n",
      "Epoch: 0, Batch: 40, Loss: 482.2121930018844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-857a85a658d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# fde = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(traj_inp.shape, traj_out.shape, fixed_params.shape, var_inp.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-470644217e2a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, fixed_params, var_inp)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Run optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Compute final trajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-dccdcade765e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDeclarativeFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-dccdcade765e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, problem, *inputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolve_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c5a24e4c9836>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, fixed_params, variable_params)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mpsi_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matan2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxdot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mc_psi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_psi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_eq_psi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_psi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda_psi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_eq_psi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mc_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxdot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_eq_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_eq_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c5a24e4c9836>\u001b[0m in \u001b[0;36mcompute_psi\u001b[0;34m(self, psi, lamda_psi, psi_temp, b_eq_psi)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_psi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda_psi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_eq_psi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_smoothness_psi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho_psi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_psi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_psi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho_eq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_eq_psi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_eq_psi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mlincost_psi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda_psi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho_psi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_psi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho_eq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_eq_psi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_eq_psi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_train_loss = []\n",
    "num_epochs = 600\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    # mean_ade = []\n",
    "    # mean_fde = []    \n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        traj_inp, traj_out, fixed_params, var_inp = data\n",
    "        traj_inp = traj_inp.to(device)\n",
    "        traj_out = traj_out.to(device)\n",
    "        fixed_params = fixed_params.to(device)\n",
    "        var_inp = var_inp.to(device)\n",
    "\n",
    "        # ade = []\n",
    "        # fde = []       \n",
    "        #print(traj_inp.shape, traj_out.shape, fixed_params.shape, var_inp.shape)\n",
    "        out = model(traj_inp, fixed_params, var_inp)\n",
    "        loss = criterion(out, traj_out)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "#         for ii in range(traj_inp.size()[0]):\n",
    "#             gt = [[out[ii][j],out[ii][j + num]] for j in range(len(out[ii])//2)]\n",
    "# #             print(out[ii][0])\n",
    "#             pred = [[traj_out[ii][j],traj_out[ii][j + num]] for j in range(len(out[ii])//2)]\n",
    "#             ade.append(get_ade(np.array(pred), np.array(gt)))\n",
    "#             fde.append(get_fde(np.array(pred), np.array(gt)))                        \n",
    "#             #plot_traj(ii, traj_inp[ii], traj_out[ii], out[ii], {\"x\": [], \"y\": []}, offsets=offsets_train, cities = [], avm=None, center=include_centerline, inp_len=t_obs * 2, c_len = t_obs * 2 + num_elems * 2, num=num, mode=\"test\", batch_num=batch_num)\n",
    "        if batch_num % 20 == 0:\n",
    "            print(\"Epoch: {}, Batch: {}, Loss: {}\".format(epoch, batch_num, loss.item()))\n",
    "            #print(\"ADE: {}\".format(np.mean(ade)), \"FDE: {}\".format(np.mean(fde)))\n",
    "    \n",
    "        # mean_ade.append(np.mean(ade))\n",
    "        # mean_fde.append(np.mean(fde))\n",
    "    \n",
    "    mean_loss = np.mean(train_loss)\n",
    "    epoch_train_loss.append(mean_loss)\n",
    "    #torch.save(model.state_dict(), \"./checkpoints/{}.ckpt\".format(name))\n",
    "    print(\"Epoch: {}, Mean Loss: {}\".format(epoch, mean_loss))\n",
    "    #print(\"Mean ADE: {}\".format(np.mean(mean_ade)), \"Mean FDE: {}\".format(np.mean(mean_fde)))\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce1b9f92-8052-4461-b9b5-30d4241939bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lstmv2_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
