{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd6f02c-1ba4-44ed-82c4-9d09f3f05e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"./ddn/\")\n",
    "sys.path.append(\"./\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "from ddn.ddn.pytorch.node import AbstractDeclarativeNode\n",
    "# from utils.bernstein import bernstein_coeff_order10_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19fcd8eb-1e48-4d58-ba3c-8ea55a1fc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.special import binom\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "def bernstein_coeff_order10_new(n, tmin, tmax, t_actual):\n",
    "    \n",
    "    l = tmax-tmin\n",
    "    t = (t_actual-tmin)/l\n",
    "    \n",
    "    P0 = binom(n,0)*((1-t)**(n-0))*t**0\n",
    "    P1 = binom(n,1)*((1-t)**(n-1))*t**1                     \n",
    "    P2 = binom(n,2)*((1-t)**(n-2))*t**2\n",
    "    P3 = binom(n,3)*((1-t)**(n-3))*t**3                        \n",
    "    P4 = binom(n,4)*((1-t)**(n-4))*t**4                    \n",
    "    P5 = binom(n,5)*((1-t)**(n-5))*t**5\n",
    "    P6 = binom(n,6)*((1-t)**(n-6))*t**6\n",
    "    P7 = binom(n,7)*((1-t)**(n-7))*t**7\n",
    "    P8 = binom(n,8)*((1-t)**(n-8))*t**8\n",
    "    P9 = binom(n,9)*((1-t)**(n-9))*t**9\n",
    "    P10 = binom(n,10)*((1-t)**(n-10))*t**10\n",
    "    \n",
    "    P0dot = -10.0*(-t + 1)**9\n",
    "    P1dot = -90.0*t*(-t + 1)**8 + 10.0*(-t + 1)**9\n",
    "    P2dot = -360.0*t**2*(-t + 1)**7 + 90.0*t*(-t + 1)**8\n",
    "    P3dot = -840.0*t**3*(-t + 1)**6 + 360.0*t**2*(-t + 1)**7\n",
    "    P4dot = -1260.0*t**4*(-t + 1)**5 + 840.0*t**3*(-t + 1)**6\n",
    "    P5dot = -1260.0*t**5*(-t + 1)**4 + 1260.0*t**4*(-t + 1)**5\n",
    "    P6dot = -840.0*t**6*(-t + 1)**3 + 1260.0*t**5*(-t + 1)**4\n",
    "    P7dot = -360.0*t**7*(-t + 1)**2 + 840.0*t**6*(-t + 1)**3\n",
    "    P8dot = 45.0*t**8*(2*t - 2) + 360.0*t**7*(-t + 1)**2\n",
    "    P9dot = -10.0*t**9 + 9*t**8*(-10.0*t + 10.0)\n",
    "    P10dot = 10.0*t**9\n",
    "    \n",
    "    P0ddot = 90.0*(-t + 1)**8\n",
    "    P1ddot = 720.0*t*(-t + 1)**7 - 180.0*(-t + 1)**8\n",
    "    P2ddot = 2520.0*t**2*(-t + 1)**6 - 1440.0*t*(-t + 1)**7 + 90.0*(-t + 1)**8\n",
    "    P3ddot = 5040.0*t**3*(-t + 1)**5 - 5040.0*t**2*(-t + 1)**6 + 720.0*t*(-t + 1)**7\n",
    "    P4ddot = 6300.0*t**4*(-t + 1)**4 - 10080.0*t**3*(-t + 1)**5 + 2520.0*t**2*(-t + 1)**6\n",
    "    P5ddot = 5040.0*t**5*(-t + 1)**3 - 12600.0*t**4*(-t + 1)**4 + 5040.0*t**3*(-t + 1)**5\n",
    "    P6ddot = 2520.0*t**6*(-t + 1)**2 - 10080.0*t**5*(-t + 1)**3 + 6300.0*t**4*(-t + 1)**4\n",
    "    P7ddot = -360.0*t**7*(2*t - 2) - 5040.0*t**6*(-t + 1)**2 + 5040.0*t**5*(-t + 1)**3\n",
    "    P8ddot = 90.0*t**8 + 720.0*t**7*(2*t - 2) + 2520.0*t**6*(-t + 1)**2\n",
    "    P9ddot = -180.0*t**8 + 72*t**7*(-10.0*t + 10.0)\n",
    "    P10ddot = 90.0*t**8\n",
    "    \n",
    "    P = torch.hstack((P0, P1, P2, P3, P4, P5, P6, P7, P8, P9, P10 ))    \n",
    "    Pdot = torch.hstack((P0dot, P1dot, P2dot, P3dot, P4dot, P5dot, P6dot, P7dot, P8dot, P9dot, P10dot ))/l\n",
    "    Pddot = torch.hstack((P0ddot, P1ddot, P2ddot, P3ddot, P4ddot, P5ddot, P6ddot, P7ddot, P8ddot, P9ddot, P10ddot ))/(l**2)\n",
    "    \n",
    "    return P, Pdot, Pddot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1db3b3d-27a6-48cc-998e-0f66af56e214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b47b636-902b-49fe-b559-1b2eca37269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDN QP\n",
    "class QPNode(AbstractDeclarativeNode):\n",
    "    def __init__(self, weight_smoothness, t_fin, num, num_batch, device=device):\n",
    "        super().__init__(eps=1e-6, gamma=6e-3, chunk_size=None)\n",
    "        \n",
    "        # Initialization\n",
    "        self.weight_smoothness = weight_smoothness\n",
    "        self.num = num\n",
    "        self.t_fin = t_fin\n",
    "        self.t = self.t_fin / self.num\n",
    "        self.num_batch = num_batch  # number of goals\n",
    "        \n",
    "        tot_time = torch.linspace(0, t_fin, num, device=device)\n",
    "        tot_time_copy = tot_time.reshape(num, 1)\n",
    "        \n",
    "        self.tot_time = tot_time\n",
    "        \n",
    "        self.P, self.Pdot, self.Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "        print(self.P.shape)\n",
    "        self.P_torch, self.Pdot_torch, self.Pddot_torch = self.P.to(device), self.Pdot.to(device), self.Pddot.to(device)\n",
    "        \n",
    "        self.nvar = self.P_torch.shape[1] - 3\n",
    "        \n",
    "        self.P_offset = self.P_torch[:, 0:3]\n",
    "        self.Pdot_offset = self.Pdot_torch[:, 0:3]\n",
    "        self.Pddot_offset = self.Pddot_torch[:, 0:3]\n",
    "        \n",
    "        self.P_bar = self.P_torch[:, 3:]\n",
    "        self.Pdot_bar = self.Pdot_torch[:, 3:]\n",
    "        self.Pddot_bar = self.Pddot_torch[:, 3:]\n",
    "\n",
    "        self.A_goal = torch.vstack([self.P_bar[-1], self.Pdot_bar[-1], self.Pddot_bar[-1]])\n",
    "        print(self.A_goal.shape)\n",
    "        self.Q_smoothness = self.weight_smoothness * torch.mm(self.Pddot_bar.T, self.Pddot_bar)\n",
    "        self.Q_goal = torch.mm(self.A_goal.T, self.A_goal)\n",
    "\n",
    "    def objective(self, b_goal_state, y):\n",
    "        \n",
    "        c_x = y[:, 0:self.nvar]\n",
    "        c_y = y[:, self.nvar:2 * self.nvar]\n",
    "                \n",
    "        x_f, y_f, vx_f, vy_f, ax_f, ay_f = [b_goal_state[:, i] for i in range(b_goal_state.shape[1])]\n",
    "        \n",
    "        x = torch.mm(self.P_bar, c_x.T).T + self.x_offset\n",
    "        vx = torch.mm(self.Pdot_bar, c_x.T).T + self.vx_offset\n",
    "        ax = torch.mm(self.Pddot_bar, c_x.T).T + self.ax_offset\n",
    "\n",
    "        y = torch.mm(self.P_bar, c_y.T).T + self.y_offset\n",
    "        vy = torch.mm(self.Pdot_bar, c_y.T).T + self.vy_offset\n",
    "        ay = torch.mm(self.Pddot_bar, c_y.T).T + self.ay_offset\n",
    "        \n",
    "        # Cost function\n",
    "        cost = 0.5 * self.weight_smoothness * (torch.sum(ax ** 2, 1) + torch.sum(ay ** 2 , 1)) + \\\n",
    "               0.5 * ( (x[:, -1] - x_f) ** 2 + (vx[:, -1] - vx_f) ** 2 + (ax[:, -1] - ax_f) ** 2 + \\\n",
    "                       (y[:, -1] - y_f) ** 2 + (vy[:, -1] - vy_f) ** 2 + (ay[:, -1] - ay_f) ** 2)\n",
    "\n",
    "        return cost\n",
    "\n",
    "    def solve(self, fixed_params, b_pred):\n",
    "                        \n",
    "        x_init, y_init, vx_init, vy_init, ax_init, ay_init = [fixed_params[:, i] for i in range(fixed_params.shape[1])]\n",
    "        x_f, y_f, vx_f, vy_f, ax_f, ay_f = [b_pred[:, i] for i in range(b_pred.shape[1])]\n",
    "                \n",
    "        P_00 = self.P_torch[0, 0]\n",
    "        P_01 = self.P_torch[0, 1]\n",
    "        P_02 = self.P_torch[0, 2]\n",
    "\n",
    "        Pdot_00 = self.Pdot_torch[0, 0]\n",
    "        Pdot_01 = self.Pdot_torch[0, 1]\n",
    "        Pdot_02 = self.Pdot_torch[0, 2]\n",
    "\n",
    "        Pddot_00 = self.Pddot_torch[0, 0]\n",
    "        Pddot_01 = self.Pddot_torch[0, 1]\n",
    "        Pddot_02 = self.Pddot_torch[0, 2]\n",
    "\n",
    "        cx_1 = x_init\n",
    "        cx_2 = (vx_init - cx_1 * Pdot_00) / Pdot_01\n",
    "        cx_3 = (ax_init - cx_1 * Pddot_00 - cx_2 * Pddot_01) / Pddot_02\n",
    "\n",
    "        cy_1 = y_init\n",
    "        cy_2 = (vy_init - cy_1 * Pdot_00) / Pdot_01\n",
    "        cy_3 = (ay_init - cy_1 * Pddot_00 - cy_2 * Pddot_01) / Pddot_02\n",
    "\n",
    "        cx_offset = torch.vstack((cx_1, cx_2, cx_3)).T\n",
    "        cy_offset = torch.vstack((cy_1, cy_2, cy_3)).T\n",
    "\n",
    "        self.x_offset = torch.mm(self.P_offset, cx_offset.T ).T\n",
    "        self.vx_offset  = torch.mm(self.Pdot_offset, cx_offset.T ).T\n",
    "        self.ax_offset = torch.mm(self.Pddot_offset, cx_offset.T ).T\n",
    "\n",
    "        self.y_offset = torch.mm(self.P_offset, cy_offset.T ).T\n",
    "        self.vy_offset  = torch.mm(self.Pdot_offset, cy_offset.T ).T\n",
    "        self.ay_offset = torch.mm(self.Pddot_offset, cy_offset.T ).T\n",
    "\n",
    "        b_x_goal = (- self.x_offset[:, -1] + x_f).reshape(self.num_batch, 1)\n",
    "        b_y_goal = (- self.y_offset[:, -1] + y_f).reshape(self.num_batch, 1)\n",
    "\n",
    "        b_vx_goal = (- self.vx_offset[:, -1] + vx_f).reshape(self.num_batch, 1)\n",
    "        b_vy_goal = (- self.vy_offset[:, -1] + vy_f).reshape(self.num_batch, 1)\n",
    "\n",
    "        b_ax_goal = (- self.ax_offset[:, -1] + ax_f).reshape(self.num_batch, 1)\n",
    "        b_ay_goal = (- self.ay_offset[:, -1] + ay_f).reshape(self.num_batch, 1)\n",
    "\n",
    "        b_goal_state_x = torch.hstack((b_x_goal, b_vx_goal, b_ax_goal))\n",
    "        b_goal_state_y = torch.hstack((b_y_goal, b_vy_goal, b_ay_goal))\n",
    "\n",
    "        q_x_smoothness = torch.mm(self.Pddot_bar.T, self.ax_offset.T).T \n",
    "        q_x_goal = - torch.mm(self.A_goal.T, b_goal_state_x.T).T \n",
    "        cost_x = self.Q_smoothness + self.Q_goal\n",
    "        lincost_x = q_x_smoothness + q_x_goal\n",
    "        sol_x = torch.linalg.solve(- cost_x, lincost_x.T).T\n",
    "    \n",
    "        q_y_smoothness = torch.mm(self.Pddot_bar.T, self.ay_offset.T).T \n",
    "        q_y_goal = - torch.mm(self.A_goal.T, b_goal_state_y.T).T \n",
    "        cost_y = self.Q_smoothness + self.Q_goal\n",
    "        lincost_y = q_y_smoothness + q_y_goal        \n",
    "        sol_y = torch.linalg.solve(- cost_y, lincost_y.T).T\n",
    "                \n",
    "        sol = torch.hstack([sol_x, sol_y])\n",
    "        \n",
    "        offset = torch.hstack([self.x_offset, self.y_offset])\n",
    "        \n",
    "        return sol, None, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8ac226d-fc25-4cf7-906d-3c5d50284c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QPFunction(torch.autograd.Function):\n",
    "    \"\"\"Generic declarative autograd function.\n",
    "    Defines the forward and backward functions. Saves all inputs and outputs,\n",
    "    which may be memory-inefficient for the specific problem.\n",
    "    \n",
    "    Assumptions:\n",
    "    * All inputs are PyTorch tensors\n",
    "    * All inputs have a single batch dimension (b, ...)\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, problem, *inputs):\n",
    "        output, solve_ctx, offset = torch.no_grad()(problem.solve)(*inputs)\n",
    "        ctx.save_for_backward(output, inputs[-1])\n",
    "        ctx.problem = problem\n",
    "        ctx.solve_ctx = solve_ctx\n",
    "        return output.clone(), offset.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output, offset):\n",
    "        output, inputs = ctx.saved_tensors\n",
    "        problem = ctx.problem\n",
    "        solve_ctx = ctx.solve_ctx\n",
    "        output.requires_grad = True\n",
    "        offset.requires_grad = False\n",
    "        # inputs = tuple(inputs)\n",
    "        grad_inputs = problem.gradient(inputs, y=output, v=grad_output,\n",
    "            ctx=solve_ctx)\n",
    "        return (None, None, *grad_inputs)\n",
    "    \n",
    "class DeclarativeLayer(torch.nn.Module):\n",
    "    \"\"\"Generic declarative layer.\n",
    "    \n",
    "    Assumptions:\n",
    "    * All inputs are PyTorch tensors\n",
    "    * All inputs have a single batch dimension (b, ...)\n",
    "    Usage:\n",
    "        problem = <derived class of *DeclarativeNode>\n",
    "        declarative_layer = DeclarativeLayer(problem)\n",
    "        y = declarative_layer(x1, x2, ...)\n",
    "    \"\"\"\n",
    "    def __init__(self, problem):\n",
    "        super(DeclarativeLayer, self).__init__()\n",
    "        self.problem = problem\n",
    "        \n",
    "    def forward(self, *inputs):\n",
    "        return QPFunction.apply(self.problem, *inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5562f01-eaf1-4f38-8c9d-5519c9e1d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevents NaN by torch.log(0)\n",
    "def torch_log(x):\n",
    "    return torch.log(torch.clamp(x, min = 1e-10))\n",
    "\n",
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # GRU\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size=input_size + output_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Regularization\n",
    "        self.bn = nn.BatchNorm1d(num_features=hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        \n",
    "        # Feed Forward Layer\n",
    "        self.linear1 = nn.Linear(hidden_size, 64)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        # Mean and Variance\n",
    "        self.mu = nn.Linear(64, z_dim)\n",
    "        self.var = nn.Linear(64, z_dim)\n",
    "        \n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "                \n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros((self.num_layers, batch_size, self.hidden_size), device=device, requires_grad=True)\n",
    "        \n",
    "        out, hn = self.gru(x.view(batch_size, 1, -1), (h0))\n",
    "        \n",
    "        out = self.activation(self.linear1(self.bn(hn[0])))\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        mu = self.mu(out)\n",
    "        var = self.var(out)\n",
    "        \n",
    "        return mu, self.softplus(var)\n",
    "    \n",
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, opt_layer, P, input_size, hidden_size, output_size, num_layers, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # GRU\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size=z_dim + input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Regularization\n",
    "        self.bn = nn.BatchNorm1d(num_features=hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        \n",
    "        # Feed Forward Layer\n",
    "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        # Optimization\n",
    "        self.P = P\n",
    "        self.opt_layer = opt_layer\n",
    "    \n",
    "    def forward(self, x, inputs):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros((self.num_layers, batch_size, self.hidden_size), device=device, requires_grad=True)\n",
    "        out, hn = self.gru(x.view(batch_size, 1, -1), (h0))\n",
    "        \n",
    "        out = self.activation(self.linear1(self.bn(hn[0])))\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        b_pred = self.linear2(out)\n",
    "        \n",
    "        # Run Optimization\n",
    "        sol, offset = self.opt_layer(inputs, b_pred)\n",
    "        \n",
    "        print(sol.shape, offset.shape)\n",
    "        # Compute final trajectory\n",
    "        x_traj_batch = torch.mm(self.P, sol[:, :8].T).T + offset[:, 0:12]\n",
    "        y_traj_batch = torch.mm(self.P, sol[:, 8:].T).T + offset[:, 12:]\n",
    "        traj = torch.hstack([x_traj_batch, y_traj_batch])\n",
    "        \n",
    "        return traj\n",
    "\n",
    "class GRU_cVAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GRU_cVAE, self).__init__()\n",
    "        \n",
    "        # Encoder & Decoder\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        # RCL Loss\n",
    "        self.rcl_loss = nn.MSELoss()\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "    # Encode Past & Future Trajectories\n",
    "    def _encoder(self, past, future):\n",
    "        inp = torch.cat([past, future], dim = 1)\n",
    "        mean, std = self.encoder(inp)        \n",
    "        return mean, std\n",
    "\n",
    "    # Reparametrization Trick\n",
    "    def _sample_z(self, mean, std):\n",
    "        eps = torch.randn_like(mean).to(device)\n",
    "        return mean + std * eps\n",
    "\n",
    "    # Reconstruct future trajectories given z & past trajectories + initial conditions\n",
    "    def _decoder(self, z, past, b_inp):\n",
    "        inp = torch.cat([z, past], dim = 1)\n",
    "        y = self.decoder(inp, b_inp)\n",
    "        return y\n",
    "    \n",
    "    # Forward Pass\n",
    "    def forward(self, past, future, b_inp, beta = 1.0, step = 0):\n",
    "        \n",
    "        # Beta Annealing\n",
    "        beta_d = min(step / 1000 * beta, beta)\n",
    "        \n",
    "        # Mu & Variance\n",
    "        mean, std = self._encoder(past, future)\n",
    "        \n",
    "        # Sample from z -> Reparameterized \n",
    "        z = self._sample_z(mean, std)\n",
    "        \n",
    "        # Decode y\n",
    "        y = self._decoder(z, past, b_inp)\n",
    "        \n",
    "        # KL Loss\n",
    "        KL = -0.5 * torch.mean(torch.sum(1 + torch_log(std ** 2) - mean ** 2 - std ** 2, dim=1))\n",
    "        \n",
    "        # RCL Loss \n",
    "        RCL = self.rcl_loss(future, y)\n",
    "        \n",
    "        # ELBO Loss\n",
    "        loss = beta_d * KL + RCL\n",
    "        \n",
    "        return KL, RCL, loss, beta_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ace6c95-24dc-492a-9d3a-bb1bcf79b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 80]) torch.Size([64, 120]) torch.Size([64, 6])\n"
     ]
    }
   ],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, data_path, t_obs=8, dt=0.4):\n",
    "\n",
    "        self.data = np.load(data_path).astype(np.float32)\n",
    "        self.t_obs = t_obs\n",
    "        self.dt = dt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        traj = self.data[idx]\n",
    "        \n",
    "        # x - B x 20\n",
    "        x_traj = traj[:, 0]\n",
    "        \n",
    "        # y - B x 20\n",
    "        y_traj = traj[:, 1]\n",
    "        \n",
    "        x_traj = x_traj - x_traj[0]\n",
    "        y_traj = y_traj - y_traj[0]\n",
    "        \n",
    "        # Inputs B x 8\n",
    "        x_inp = x_traj[:self.t_obs]\n",
    "        y_inp = y_traj[:self.t_obs]\n",
    "        \n",
    "        # Output - B x 12\n",
    "        x_fut = x_traj[self.t_obs:]\n",
    "        y_fut = y_traj[self.t_obs:]\n",
    "    \n",
    "        # Init Conditions\n",
    "        vx_beg = (x_inp[-1]-x_inp[-2]) / self.dt\n",
    "        vy_beg = (y_inp[-1]-y_inp[-2]) / self.dt\n",
    "\n",
    "        vx_beg_prev = (x_inp[-2]-x_inp[-3]) / self.dt\n",
    "        vy_beg_prev = (y_inp[-2]-y_inp[-3]) / self.dt\n",
    "\n",
    "        ax_beg = (vx_beg - vx_beg_prev) / self.dt\n",
    "        ay_beg = (vy_beg - vy_beg_prev) / self.dt\n",
    "\n",
    "        traj_inp = np.hstack((x_inp, y_inp)).flatten()\n",
    "        traj_out = np.hstack((x_fut, y_fut)).flatten()\n",
    "        b_inp = np.array([x_inp[-1], y_inp[-1], vx_beg, vy_beg, ax_beg, ay_beg])\n",
    "        \n",
    "        return torch.tensor(traj_inp).double(), torch.tensor(traj_out).double(), torch.tensor(b_inp).double()\n",
    "    \n",
    "def rotate(gt_x, gt_y,theta):\n",
    "    gt_x_x = [ (gt_x[k] * np.cos(theta) - gt_y[k] * np.sin(theta))  for k in range(len(gt_x))]\n",
    "    gt_y_y = [ (gt_x[k] * np.sin(theta) + gt_y[k] * np.cos(theta))  for k in range(len(gt_x))]\n",
    "    gt_x = gt_x_x\n",
    "    gt_y = gt_y_y\n",
    "    return gt_x, gt_y\n",
    "\n",
    "class TrajDataset(Dataset):\n",
    "    \"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "    def __init__(self, dataset_path):\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.files = os.listdir(DATASET_PATH)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(os.path.join(self.dataset_path, self.files[idx], f\"{self.files[idx]}.npy\"), allow_pickle=True)\n",
    "        # map_info = np.load(os.path.join(self.dataset_path, self.files[idx], f\"lanes_{self.files[idx]}.npy\"), allow_pickle=True)\n",
    "        agent, obstacle_tracks = None, []\n",
    "        # [object_state.position[0], object_state.position[1], object_state.heading, object_state.velocity[0], object_state.velocity[1], timestamps_ns[ind], tck[track.category], vmp[track.object_type]\n",
    "        # 5s of input of agent and 4 obstacles, 5s of output\n",
    "        inp = np.zeros((200))\n",
    "        out = np.zeros((120))\n",
    "        for tracks in arr:\n",
    "            if tracks[0][-2] == 3:\n",
    "                agent = tracks\n",
    "                last_obs = np.array(tracks)[-1]\n",
    "                last_obs_x = last_obs[0]\n",
    "                last_obs_y = last_obs[1]\n",
    "                last_obs_vel_x = last_obs[3]\n",
    "                last_obs_vel_y = last_obs[4]\n",
    "                for i in range(np.array(tracks).shape[0], 110):\n",
    "                    timestep = (i - np.array(tracks).shape[0] + 1)\n",
    "                    tracks.append([last_obs_x + last_obs_vel_x * timestep, last_obs_y + last_obs_vel_y * timestep, last_obs[2], last_obs_vel_x, last_obs_vel_y, i, last_obs[-2], last_obs[-1]])\n",
    "                agx = np.array(tracks)[10:50, 0] # position-x\n",
    "                agy = np.array(tracks)[10:50, 1] # position-y\n",
    "                offsetx = agx[-1]\n",
    "                offsety = agy[-1]\n",
    "                theta = np.arctan2(agy[-1] - agy[-2], agx[-1] - agx[-2])\n",
    "                ox = np.array(tracks)[50:, 0] # position-x\n",
    "                oy = np.array(tracks)[50:, 1] # position-x\n",
    "                agx, agy = rotate(agx - offsetx, agy - offsety, -theta)\n",
    "                ox, oy = rotate(ox - offsetx, oy - offsety, -theta)\n",
    "                vx = np.array(tracks)[10:50, 3] # velocity-x\n",
    "                vy = np.array(tracks)[10:50, 4] # velocity-y\n",
    "                vx, vy = rotate(vx, vy, -theta)\n",
    "                inp[0::5] = agx\n",
    "                inp[1::5] = agy\n",
    "                inp[2::5] = vx\n",
    "                inp[3::5] = vy\n",
    "                inp[4::5] = np.array(tracks)[10:50, 2] - theta # heading\n",
    "                out[:60] = ox\n",
    "                out[60:] = oy\n",
    "                traj_inp = np.hstack((agx, agy)).flatten()\n",
    "                traj_out = np.hstack((ox, oy)).flatten()\n",
    "                b_inp = np.array([agx[-1], agy[-1], vx[-1], vy[-1], 0, 0])\n",
    "                \n",
    "        return torch.tensor(traj_inp).double(), torch.tensor(traj_out).double(), torch.tensor(b_inp).double() #torch.tensor(inp).double(), torch.tensor(out).double()\n",
    "\n",
    "    \n",
    "DATASET_PATH =  \"/mnt/e/datasets/argoverse/parsed\"\n",
    "import os\n",
    "files = os.listdir(DATASET_PATH)\n",
    "    \n",
    "train_dataset = TrajDataset(DATASET_PATH)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "for _, data in enumerate(train_loader):\n",
    "    inp, traj_out, b_inp = data\n",
    "    print(inp.shape, traj_out.shape, b_inp.shape)\n",
    "    break\n",
    "    pass\n",
    "# Using PyTorch Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46fe45d8-a48b-461b-8958-40eb05d635c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 11])\n",
      "torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "# NGSIM - 8 Observed ( 3.2s ) & 12 Pred ( 4.8s )\n",
    "\n",
    "weight_smoothness = 1.0\n",
    "t_fin = 6\n",
    "num_batch = train_loader.batch_size\n",
    "num = 60\n",
    "\n",
    "# P_bar\n",
    "tot_time = torch.linspace(0, t_fin, num, device=device)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "\n",
    "P, _, _ = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "P_bar = P[:, 3:].to(device) # self.P_torch[:, 3:]\n",
    "\n",
    "node = QPNode(weight_smoothness, t_fin, num, num_batch, device)\n",
    "qp_layer = DeclarativeLayer(node)\n",
    "\n",
    "# cVAE Inputs\n",
    "input_size = 80\n",
    "output_size = 120\n",
    "z_dim = 6\n",
    "num_layers = 1\n",
    "hidden_size = 128\n",
    "decoder_output_size = 6\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size, output_size, num_layers, z_dim)\n",
    "decoder = Decoder(qp_layer, P_bar, input_size, hidden_size, decoder_output_size, num_layers, z_dim)\n",
    "model = GRU_cVAE(encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33d0b27c-d9df-42a8-a758-cead1d6866db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TrajectoryDataset(\"./datasets/toy/train_data.npy\")\n",
    "# train_loader = DataLoader(train_dataset, batch_size=num_batch, shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "# val_dataset = TrajectoryDataset(\"./datasets/toy/val_data.npy\")\n",
    "# val_loader = DataLoader(val_dataset, batch_size=num_batch, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d38b71d9-11bb-4fea-aaee-3b112d3c5cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 80]) torch.Size([64, 120]) torch.Size([64, 6])\n"
     ]
    }
   ],
   "source": [
    "for batch_num, data in enumerate(train_loader):\n",
    "    traj_inp, traj_out, b_inp = data\n",
    "    print(traj_inp.shape, traj_out.shape, b_inp.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba11ff52-27d3-4e87-bb1d-8f97b9fffd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16]) torch.Size([64, 120])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (60) must match the size of tensor b (12) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m future \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m b_inp \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 18\u001b[0m KL_loss, RCL_loss, loss, beta_d \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mGRU_cVAE.forward\u001b[0;34m(self, past, future, b_inp, beta, step)\u001b[0m\n\u001b[1;32m    127\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_z(mean, std)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Decode y\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_inp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# KL Loss\u001b[39;00m\n\u001b[1;32m    133\u001b[0m KL \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m torch_log(std \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m mean \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m std \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mGRU_cVAE._decoder\u001b[0;34m(self, z, past, b_inp)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decoder\u001b[39m(\u001b[38;5;28mself\u001b[39m, z, past, b_inp):\n\u001b[1;32m    113\u001b[0m     inp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([z, past], dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_inp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, inputs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(sol\u001b[38;5;241m.\u001b[39mshape, offset\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Compute final trajectory\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m x_traj_batch \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msol\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     83\u001b[0m y_traj_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP, sol[:, \u001b[38;5;241m8\u001b[39m:]\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m+\u001b[39m offset[:, \u001b[38;5;241m12\u001b[39m:]\n\u001b[1;32m     84\u001b[0m traj \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack([x_traj_batch, y_traj_batch])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (60) must match the size of tensor b (12) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "epochs = 24\n",
    "step, beta = 0, 3.5\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 1e-3, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 6, gamma = 0.1)\n",
    "\n",
    "avg_train_loss, avg_rcl_loss, avg_kl_loss = [], [], []\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train Loop\n",
    "    losses_train, kl_losses, rcl_losses = [], [], []\n",
    "    model.train()\n",
    "    for past, future, inputs in train_loader:\n",
    "        \n",
    "        past = past.to(device)\n",
    "        future = future.to(device)\n",
    "        b_inp = inputs.to(device)\n",
    "                        \n",
    "        KL_loss, RCL_loss, loss, beta_d = model.forward(past, future, b_inp, beta, step)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses_train.append(loss.detach().cpu().numpy())\n",
    "        rcl_losses.append(RCL_loss.detach().cpu().numpy())\n",
    "        kl_losses.append(KL_loss.detach().cpu().numpy())\n",
    "    \n",
    "    print(f\"Epoch: {epoch + 1}, Beta: {beta_d}, Step: {step}, Train Loss: {np.average(losses_train):.3f}\")\n",
    "    step += 1.5\n",
    "    scheduler.step()\n",
    "    avg_train_loss.append(np.average(losses_train)), avg_rcl_loss.append(np.average(rcl_losses)), avg_kl_loss.append(np.average(kl_losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
