{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bernstein_torch import bernstein_coeff_order10_new\n",
    "\n",
    "# Generating P matrix\n",
    "t_fin = 15.0\n",
    "num = 100\n",
    "tot_time = torch.linspace(0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "P, Pdot, Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Loader \n",
    "class TrajDataset(Dataset):\n",
    "    \"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        # Inputs\n",
    "        self.inp = data[:, 0:55]\n",
    "        \n",
    "        # Outputs\n",
    "        self.out = data[:, 55:]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inp)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Inputs\n",
    "        inp = self.inp[idx]\n",
    "        \n",
    "        # Outputs\n",
    "        out = self.out[idx]\n",
    "                 \n",
    "        return torch.tensor(inp).double(), torch.tensor(out).double()\n",
    "\n",
    "# Load the dataset\n",
    "train_data = np.load(\"../datasets/toy/train_data.npy\", mmap_mode=\"c\")\n",
    "\n",
    "# Using PyTorch Dataloader\n",
    "train_dataset = TrajDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2145, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2145, 20, 2]) torch.Size([2145, 0, 2])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for dimension 0 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m a_obs, b_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5.8\u001b[39m, \u001b[38;5;241m3.2\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     x_ell \u001b[38;5;241m=\u001b[39m \u001b[43mx_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m a_obs \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(th)\n\u001b[1;32m     20\u001b[0m     y_ell \u001b[38;5;241m=\u001b[39m y_obs[i] \u001b[38;5;241m+\u001b[39m b_obs \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msin(th)\n\u001b[1;32m     21\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(x_ell, y_ell, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-k\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7 is out of bounds for dimension 0 with size 7"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity Check\n",
    "for batch_num, (datas) in enumerate(train_loader):\n",
    "    inp, out = datas\n",
    "    \n",
    "    print(inp.shape, out.shape)\n",
    "        \n",
    "    num = 2\n",
    "    \n",
    "    # Sanity Check\n",
    "    x_obs = inp[num].flatten()[5::5]\n",
    "    y_obs = inp[num].flatten()[6::5]\n",
    "     \n",
    "    th = np.linspace(0, 2 * np.pi, 100)\n",
    "    plt.figure(1)\n",
    "    \n",
    "    a_obs, b_obs = 5.8, 3.2\n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        x_ell = x_obs[i] + a_obs * np.cos(th)\n",
    "        y_ell = y_obs[i] + b_obs * np.sin(th)\n",
    "        plt.plot(x_ell, y_ell, '-k', linewidth=1.0)\n",
    "\n",
    "    plt.axis('equal')\n",
    "        \n",
    "    cx = out[num].flatten()[0:11]\n",
    "    cy = out[num].flatten()[11:22]\n",
    "    \n",
    "    x_gt = P.cpu() @ cx\n",
    "    y_gt = P.cpu() @ cy\n",
    "    \n",
    "    plt.plot(x_gt.numpy(), y_gt.numpy(), label=\"Ground Truth\", color=\"red\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta_cvae_aug_ddn import Encoder, Decoder, Beta_cVAE, BatchOpt_DDN, DeclarativeLayer\n",
    "\n",
    "# DDN\n",
    "num_batch = train_loader.batch_size\n",
    "node = BatchOpt_DDN(P, Pdot, Pddot, num_batch)\n",
    "opt_layer = DeclarativeLayer(node)\n",
    "\n",
    "# Beta-cVAE Inputs\n",
    "enc_inp_dim = 55\n",
    "enc_out_dim = 200\n",
    "dec_inp_dim = enc_inp_dim\n",
    "dec_out_dim = 8\n",
    "hidden_dim = 1024 * 2\n",
    "z_dim = 2\n",
    "\n",
    "inp_mean, inp_std = 5.1077423, 20.914295\n",
    "\n",
    "encoder = Encoder(enc_inp_dim, enc_out_dim, hidden_dim, z_dim)\n",
    "decoder = Decoder(dec_inp_dim, dec_out_dim, hidden_dim, z_dim)\n",
    "model = Beta_cVAE(encoder, decoder, opt_layer, inp_mean, inp_std).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = torch.block_diag(P, P).to(device)\n",
    "Pdot = Pdot.to(device)\n",
    "Pddot = Pddot.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4290x0 and 22x200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m inp \u001b[38;5;241m=\u001b[39m inp\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m traj_gt \u001b[38;5;241m=\u001b[39m (\u001b[43mP\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Ego vehicle states\u001b[39;00m\n\u001b[1;32m     19\u001b[0m initial_state_ego \u001b[38;5;241m=\u001b[39m inp[:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m6\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4290x0 and 22x200)"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "step, beta = 0, 3.5\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 1e-3, weight_decay=6e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 12, gamma = 0.1)\n",
    "\n",
    "avg_train_loss, avg_rcl_loss, avg_kl_loss, avg_aug_loss = [], [], [], []\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train Loop\n",
    "    losses_train, kl_losses, rcl_losses, aug_losses = [], [], [], []\n",
    "    model.train()\n",
    "    for inp, out in train_loader:\n",
    "        \n",
    "        inp = inp.to(device)\n",
    "        out = out.to(device)\n",
    "        traj_gt = (P @ out.T).T\n",
    "       \n",
    "        # Ego vehicle states\n",
    "        initial_state_ego = inp[:, 2:6]\n",
    "        initial_state_ego[:, 2:4] = initial_state_ego[:, 0:2]\n",
    "        initial_state_ego[:, 0:2] = 0\n",
    "               \n",
    "        # Remember to add the Aug Loss\n",
    "        KL_loss, RCL_loss, loss, _ = model.forward(inp, traj_gt, initial_state_ego, P, Pdot, Pddot, beta, step)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses_train.append(loss.detach().cpu().numpy()) \n",
    "        rcl_losses.append(RCL_loss.detach().cpu().numpy())\n",
    "        kl_losses.append(KL_loss.detach().cpu().numpy())\n",
    "        # aug_losses.append(Aug.detach().cpu().numpy())\n",
    "\n",
    "    if epoch % 1 == 0:    \n",
    "        print(f\"Epoch: {epoch + 1}, Train Loss: {np.average(losses_train):.3f}, RCL: {np.average(rcl_losses):.3f}, KL: {np.average(kl_losses):.3f}\") #, Aug: {np.average(aug_losses):.3f}\")\n",
    "\n",
    "    step += 1.0\n",
    "    scheduler.step()\n",
    "    avg_train_loss.append(np.average(losses_train)), avg_rcl_loss.append(np.average(rcl_losses)), \\\n",
    "    avg_kl_loss.append(np.average(kl_losses)) #, avg_aug_loss.append(np.average(aug_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './Weights/cvae_aug_mse.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c562111517df06ec79e2a0b366e2ca57c1da3a77768b6967f7ee5330ff1fbc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
