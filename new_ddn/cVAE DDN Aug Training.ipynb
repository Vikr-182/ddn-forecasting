{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikrant/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 11]) torch.Size([60, 11]) torch.Size([60, 11])\n"
     ]
    }
   ],
   "source": [
    "from bernstein_torch import bernstein_coeff_order10_new\n",
    "\n",
    "# Generating P matrix\n",
    "t_fin = 6.0\n",
    "num = 60\n",
    "tot_time = torch.linspace(0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "P, Pdot, Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "print(P.shape, Pdot.shape, Pddot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_frenet_frame(traj, ref_line):\n",
    "    distance_to_ref = torch.cdist(traj[:, :, :2], ref_line[:, :, :2])\n",
    "    k = torch.argmin(distance_to_ref, dim=-1).view(-1, traj.shape[1], 1).expand(-1, -1, 3)\n",
    "    ref_points = torch.gather(ref_line, 1, k)\n",
    "    x_r, y_r, theta_r = ref_points[:, :, 0], ref_points[:, :, 1], ref_points[:, :, 2] \n",
    "    x, y = traj[:, :, 0], traj[:, :, 1]\n",
    "    s = 0.1 * (k[:, :, 0] - 200)\n",
    "    l = torch.sign((y-y_r)*torch.cos(theta_r)-(x-x_r)*torch.sin(theta_r)) * torch.sqrt(torch.square(x-x_r)+torch.square(y-y_r))\n",
    "    sl = torch.stack([s, l], dim=-1)\n",
    "    return sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tracks(static_map_path, scenario_path):\n",
    "    static_map = ArgoverseStaticMap.from_json(Path(static_map_path))\n",
    "    tracks_df = pd.read_parquet(scenario_path)\n",
    "\n",
    "    scenario_id = tracks_df[\"scenario_id\"][0]\n",
    "    focal_track_id = tracks_df[\"focal_track_id\"][0]\n",
    "    city_name = tracks_df[\"city\"][0]\n",
    "    map_id = tracks_df[\"map_id\"][0] if \"map_id\" in tracks_df.columns else None\n",
    "    slice_id = tracks_df[\"slice_id\"][0] if \"slice_id\" in tracks_df.columns else None\n",
    "\n",
    "    # Interpolate scenario timestamps based on the saved start and end timestamps\n",
    "    timestamps_ns = np.linspace(\n",
    "        tracks_df[\"start_timestamp\"][0], tracks_df[\"end_timestamp\"][0], num=tracks_df[\"num_timestamps\"][0]\n",
    "    )\n",
    "\n",
    "\n",
    "    tracks: List[Track] = []\n",
    "    for track_id, track_df in tracks_df.groupby(\"track_id\"):\n",
    "\n",
    "        observed_states: List[bool] = track_df.loc[:, \"observed\"].values.tolist()\n",
    "        object_type: ObjectType = ObjectType(track_df[\"object_type\"].iloc[0])\n",
    "        object_category: TrackCategory = TrackCategory(track_df[\"object_category\"].iloc[0])\n",
    "        timesteps: List[int] = track_df.loc[:, \"timestep\"].values.tolist()\n",
    "        positions: List[Tuple[float, float]] = list(\n",
    "            zip(\n",
    "                track_df.loc[:, \"position_x\"].values.tolist(),\n",
    "                track_df.loc[:, \"position_y\"].values.tolist(),\n",
    "            )\n",
    "        )\n",
    "        headings: List[float] = track_df.loc[:, \"heading\"].values.tolist()\n",
    "        velocities: List[Tuple[float, float]] = list(\n",
    "            zip(\n",
    "                track_df.loc[:, \"velocity_x\"].values.tolist(),\n",
    "                track_df.loc[:, \"velocity_y\"].values.tolist(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        object_states: List[ObjectState] = []\n",
    "        for idx in range(len(timesteps)):\n",
    "            object_states.append(\n",
    "                ObjectState(\n",
    "                    observed=observed_states[idx],\n",
    "                    timestep=timesteps[idx],\n",
    "                    position=positions[idx],\n",
    "                    heading=headings[idx],\n",
    "                    velocity=velocities[idx],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        tracks.append(\n",
    "            Track(track_id=track_id, object_states=object_states, object_type=object_type, category=object_category)\n",
    "        )\n",
    "\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lanes(static_map_path, scenario_path, debug=False, sample_len=100):\n",
    "    static_map = ArgoverseStaticMap.from_json(Path(static_map_path))\n",
    "    tracks_df = pd.read_parquet(scenario_path)\n",
    "\n",
    "    tracks = extract_tracks(static_map_path, scenario_path)\n",
    "\n",
    "    agx, agy = None, None\n",
    "\n",
    "    for track in tracks:\n",
    "        if track.category == TrackCategory.FOCAL_TRACK:\n",
    "            states = track.object_states\n",
    "            agx = [state.position[0] for state in states]\n",
    "            agy = [state.position[1] for state in states]\n",
    "            if debug: plt.scatter(agx[:50], agy[:50], color=\"blue\", zorder=10)\n",
    "            if debug: plt.scatter(agx[50:], agy[50:], color=\"orange\", zorder=10)\n",
    "            traj = np.array([agx, agy])\n",
    "            traj = traj.reshape(traj.shape[1], traj.shape[0])\n",
    "            pass\n",
    "        elif track.category == TrackCategory.SCORED_TRACK:\n",
    "            states = track.object_states\n",
    "            otx = [state.position[0] for state in states]\n",
    "            oty = [state.position[1] for state in states]\n",
    "            # plt.scatter(otx[:50], oty[:50], color=\"red\")\n",
    "            # plt.scatter(otx[50:], oty[50:], color=\"grey\")\n",
    "            pass    \n",
    "\n",
    "    # getting the backbone\n",
    "    backbones = []\n",
    "    for tm in range(0, 50):\n",
    "        min_ind = get_nearest_centerline(agx, agy, static_map, tm=tm)\n",
    "        cx = get_centerline(static_map, min_ind)\n",
    "        lane_seg = static_map.vector_lane_segments[min_ind]\n",
    "        if tm == 0:\n",
    "            backbones.append([min_ind])\n",
    "            continue\n",
    "        last_lane = backbones[-1][-1]\n",
    "        if min_ind == last_lane:\n",
    "            continue\n",
    "        fg = True\n",
    "        for backbone in backbones:\n",
    "            if min_ind in backbone:\n",
    "                fg = False\n",
    "            if min_ind in static_map.vector_lane_segments[backbone[-1]].successors:\n",
    "                backbone.append(min_ind)\n",
    "                fg = False\n",
    "        if fg:\n",
    "            backbones.append([min_ind])\n",
    "        # plt.plot(cx[:, 0], cx[:, 1])\n",
    "\n",
    "    MAX_DIS = 300\n",
    "\n",
    "    hold_lanes = []\n",
    "    import copy\n",
    "    \n",
    "    qry_pt = [agx[50], agy[50]]\n",
    "\n",
    "    def BFS(queue, lane_id, visited, hold, static_map, qry_pt=[]):\n",
    "        while len(queue):\n",
    "            [cur, distance, hold] = queue.pop(0)\n",
    "            if distance > MAX_DIS:\n",
    "                hold_lanes.append(hold)\n",
    "                continue\n",
    "            successors = static_map.vector_lane_segments[cur].successors\n",
    "            done = False\n",
    "            for successor in successors:\n",
    "                if visited.get(successor) == None:\n",
    "                    # not visited\n",
    "                    try:\n",
    "                        static_map.vector_lane_segments[successor]\n",
    "                        hold_ = copy.deepcopy(hold)\n",
    "                        hold_.append(successor)\n",
    "                        cx = get_centerline(static_map, successor)\n",
    "                        distance1 = get_distance(qry_pt, cx[-1])\n",
    "                        distance2 = get_distance(qry_pt, cx[0])\n",
    "                        queue.append([successor, max(distance1, distance2), hold_])\n",
    "                        visited[successor] = True\n",
    "                    except:\n",
    "                        done = True\n",
    "            if done:\n",
    "                hold_lanes.append(hold)\n",
    "                pass\n",
    "            if len(successors) == 0:\n",
    "                # end of the line\n",
    "                hold_lanes.append(hold)\n",
    "                pass\n",
    "\n",
    "    # hold\n",
    "    visited = {}\n",
    "    for lane in backbone:\n",
    "        queue = []\n",
    "        if visited.get(lane) == None:\n",
    "            visited[lane] = True\n",
    "            cx = get_centerline(static_map, lane)\n",
    "            distance1 = get_distance(qry_pt, cx[-1])\n",
    "            distance2 = get_distance(qry_pt, cx[0])\n",
    "            hold = []\n",
    "            hold.append(lane)\n",
    "            queue.append([lane, max(distance1, distance2), hold])\n",
    "            BFS(queue, lane, visited, hold, static_map, qry_pt)\n",
    "            cnt = 0\n",
    "            for lanes in hold_lanes:\n",
    "                color = \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "                for lane_ in lanes:\n",
    "                    # if cnt == 1: print(\"BAZINGA\", lane_)\n",
    "                    cx = get_centerline(static_map, lane_)\n",
    "                    if debug: plt.plot(cx[:, 0], cx[:, 1], color=color)\n",
    "                cnt = cnt + 1\n",
    "                if debug: plt.scatter(agx[:50], agy[:50], color=\"blue\", zorder=10)\n",
    "                if debug: plt.scatter(agx[50:], agy[50:], color=\"orange\", zorder=10)                    \n",
    "                # if debug: plt.axis('equal')\n",
    "                if debug: plt.xlim([np.min(agx) - 100, np.max(agx) + 100])\n",
    "                if debug: plt.ylim([np.min(agy) - 150, np.max(agy) + 150])                \n",
    "                if debug: plt.show()\n",
    "                if debug: plt.clf()\n",
    "    hold_array = copy.deepcopy(hold_lanes)\n",
    "\n",
    "    hold_lanes = []\n",
    "    # left change\n",
    "    visited = {}\n",
    "    for lane_hold in backbone:\n",
    "        queue = []\n",
    "        lane = static_map.vector_lane_segments[lane_hold].left_neighbor_id\n",
    "        if visited.get(lane) == None:\n",
    "            try:\n",
    "                # to check if available in lst\n",
    "                static_map.vector_lane_segments[lane].successors\n",
    "            except:\n",
    "                continue\n",
    "            visited[lane] = True\n",
    "            cx = get_centerline(static_map, lane)\n",
    "            distance1 = get_distance(qry_pt, cx[-1])\n",
    "            distance2 = get_distance(qry_pt, cx[0])            \n",
    "            hold = []\n",
    "            hold.append(lane)\n",
    "            queue.append([lane, max(distance1, distance2), hold])\n",
    "            BFS(queue, lane, visited, hold, static_map, qry_pt)\n",
    "            for lanes in hold_lanes:\n",
    "                for lane_ in lanes:\n",
    "                    cx = get_centerline(static_map, lane_)\n",
    "                    # if debug: plt.plot(cx[:, 0], cx[:, 1], color=\"blue\")\n",
    "    left_change_array = copy.deepcopy(hold_lanes)\n",
    "\n",
    "    hold_lanes = []                \n",
    "    # left change\n",
    "    visited = {}\n",
    "    for lane_hold in backbone:\n",
    "        queue = []\n",
    "        lane = static_map.vector_lane_segments[lane_hold].right_neighbor_id\n",
    "        if visited.get(lane) == None:\n",
    "            try:\n",
    "                # to check if available in lst\n",
    "                static_map.vector_lane_segments[lane].successors\n",
    "            except:\n",
    "                continue\n",
    "            visited[lane] = True\n",
    "            cx = get_centerline(static_map, lane)\n",
    "            distance1 = get_distance(qry_pt, cx[-1])\n",
    "            distance2 = get_distance(qry_pt, cx[0])                        \n",
    "            hold = []\n",
    "            hold.append(lane)\n",
    "            queue.append([lane, max(distance1, distance2), hold])\n",
    "            BFS(queue, lane, visited, hold, static_map, qry_pt)\n",
    "            for lanes in hold_lanes:\n",
    "                for lane_ in lanes:\n",
    "                    cx = get_centerline(static_map, lane_)\n",
    "                    # if debug: plt.plot(cx[:, 0], cx[:, 1], color=\"yellow\")\n",
    "    right_change_array = copy.deepcopy(hold_lanes)\n",
    "    if debug: plt.xlim([np.min(agx) - 50, np.max(agx) + 50])\n",
    "    if debug: plt.ylim([np.min(agy) - 50, np.max(agy) + 50])\n",
    "    lanes = []\n",
    "    cnt = 0\n",
    "    for lane in hold_array:\n",
    "        lane_information = []\n",
    "        for lane_id in lane:\n",
    "            # if cnt == 1: print(\"LAUWA LAUWA\", lane_id)\n",
    "            wx = [waypt.x for waypt in static_map.vector_lane_segments[lane_id].left_lane_boundary.waypoints]\n",
    "            wy = [waypt.y for waypt in static_map.vector_lane_segments[lane_id].left_lane_boundary.waypoints]\n",
    "            wwx = [waypt.x for waypt in static_map.vector_lane_segments[lane_id].right_lane_boundary.waypoints]\n",
    "            wwy = [waypt.y for waypt in static_map.vector_lane_segments[lane_id].right_lane_boundary.waypoints]\n",
    "            left_boundary = np.dstack((wx, wy))[0]\n",
    "            right_boundary = np.dstack((wwx, wwy))[0]\n",
    "            left_boundary = interp_arc(t=100, points=left_boundary)\n",
    "            right_boundary = interp_arc(t=100, points=right_boundary)\n",
    "            cx = get_centerline(static_map, lane_id)\n",
    "            cx = interp_arc(t=sample_len, points=cx)\n",
    "            is_intersection = static_map.vector_lane_segments[lane_id].is_intersection\n",
    "            lane_type = static_map.vector_lane_segments[lane_id].lane_type.name\n",
    "            left_mark_type = static_map.vector_lane_segments[lane_id].left_mark_type.name\n",
    "            right_mark_type = static_map.vector_lane_segments[lane_id].right_mark_type.name\n",
    "            for ind in range(sample_len):\n",
    "                lane_information.append([is_intersection, lane_type, cx[ind],\n",
    "                                        left_boundary[ind][0], left_boundary[ind][1], left_mark_type, \n",
    "                                         right_boundary[ind][0], right_boundary[ind][1], right_mark_type, cx[ind][0],  cx[ind][1]])\n",
    "                pass\n",
    "        lanes.append(lane_information)\n",
    "        cnt = cnt + 1\n",
    "    for lane in left_change_array:\n",
    "        lane_information = []\n",
    "        for lane_id in lane:\n",
    "            wx = [waypt.x for waypt in static_map.vector_lane_segments[lane_id].left_lane_boundary.waypoints]\n",
    "            wy = [waypt.y for waypt in static_map.vector_lane_segments[lane_id].left_lane_boundary.waypoints]\n",
    "            wwx = [waypt.x for waypt in static_map.vector_lane_segments[lane_id].right_lane_boundary.waypoints]\n",
    "            wwy = [waypt.y for waypt in static_map.vector_lane_segments[lane_id].right_lane_boundary.waypoints]\n",
    "            left_boundary = np.dstack((wx, wy))[0]\n",
    "            right_boundary = np.dstack((wwx, wwy))[0]\n",
    "            left_boundary = interp_arc(t=100, points=left_boundary)\n",
    "            right_boundary = interp_arc(t=100, points=right_boundary)\n",
    "            cx = get_centerline(static_map, lane_id)\n",
    "            cx = interp_arc(t=sample_len, points=cx)\n",
    "            is_intersection = static_map.vector_lane_segments[lane_id].is_intersection\n",
    "            lane_type = static_map.vector_lane_segments[lane_id].lane_type.name\n",
    "            left_mark_type = static_map.vector_lane_segments[lane_id].left_mark_type.name\n",
    "            right_mark_type = static_map.vector_lane_segments[lane_id].right_mark_type.name\n",
    "            for ind in range(sample_len):\n",
    "                lane_information.append([is_intersection, lane_type, cx[ind],\n",
    "                                        left_boundary[ind][0], left_boundary[ind][1], left_mark_type, \n",
    "                                         right_boundary[ind][0], right_boundary[ind][1], right_mark_type, cx[ind][0],  cx[ind][1]])\n",
    "                pass\n",
    "        lanes.append(lane_information)\n",
    "    for lane in right_change_array:\n",
    "        lane_information = []\n",
    "        for lane_id in lane:\n",
    "            wx = [waypt.x for waypt in static_map.vector_lane_segments[lane_id].left_lane_boundary.waypoints]\n",
    "            wy = [waypt.y for waypt in static_map.vector_lane_segments[lane_id].left_lane_boundary.waypoints]\n",
    "            wwx = [waypt.x for waypt in static_map.vector_lane_segments[lane_id].right_lane_boundary.waypoints]\n",
    "            wwy = [waypt.y for waypt in static_map.vector_lane_segments[lane_id].right_lane_boundary.waypoints]\n",
    "            left_boundary = np.dstack((wx, wy))[0]\n",
    "            right_boundary = np.dstack((wwx, wwy))[0]\n",
    "            left_boundary = interp_arc(t=100, points=left_boundary)\n",
    "            right_boundary = interp_arc(t=100, points=right_boundary)\n",
    "            cx = get_centerline(static_map, lane_id)\n",
    "            cx = interp_arc(t=sample_len, points=cx)\n",
    "            is_intersection = static_map.vector_lane_segments[lane_id].is_intersection\n",
    "            lane_type = static_map.vector_lane_segments[lane_id].lane_type.name\n",
    "            left_mark_type = static_map.vector_lane_segments[lane_id].left_mark_type.name\n",
    "            right_mark_type = static_map.vector_lane_segments[lane_id].right_mark_type.name\n",
    "            for ind in range(sample_len):\n",
    "                lane_information.append([is_intersection, lane_type, cx[ind],\n",
    "                                        left_boundary[ind][0], left_boundary[ind][1], left_mark_type, \n",
    "                                         right_boundary[ind][0], right_boundary[ind][1], right_mark_type, cx[ind][0],  cx[ind][1]])\n",
    "                pass\n",
    "        lanes.append(lane_information)\n",
    "    return lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from av2.map.map_api import ArgoverseStaticMap\n",
    "from av2.datasets.motion_forecasting.data_schema import ArgoverseScenario, ObjectState, ObjectType, Track, TrackCategory\n",
    "from av2.geometry.polyline_utils import convert_lane_boundaries_to_polygon, get_polyline_length, interp_polyline_by_fixed_waypt_interval\n",
    "from av2.geometry.interpolate import compute_midpoint_line, interp_arc\n",
    "from shapely.geometry import LineString, Point, Polygon\n",
    "\n",
    "MAX_DIS = 200\n",
    "\n",
    "def get_centerline(static_map, min_ind):\n",
    "    wx = [waypt.x for waypt in static_map.vector_lane_segments[min_ind].left_lane_boundary.waypoints]\n",
    "    wy = [waypt.y for waypt in static_map.vector_lane_segments[min_ind].left_lane_boundary.waypoints]\n",
    "    wwx = [waypt.x for waypt in static_map.vector_lane_segments[min_ind].right_lane_boundary.waypoints]\n",
    "    wwy = [waypt.y for waypt in static_map.vector_lane_segments[min_ind].right_lane_boundary.waypoints]\n",
    "    cx, _ = compute_midpoint_line(np.dstack((wx, wy))[0], np.dstack((wwx, wwy))[0])\n",
    "    return cx\n",
    "\n",
    "def get_distance(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "def get_nearest_centerline(agx, agy, static_map, tm = 90):\n",
    "    min_ind = 0\n",
    "    min_dist = 1e11\n",
    "    \n",
    "    lane_ids = list(static_map.vector_lane_segments.keys())\n",
    "    for lane_id in lane_ids:\n",
    "        wx = [waypt.x for waypt in static_map.vector_lane_segments[lane_id].left_lane_boundary.waypoints]\n",
    "        wy = [waypt.y for waypt in static_map.vector_lane_segments[lane_id].left_lane_boundary.waypoints]\n",
    "\n",
    "        wwx = [waypt.x for waypt in static_map.vector_lane_segments[lane_id].right_lane_boundary.waypoints]\n",
    "        wwy = [waypt.y for waypt in static_map.vector_lane_segments[lane_id].right_lane_boundary.waypoints]\n",
    "        # poly = convert_lane_boundaries_to_polygon(np.dstack((wx, wy))[0], np.dstack((wwx, wwy))[0])\n",
    "        cx, _ = compute_midpoint_line(np.dstack((wx, wy))[0], np.dstack((wwx, wwy))[0])\n",
    "\n",
    "        centerline = interp_arc(100, cx)\n",
    "        # plt.plot(centerline[:, 0], centerline[:, 1], \"--\")\n",
    "        pos = np.array([agx[tm], agy[tm]])\n",
    "        dist = np.linalg.norm(centerline - pos, axis=1).min()\n",
    "\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_ind = lane_id\n",
    "    return min_ind\n",
    "\n",
    "def give_lane_color(name):\n",
    "    string = \"\"\n",
    "    if \"YELLOW\" in name:\n",
    "        string += \"y\"\n",
    "    elif \"WHITE\" in name:\n",
    "        string += \"w\"\n",
    "    else:\n",
    "        string = \"grey\"\n",
    "    if \"DASH\" in name:\n",
    "        string += \"--\"\n",
    "    return string\n",
    "\n",
    "def get_backbone(agx, agy, static_map_path, end_tm=40):\n",
    "    static_map = ArgoverseStaticMap.from_json(Path(static_map_path))\n",
    "    backbones = []\n",
    "    for tm in range(0, end_tm):\n",
    "        min_ind = get_nearest_centerline(agx, agy, static_map, tm=tm)\n",
    "        cx = get_centerline(static_map, min_ind)\n",
    "        lane_seg = static_map.vector_lane_segments[min_ind]\n",
    "        if tm == 0:\n",
    "            backbones.append([min_ind])\n",
    "            continue\n",
    "        last_lane = backbones[-1][-1]\n",
    "        if min_ind == last_lane:\n",
    "            continue\n",
    "        fg = True\n",
    "        for backbone in backbones:\n",
    "            if min_ind in backbone:\n",
    "                fg = False\n",
    "            if min_ind in static_map.vector_lane_segments[backbone[-1]].successors:\n",
    "                backbone.append(min_ind)\n",
    "                fg = False\n",
    "        if fg:\n",
    "            backbones.append([min_ind])\n",
    "    for backbone in backbones:\n",
    "        import random\n",
    "        # color = \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "        for min_ind in backbone:\n",
    "            cx = get_centerline(static_map, min_ind)\n",
    "            # plt.plot(cx[:, 0], cx[:, 1], color=color)\n",
    "\n",
    "    max_backbone = None\n",
    "    max_len = -1e11\n",
    "    ag_traj, _ = interp_polyline_by_fixed_waypt_interval(np.dstack((agx, agy))[0], 0.5)\n",
    "    for backbone in backbones:\n",
    "        total = 0\n",
    "        color = \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "        cxs = []\n",
    "        cys = []\n",
    "        for lane in backbone:\n",
    "            cx = get_centerline(static_map, lane)\n",
    "            cxs.append(cx[:, 0])\n",
    "            cys.append(cx[:, 1])\n",
    "            # plt.plot(cx[:, 0], cx[:, 1], color=color, marker='o')\n",
    "        lane_seq_polygon = centerline_to_polygon(np.dstack((cxs, cys))[0])\n",
    "        total = 0\n",
    "        for xy in ag_traj:\n",
    "            point_in_polygon_score = Polygon(lane_seq_polygon).contains(Point(xy))\n",
    "            total += point_in_polygon_score\n",
    "        if total > max_len:\n",
    "            max_len = total\n",
    "            max_backbone = backbone\n",
    "    # plt.plot(agx, agy, \"b\")            \n",
    "    # plt.xlim([np.min(agx) - 100, np.max(agx) + 100])\n",
    "    # plt.ylim([np.min(agy) - 150, np.max(agy) + 150])                    \n",
    "    # plt.show()\n",
    "    return max_backbone\n",
    "\n",
    "\n",
    "def BFS(queue, lane_id, visited, hold, static_map, qry_pt=[], hold_lanes = []):\n",
    "    while len(queue):\n",
    "        [cur, distance, hold] = queue.pop(0)\n",
    "        if distance > MAX_DIS:\n",
    "            hold_lanes.append(hold)\n",
    "            continue\n",
    "        successors = static_map.vector_lane_segments[cur].successors\n",
    "        done = False\n",
    "        for successor in successors:\n",
    "            if visited.get(successor) == None:\n",
    "                # not visited\n",
    "                try:\n",
    "                    static_map.vector_lane_segments[successor]\n",
    "                    import copy\n",
    "                    hold_ = copy.deepcopy(hold)\n",
    "                    hold_.append(successor)\n",
    "                    cx = get_centerline(static_map, successor)\n",
    "                    distance1 = get_distance(qry_pt, cx[-1])\n",
    "                    distance2 = get_distance(qry_pt, cx[0])\n",
    "                    queue.append([successor, max(distance1, distance2), hold_])\n",
    "                    visited[successor] = True\n",
    "                except:\n",
    "                    done = True\n",
    "        if done:\n",
    "            hold_lanes.append(hold)\n",
    "            pass\n",
    "        if len(successors) == 0:\n",
    "            # end of the line\n",
    "            hold_lanes.append(hold)\n",
    "            pass\n",
    "    return hold_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_frenet_frame(traj, oracle_centerline):\n",
    "    traj, oracle_centerline = traj.clone().detach(), oracle_centerline.clone().detach()\n",
    "    distance_to_ref = torch.cdist(torch.tensor(traj)[:, :, :2], torch.tensor(oracle_centerline))#.reshape(1, oracle_centerline.shape[0], oracle_centerline.shape[1]))[:, :, :2])\n",
    "    k = torch.argmin(distance_to_ref, dim=-1).view(-1, traj.shape[1], 1).expand(-1, -1, 2)\n",
    "    ref_line = oracle_centerline.clone()#torch.tensor(oracle_centerline.reshape(1, oracle_centerline.shape[0], oracle_centerline.shape[1]))\n",
    "    _ref_points = torch.gather(ref_line, 1, k - torch.ones_like(k))\n",
    "    ref_points = torch.gather(ref_line, 1, k)\n",
    "    ref_points_ = torch.gather(ref_line, 1, k + torch.ones_like(k))\n",
    "    norm = torch.linalg.norm(ref_points_ - _ref_points, dim=2)\n",
    "    _ref_points_3d = torch.zeros((ref_points.shape[0], ref_points.shape[1], 3)); _ref_points_3d[:, :, 0] = _ref_points[:, :, 0]; _ref_points_3d[:, :, 1] = _ref_points[:, :, 1]\n",
    "    ref_points_3d = torch.zeros((ref_points.shape[0], ref_points.shape[1], 3)); ref_points_3d[:, :, 0] = ref_points[:, :, 0]; ref_points_3d[:, :, 1] = ref_points[:, :, 1]\n",
    "    ref_points__3d = torch.zeros((ref_points.shape[0], ref_points.shape[1], 3)); ref_points__3d[:, :, 0] = ref_points_[:, :, 0]; ref_points__3d[:, :, 1] = ref_points_[:, :, 1]\n",
    "    traj_3d = torch.zeros((traj.shape[0], traj.shape[1], 3)); traj_3d[:, :, 0] = torch.tensor(traj[:, :, 0]); traj_3d[:, :, 1] = torch.tensor(traj[:, :, 1])\n",
    "\n",
    "    prp = torch.linalg.cross(ref_points__3d - traj_3d, ref_points__3d - _ref_points_3d, dim=2)[:, :, 2]\n",
    "    norm = torch.linalg.norm(ref_points_ - _ref_points, dim=2)\n",
    "    d = torch.div(prp, norm)\n",
    "    s = 0.5 * torch.argmin(distance_to_ref, dim=-1)\n",
    "    return torch.stack([s, d], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "from av2.geometry.interpolate import compute_midpoint_line, interp_arc\n",
    "from av2.geometry.polyline_utils import centerline_to_polygon\n",
    "from shapely.geometry import LineString, Point, Polygon\n",
    "from spline import Spline2D\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def rotate(gt_x, gt_y,theta):\n",
    "    gt_x_x = [ (gt_x[k] * np.cos(theta) - gt_y[k] * np.sin(theta))  for k in range(len(gt_x))]\n",
    "    gt_y_y = [ (gt_x[k] * np.sin(theta) + gt_y[k] * np.cos(theta))  for k in range(len(gt_x))]\n",
    "    gt_x = gt_x_x\n",
    "    gt_y = gt_y_y\n",
    "    return gt_x, gt_y\n",
    "\n",
    "# Custom Dataset Loader \n",
    "class TrajDataset(Dataset):\n",
    "    \"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "    def __init__(self, dataset_path, source_path, debug=False):\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.source_path = source_path\n",
    "        self.files = os.listdir(DATASET_PATH)\n",
    "        self.debug = debug\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # idx = 11363\n",
    "        debug = self.debug\n",
    "        tracks = np.load(os.path.join(self.dataset_path, self.files[idx], f\"{self.files[idx]}.npy\"), allow_pickle=True)\n",
    "        # [object_state.position[0], object_state.position[1], object_state.heading, object_state.velocity[0], object_state.velocity[1], timestamps_ns[ind], tck[track.category], vmp[track.object_type]\n",
    "        focal_track = None\n",
    "        file = self.files[idx]\n",
    "        for track in tracks: \n",
    "            if track[0][-2] == 3: focal_track = track\n",
    "\n",
    "        agx = np.array(focal_track)[10:50, 0] # position-x\n",
    "        agy = np.array(focal_track)[10:50, 1] # position-y\n",
    "        ox = np.array(focal_track)[50:, 0] # position-x\n",
    "        oy = np.array(focal_track)[50:, 1] # position-y        \n",
    "        \n",
    "        # obtain centerlines\n",
    "        static_map_path = os.path.join(self.source_path, file,  f\"log_map_archive_{file}.json\")\n",
    "        static_map = ArgoverseStaticMap.from_json(Path(static_map_path))\n",
    "        scenario_path = os.path.join(self.source_path, file, f\"scenario_{file}.parquet\")\n",
    "        backbone = get_backbone(agx, agy, static_map_path)\n",
    "        for lane in backbone:\n",
    "            queue = []\n",
    "            cx = get_centerline(static_map, lane)\n",
    "        if debug: plt.axis('equal')\n",
    "        visited = {}\n",
    "        hold_lanes = []\n",
    "        qry_pt = [agx[39], agy[39]]\n",
    "        for lane in backbone:\n",
    "            queue = []\n",
    "            cx = get_centerline(static_map, lane)\n",
    "            if visited.get(lane) == None:\n",
    "                visited[lane] = True\n",
    "                cx = get_centerline(static_map, lane)\n",
    "                distance1 = get_distance(qry_pt, cx[-1])\n",
    "                distance2 = get_distance(qry_pt, cx[0])\n",
    "                hold = []\n",
    "                hold.append(lane)\n",
    "                queue.append([lane, max(distance1, distance2), hold])\n",
    "                hold_lanes = BFS(queue, lane, visited, hold, static_map, qry_pt, hold_lanes)\n",
    "\n",
    "        tx = np.hstack((agx, ox))\n",
    "        ty = np.hstack((agy, oy))\n",
    "        traj = np.dstack((tx, ty))[0]\n",
    "        oracle_centerline = None\n",
    "        max_len = -1e11\n",
    "        # print(idx)\n",
    "        cxs = []\n",
    "        cys = []\n",
    "        for lane in backbone:\n",
    "            cx = get_centerline(static_map, lane)\n",
    "            cxs.append(cx[:, 0])\n",
    "            cys.append(cx[:, 1])            \n",
    "        oracle_ids = None\n",
    "        for hold_lane in hold_lanes:\n",
    "            cxs = []\n",
    "            cys = []\n",
    "            oracle = []\n",
    "            for lane in hold_lane:\n",
    "                cx = get_centerline(static_map, lane)\n",
    "                cxs.append(cx[:, 0])\n",
    "                cys.append(cx[:, 1])\n",
    "                oracle.append(lane)\n",
    "            lane_seq_polygon = centerline_to_polygon(np.dstack((cxs, cys))[0])\n",
    "            total = 0\n",
    "            for xy in traj:\n",
    "                point_in_polygon_score = Polygon(lane_seq_polygon).contains(Point(xy))\n",
    "                total += point_in_polygon_score\n",
    "            if total > max_len:\n",
    "                max_len = total\n",
    "                oracle_ids = oracle\n",
    "                oracle_centerline = np.dstack((cxs, cys))[0]\n",
    "        cxs = []\n",
    "        cys = []\n",
    "        for lane in oracle_ids:\n",
    "            cx = get_centerline(static_map, lane)\n",
    "            for pos in cx:            \n",
    "                cxs.append(pos[0])\n",
    "                cys.append(pos[1])     \n",
    "        oracle_centerline = np.dstack((cxs, cys))[0]\n",
    "        # print(idx)\n",
    "        if debug:\n",
    "            plt.plot(agx, agy, 'b', zorder=4)\n",
    "            plt.plot(ox, oy, 'r', zorder=4)\n",
    "            plt.plot(oracle_centerline[:, 0], oracle_centerline[:, 1], \"ko\")\n",
    "            plt.title(\"before transformation\")\n",
    "            plt.axis('equal')\n",
    "            plt.show()        \n",
    "        \n",
    "        # lanes = extract_lanes(static_map_path, scenario_path, debug=False, sample_len=100)\n",
    "        offsetx = agx[-1]\n",
    "        offsety = agy[-1]\n",
    "        theta = np.arctan2(agy[-1] - agy[-2], agx[-1] - agx[-2])\n",
    "        agx, agy = rotate(agx - offsetx, agy - offsety, -theta)\n",
    "        ox, oy = rotate(ox - offsetx, oy - offsety, -theta)\n",
    "        oracle_centerline_x, oracle_centerline_y = rotate(np.array(cxs) - offsetx, np.array(cys) - offsety, -theta)\n",
    "        oracle_centerline = np.dstack((oracle_centerline_x, oracle_centerline_y))[0]\n",
    "        last_diff = oracle_centerline[-1] - oracle_centerline[-2]\n",
    "        first_diff = oracle_centerline[0] - oracle_centerline[1]\n",
    "        last_diff /= (2 * np.linalg.norm(last_diff))\n",
    "        first_diff /= (2 * np.linalg.norm(first_diff))\n",
    "        num = 100\n",
    "        last = np.linspace(0.5, num, num * 2).reshape(num * 2, 1) @ last_diff.reshape(1, 2) + oracle_centerline[-1]\n",
    "        first = oracle_centerline[0] + np.linspace(num, 0.5, num * 2).reshape(num * 2, 1) @ first_diff.reshape(1, 2)\n",
    "        long_spline = np.concatenate((first, oracle_centerline, last), axis=0)\n",
    "        oracle_centerline_, _ = interp_polyline_by_fixed_waypt_interval(long_spline, 0.5)\n",
    "        if debug:\n",
    "            plt.plot(oracle_centerline_[:, 0], oracle_centerline_[:, 1], \"ko\")\n",
    "            plt.plot(first[:, 0], first[:, 1], \"ro\")\n",
    "            plt.plot(last[:, 0], last[:, 1], \"bo\")\n",
    "            plt.plot(agx, agy, 'b', zorder=4)\n",
    "            plt.plot(ox, oy, 'r', zorder=4)        \n",
    "            # plt.plot(long_spline[:, 0], long_spline[:, 1], \"ko\")\n",
    "            plt.title(\"after transformation\")\n",
    "            plt.axis('equal')\n",
    "            plt.show()\n",
    "        \n",
    "        traj = np.dstack((agx, agy))\n",
    "        oracle_centerline, _ = interp_polyline_by_fixed_waypt_interval(np.dstack((oracle_centerline_x, oracle_centerline_y))[0], 0.5)\n",
    "        # oracle_centerline = np.dstack((oracle_centerline_x, oracle_centerline_y))\n",
    "        # print(len(oracle_centerline))\n",
    "        total_pad = 1000\n",
    "        pad_left = (total_pad - len(oracle_centerline))//2\n",
    "        pad_right = total_pad - pad_left - len(oracle_centerline)\n",
    "        agent_traj = np.dstack((np.hstack((agx, ox)), np.hstack((agy, oy))))\n",
    "        last_diff = oracle_centerline[-1] - oracle_centerline[-2]\n",
    "        first_diff = oracle_centerline[0] - oracle_centerline[1]\n",
    "        last_diff /= (2 * np.linalg.norm(last_diff))\n",
    "        first_diff /= (2 * np.linalg.norm(first_diff))\n",
    "        num = 100\n",
    "        last = np.linspace(0.5, pad_right//2 + 0.5 * (pad_right % 2), pad_right).reshape(pad_right * 2, 1) @ last_diff.reshape(1, 2) + oracle_centerline[-1]\n",
    "        first = oracle_centerline[0] + np.linspace(pad_left, 0.5, pad_left * 2).reshape(pad_left * 2, 1) @ first_diff.reshape(1, 2)\n",
    "        long_spline = np.concatenate((first, oracle_centerline, last), axis=0)\n",
    "        oracle_centerline_, _ = interp_polyline_by_fixed_waypt_interval(long_spline, 0.5)\n",
    "        oracle_centerline_plot = interp_arc(t=agent_traj.shape[1], points=oracle_centerline_[5:-10])\n",
    "        total_traj = np.concatenate((oracle_centerline_plot.reshape(1, 100, 2), agent_traj), axis=1)\n",
    "        oracle_centerline_, _ = interp_polyline_by_fixed_waypt_interval(long_spline, 0.5)        \n",
    "        # inp = []\n",
    "        # out = []\n",
    "        # print(total_traj.shape, oracle_centerline_.shape)\n",
    "        print(len(last), len(first), len(oracle_centerline))\n",
    "        return torch.tensor(total_traj[0]).double(), torch.tensor(oracle_centerline_).double()\n",
    "        # return torch.tensor(inp).double(), torch.tensor(out).double(), torch.tensor(traj_inp).double(), torch.tensor(traj_out).double(), torch.tensor(b_inp).double(), torch.tensor(c).double(), torch.tensor(traj_c).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1000, 2] at entry 0 and [999, 2] at entry 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [199]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TrajDataset(DATASET_PATH, source_path)\n\u001b[1;32m      9\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _ \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m8\u001b[39m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# inp, out, past, future, inputs, c, traj_c = data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m         storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    140\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1000, 2] at entry 0 and [999, 2] at entry 7"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# train_data = np.load(\"../datasets/toy/train_data.npy\", mmap_mode=\"c\")\n",
    "DATASET_PATH =  \"/mnt/e/datasets/argoverse/parsed\"\n",
    "source_path =  \"/mnt/e/datasets/argoverse/val\"\n",
    "sample_len = 100\n",
    "import os\n",
    "files = os.listdir(DATASET_PATH)\n",
    "train_dataset = TrajDataset(DATASET_PATH, source_path)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "for _, data in enumerate(train_loader):\n",
    "    if _ < 8: continue\n",
    "    # inp, out, past, future, inputs, c, traj_c = data\n",
    "    total_traj, oracle_centerline_ = data        \n",
    "\n",
    "    frenet_coordinates = project_to_frenet_frame(total_traj, oracle_centerline_)\n",
    "    # print(frenet_coordinates.shape, \"OOOHHHHHHHHHHHHHHH\")\n",
    "    frenet_coordinates = frenet_coordinates.detach()\n",
    "    frenet_coordinates = frenet_coordinates - frenet_coordinates[:, 139:140,:]\n",
    "    # print(oracle_centerline.shape, traj.shape, k.shape, distance_to_ref.shape, ref_line.shape)    \n",
    "    vels = frenet_coordinates[:, 1:] - frenet_coordinates[:, :-1]\n",
    "    \n",
    "    # print(frenet_coordinates[:, 139:140,:].shape)\n",
    "\n",
    "    inp = torch.zeros((train_loader.batch_size, 200), requires_grad=False)\n",
    "    out = torch.zeros((train_loader.batch_size, 120), requires_grad=False)\n",
    "    inp[:, 0::5] = frenet_coordinates[:, 100:140, 0]\n",
    "    inp[:, 1::5] = frenet_coordinates[:, 100:140, 1]\n",
    "    inp[:, 2::5] = vels[:, 99:139, 0]\n",
    "    inp[:, 3::5] = vels[:, 99:139, 1]\n",
    "    inp[:, 4::5] = 0\n",
    "    out[:, :60] = frenet_coordinates[:, 140:, 0]\n",
    "    out[:, 60:] = frenet_coordinates[:, 140:, 1]\n",
    "    \n",
    "    inp = torch.tensor(inp)\n",
    "    out = torch.tensor(out)\n",
    "    \n",
    "    # for num in range(train_loader.batch_size):\n",
    "    #     plt.plot(frenet_coordinates[num, :100, 0], frenet_coordinates[num, :100, 1], 'ko', zorder=4)        \n",
    "    #     plt.plot(frenet_coordinates[num, 100:140, 0], frenet_coordinates[num, 100:140, 1], 'bo', zorder=5)\n",
    "    #     plt.plot(frenet_coordinates[num, 140:, 0], frenet_coordinates[num, 140:, 1], 'ro', zorder=5)\n",
    "    #     # plt.plot(oss, od, 'r', zorder=4)\n",
    "    #     # plt.plot(cs, cd, \"ko\")\n",
    "    #     plt.title(\"after torch frenet projection\")\n",
    "    #     plt.axis('equal')\n",
    "    #     plt.show()\n",
    "\n",
    "    pass\n",
    "    # break\n",
    "# Using PyTorch Dataloader\n",
    "# train_loader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta_cvae_aug_ddn import Encoder, Decoder, Beta_cVAE, BatchOpt_DDN, DeclarativeLayer\n",
    "from gru_cvae_aug_ddn import GRU_cVAE, DecoderGRU, EncoderGRU\n",
    "\n",
    "# DDN\n",
    "num_batch = train_loader.batch_size\n",
    "node = BatchOpt_DDN(P, Pdot, Pddot, num_batch)\n",
    "opt_layer = DeclarativeLayer(node)\n",
    "\n",
    "# Beta-cVAE Inputs\n",
    "enc_inp_dim = 200\n",
    "enc_out_dim = 120\n",
    "dec_inp_dim = enc_inp_dim\n",
    "dec_out_dim = 8\n",
    "hidden_dim = 1024 * 2\n",
    "z_dim = 2\n",
    "\n",
    "# inp_mean, inp_std = 5.1077423, 20.914295\n",
    "inp_mean, inp_std = 5.1077423, 10.914295\n",
    "\n",
    "encoder = Encoder(enc_inp_dim, enc_out_dim, hidden_dim, z_dim)\n",
    "decoder = Decoder(dec_inp_dim, dec_out_dim, hidden_dim, z_dim)\n",
    "model = Beta_cVAE(encoder, decoder, opt_layer, inp_mean, inp_std).to(device)\n",
    "\n",
    "encoder = EncoderGRU(enc_inp_dim, enc_out_dim, hidden_dim, z_dim, batch_size=num_batch)\n",
    "decoder = DecoderGRU(dec_inp_dim, 2, hidden_dim, z_dim, batch_size=num_batch)\n",
    "model_gru = GRU_cVAE(encoder, decoder, opt_layer, inp_mean, inp_std).to(device)\n",
    "\n",
    "P_ = torch.block_diag(P, P).to(device)\n",
    "Pdot_ = Pdot.to(device)\n",
    "Pddot_ = Pddot.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "step, beta = 0, 3.5\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 1e-4, weight_decay=6e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 12, gamma = 0.1)\n",
    "\n",
    "avg_train_loss, avg_rcl_loss, avg_kl_loss, avg_aug_loss = [], [], [], []\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train Loop\n",
    "    losses_train, kl_losses, rcl_losses, aug_losses = [], [], [], []\n",
    "    model.train()\n",
    "    from tqdm import tqdm\n",
    "    it = 0\n",
    "    for total_traj, oracle_centerline_ in tqdm(train_loader):        \n",
    "        frenet_coordinates = project_to_frenet_frame(total_traj, oracle_centerline_)\n",
    "        # print(frenet_coordinates.shape, \"OOOHHHHHHHHHHHHHHH\")\n",
    "        frenet_coordinates = frenet_coordinates.detach()\n",
    "        frenet_coordinates = frenet_coordinates - frenet_coordinates[:, 139:140,:]\n",
    "        # print(oracle_centerline.shape, traj.shape, k.shape, distance_to_ref.shape, ref_line.shape)    \n",
    "        vels = frenet_coordinates[:, 1:] - frenet_coordinates[:, :-1]\n",
    "\n",
    "        # print(frenet_coordinates[:, 139:140,:].shape)\n",
    "\n",
    "        inp = torch.zeros((train_loader.batch_size, 200), requires_grad=False)\n",
    "        out = torch.zeros((train_loader.batch_size, 120), requires_grad=False)\n",
    "        inp[:, 0::5] = frenet_coordinates[:, 100:140, 0]\n",
    "        inp[:, 1::5] = frenet_coordinates[:, 100:140, 1]\n",
    "        inp[:, 2::5] = vels[:, 99:139, 0]\n",
    "        inp[:, 3::5] = vels[:, 99:139, 1]\n",
    "        inp[:, 4::5] = 0\n",
    "        out[:, :60] = frenet_coordinates[:, 140:, 0]\n",
    "        out[:, 60:] = frenet_coordinates[:, 140:, 1]\n",
    "\n",
    "        # inp = torch.tensor(inp, requires_grad=True)\n",
    "        # out = torch.tensor(out, requires_grad=True)\n",
    "        \n",
    "        it = it + 1\n",
    "        inp = inp.to(device)\n",
    "        out = out.to(device)\n",
    "        \n",
    "\n",
    "        traj_gt = out#torch.cat((out[:, :50], out[:, 50:]))\n",
    "        # z = torch.cat([inp, out], dim = 1)\n",
    "\t\t# Sample from z -> Reparameterized \n",
    "\t\t# z = self._sample_z(mean, std)\n",
    "\t\t\n",
    "\t\t# Decode y\n",
    "\t\t# y_star = self._decoder(z, inp_norm, init_state_ego, y_ub, y_lb)\n",
    "        \n",
    "        # Ego vehicle states\n",
    "        initial_state_ego = inp[:, 2:6].clone()\n",
    "        initial_state_ego[:, 2:4] = initial_state_ego[:, 0:2]\n",
    "        initial_state_ego[:, 0:2] = 0\n",
    "        \n",
    "        mean, std = model._encoder(inp, traj_gt)\n",
    "        z = model._sample_z(mean, std)\n",
    "        y_star = model._decoder(z, inp, initial_state_ego, 0, 0) \n",
    "        traj_sol = (P_ @ y_star.T).T \n",
    "\n",
    "        # Remember to add the Aug Loss\n",
    "        KL_loss, RCL_loss, loss, _ = model.forward(inp, traj_gt, initial_state_ego, P_, Pdot_, Pddot_, beta, step)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses_train.append(loss.detach().cpu().numpy()) \n",
    "        rcl_losses.append(RCL_loss.detach().cpu().numpy())\n",
    "        kl_losses.append(KL_loss.detach().cpu().numpy())\n",
    "        \n",
    "        if it % 5 ==1:\n",
    "            ags = inp[0, 0::5].detach()\n",
    "            agd = inp[0, 1::5].detach()\n",
    "            oss = out[0, :60].detach()\n",
    "            od = out[0, 60:].detach()\n",
    "            pss = traj_sol[0, :60].detach()\n",
    "            pd = traj_sol[0, 60:].detach()\n",
    "            cs = frenet_coordinates[0, :100, 0].detach()\n",
    "            cd = frenet_coordinates[0, :100, 1].detach()\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "            # ax1.plot(ags, agd);\n",
    "            ax1.plot(oss, od);\n",
    "            ax1.plot(pss, pd);\n",
    "            # ax1.plot(cs, cd, \"k--\");\n",
    "            # ax1.axis('equal')\n",
    "            ax2.axis('equal')\n",
    "            plt.axis('equal')\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "            from IPython.display import clear_output\n",
    "            import time\n",
    "            time.sleep(4)\n",
    "            clear_output(wait=True)\n",
    "        \n",
    "        # aug_losses.append(Aug.detach().cpu().numpy())\n",
    "        if it % 5 == 1:\n",
    "            print(f\"Epoch: {epoch + 1}, Train Loss: {np.average(losses_train):.3f}, RCL: {np.average(rcl_losses):.3f}, KL: {np.average(kl_losses):.3f}\") #, Aug: {np.average(aug_losses):.3f}\")\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch: {epoch + 1}, Train Loss: {np.average(losses_train):.3f}, RCL: {np.average(rcl_losses):.3f}, KL: {np.average(kl_losses):.3f}\") #, Aug: {np.average(aug_losses):.3f}\")\n",
    "\n",
    "    step += 1.0\n",
    "    scheduler.step()\n",
    "    avg_train_loss.append(np.average(losses_train)), avg_rcl_loss.append(np.average(rcl_losses)), \\\n",
    "    avg_kl_loss.append(np.average(kl_losses)) #, avg_aug_loss.append(np.average(aug_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 20)\n",
    "y = 2  * x\n",
    "plt.scatter(x, y)\n",
    "point = np.array(y) + 4\n",
    "plt.scatter(x, point)\n",
    "\n",
    "\n",
    "traj = np.dstack((x, point))\n",
    "spline = np.dstack((x, y))[0]\n",
    "print(spline.shape)\n",
    "\n",
    "\n",
    "oracle_centerline = spline\n",
    "last_diff = oracle_centerline[-1] - oracle_centerline[-2]\n",
    "first_diff = oracle_centerline[0] - oracle_centerline[1]\n",
    "last_diff /= (2 * np.linalg.norm(last_diff))\n",
    "first_diff /= (2 * np.linalg.norm(first_diff))\n",
    "num = 100\n",
    "last = np.linspace(0.5, num, num * 2).reshape(num * 2, 1) @ last_diff.reshape(1, 2) + oracle_centerline[-1]\n",
    "first = oracle_centerline[0] + np.linspace(num, 0.5, num * 2).reshape(num * 2, 1) @ first_diff.reshape(1, 2)\n",
    "long_spline = np.concatenate((first, oracle_centerline, last), axis=0)\n",
    "print(get_polyline_length(long_spline)//0.5)\n",
    "print(len(oracle_centerline_))\n",
    "oracle_centerline_, _ = interp_polyline_by_fixed_waypt_interval(long_spline, 0.5)\n",
    "\n",
    "frenet_coordinates = project_to_frenet_frame(traj, oracle_centerline_)\n",
    "\n",
    "plt.plot(spline[:, 0], spline[:, 1])\n",
    "plt.show()\n",
    "print(frenet_coordinates.shape)\n",
    "\n",
    "plt.plot(frenet_coordinates[0, :, 0], frenet_coordinates[0, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "for batch_num, (datas) in enumerate(train_loader):\n",
    "    inp, out = datas\n",
    "    \n",
    "    print(inp.shape, out.shape)\n",
    "        \n",
    "    num = 2\n",
    "    \n",
    "    # # Sanity Check\n",
    "    # x_obs = inp[num].flatten()[5::5]\n",
    "    # y_obs = inp[num].flatten()[6::5]\n",
    "     \n",
    "    # th = np.linspace(0, 2 * np.pi, 100)\n",
    "    plt.figure(1)\n",
    "    \n",
    "    a_obs, b_obs = 5.8, 3.2\n",
    "    \n",
    "    # for i in range(0, 10):\n",
    "    #     x_ell = x_obs[i] + a_obs * np.cos(th)\n",
    "    #     y_ell = y_obs[i] + b_obs * np.sin(th)\n",
    "    #     plt.plot(x_ell, y_ell, '-k', linewidth=1.0)\n",
    "\n",
    "    plt.axis('equal')\n",
    "        \n",
    "    traj_gt = out\n",
    "\n",
    "    # Ego vehicle states\n",
    "    initial_state_ego = inp[:, 2:6]\n",
    "    initial_state_ego[:, 2] = inp[:, 2::5][:, -1]\n",
    "    initial_state_ego[:, 3] = inp[:, 3::5][:, -1]\n",
    "    initial_state_ego[:, 0:2] = 0\n",
    "\n",
    "    mean, std = model._encoder(inp, traj_gt)\n",
    "    z = model._sample_z(mean, std)\n",
    "    y_star = model._decoder(z, inp, initial_state_ego, 0, 0) \n",
    "    traj_sol = (P @ y_star.T).T\n",
    "\n",
    "    ccx = traj_sol[num].flatten()[0:60]\n",
    "    ccy = traj_sol[num].flatten()[60:]\n",
    "    \n",
    "    cx = out[num].flatten()[0:60]\n",
    "    cy = out[num].flatten()[60:]\n",
    "    \n",
    "    x_gt =  cx\n",
    "    y_gt =  cy\n",
    "\n",
    "    x_gt_ =  ccx\n",
    "    y_gt_ =  ccy    \n",
    "    \n",
    "    x_obs = inp[0::5]\n",
    "    y_obs = inp[1::5]\n",
    "    \n",
    "    ag_x = inp[num].flatten()[0::5]\n",
    "    ag_y = inp[num].flatten()[1::5]    \n",
    "\n",
    "    # plt.plot(ag_x.numpy(), ag_y.numpy(), label=\"Observed\", color=\"blue\")    \n",
    "    plt.plot(x_gt.numpy(), y_gt.numpy(), label=\"Ground Truth\", color=\"red\")\n",
    "    plt.plot(x_gt_.detach().numpy(), y_gt_.detach().numpy(), label=\"Predicted\", color=\"orange\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"argoverse_figs/{batch_num}_{num}.png\")\n",
    "    plt.clf()\n",
    "    # plt.show()\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './Weights/cvae_aug_mse.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "from av2.geometry.interpolate import compute_midpoint_line, interp_arc\n",
    "from av2.geometry.polyline_utils import centerline_to_polygon\n",
    "from shapely.geometry import LineString, Point, Polygon\n",
    "from spline import Spline2D\n",
    "# Custom Dataset Loader \n",
    "class TrajDataset(Dataset):\n",
    "    \"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        # Inputs\n",
    "        self.inp = data[:, 0:55]\n",
    "        \n",
    "        # Outputs\n",
    "        self.out = data[:, 55:]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inp)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Inputs\n",
    "        inp = self.inp[idx]\n",
    "        \n",
    "        # Outputs\n",
    "        out = self.out[idx]\n",
    "                 \n",
    "        return torch.tensor(inp).double(), torch.tensor(out).double()\n",
    "\n",
    "def rotate(gt_x, gt_y,theta):\n",
    "    gt_x_x = [ (gt_x[k] * np.cos(theta) - gt_y[k] * np.sin(theta))  for k in range(len(gt_x))]\n",
    "    gt_y_y = [ (gt_x[k] * np.sin(theta) + gt_y[k] * np.cos(theta))  for k in range(len(gt_x))]\n",
    "    gt_x = gt_x_x\n",
    "    gt_y = gt_y_y\n",
    "    return gt_x, gt_y\n",
    "    \n",
    "# Load the dataset\n",
    "# train_data = np.load(\"../datasets/toy/train_data.npy\", mmap_mode=\"c\")\n",
    "DATASET_PATH =  \"/mnt/e/datasets/argoverse/parsed\"\n",
    "import os\n",
    "files = os.listdir(DATASET_PATH)\n",
    "\n",
    "# Custom Dataset Loader \n",
    "class TrajDataset(Dataset):\n",
    "    \"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "    def __init__(self, dataset_path):\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.files = os.listdir(DATASET_PATH)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(os.path.join(self.dataset_path, self.files[idx], f\"{self.files[idx]}.npy\"), allow_pickle=True)\n",
    "        map_info = np.load(os.path.join(self.dataset_path, self.files[idx], f\"lanes_{self.files[idx]}.npy\"), allow_pickle=True)\n",
    "        agent, obstacle_tracks = None, []\n",
    "        # [object_state.position[0], object_state.position[1], object_state.heading, object_state.velocity[0], object_state.velocity[1], timestamps_ns[ind], tck[track.category], vmp[track.object_type]\n",
    "        # 5s of input of agent and 4 obstacles, 5s of output\n",
    "        inp = np.zeros((200))\n",
    "        out = np.zeros((120))\n",
    "        if debug: fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        for tracks in arr:\n",
    "            if tracks[0][-2] == 3:\n",
    "                # FOCAL TRACK\n",
    "                agent = tracks\n",
    "                last_obs = np.array(tracks)[-1]\n",
    "                last_obs_x = last_obs[0]\n",
    "                last_obs_y = last_obs[1]\n",
    "                last_obs_vel_x = last_obs[3]\n",
    "                last_obs_vel_y = last_obs[4]\n",
    "                for i in range(np.array(tracks).shape[0], 110):\n",
    "                    timestep = (i - np.array(tracks).shape[0] + 1)\n",
    "                    tracks.append([last_obs_x + last_obs_vel_x * timestep, last_obs_y + last_obs_vel_y * timestep, last_obs[2], last_obs_vel_x, last_obs_vel_y, i, last_obs[-2], last_obs[-1]])\n",
    "                agx = np.array(tracks)[10:50, 0] # position-x\n",
    "                agy = np.array(tracks)[10:50, 1] # position-y\n",
    "                offsetx = agx[-1]\n",
    "                offsety = agy[-1]\n",
    "                theta = np.arctan2(agy[-1] - agy[-2], agx[-1] - agx[-2])\n",
    "                ox = np.array(tracks)[50:, 0] # position-x\n",
    "                oy = np.array(tracks)[50:, 1] # position-x\n",
    "                if debug: ax1.plot(agx - offsetx, agy - offsety, color=\"blue\", linewidth=3, zorder=3)\n",
    "                if debug: ax1.plot(ox - offsetx, oy - offsety, color=\"orange\", linewidth=3, zorder=3)\n",
    "                agx, agy = rotate(agx - offsetx, agy - offsety, -theta)\n",
    "                ox, oy = rotate(ox - offsetx, oy - offsety, -theta)\n",
    "                vx = np.array(tracks)[10:50, 3] # velocity-x\n",
    "                vy = np.array(tracks)[10:50, 4] # velocity-y\n",
    "                vx, vy = rotate(vx, vy, -theta)\n",
    "                \n",
    "                hold_lanes = np.array(map_info[0])\n",
    "                \n",
    "                max_ind = 0\n",
    "                max_val = -1e11\n",
    "                colors = [\"r\", \"g\", \"b\", \"o\", \"p\", \"r\", \"g\", \"b\", \"o\", \"p\", \"r\", \"g\", \"b\", \"o\", \"p\", \"r\", \"g\", \"b\", \"o\", \"p\"]\n",
    "                for lane_num in range(len(hold_lanes)//100):\n",
    "                    wx = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 3].astype(float)\n",
    "                    wy = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 4].astype(float)\n",
    "                    wwx = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 6].astype(float)\n",
    "                    wwy = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 7].astype(float)\n",
    "                    # print(np.array(c_lane).shape, \"len of c_lane\")\n",
    "                    c = np.array(hold_lanes[(lane_num * 100):((lane_num + 1)*100), 2])\n",
    "                    cx = []\n",
    "                    cy = []\n",
    "                    for pt in c:\n",
    "                        cx.append(pt[0])\n",
    "                        cy.append(pt[1])   \n",
    "                    c = np.dstack((cx, cy))[0]\n",
    "                    print(type(c), c.shape)\n",
    "                    lane_seq_polygon = centerline_to_polygon(c)\n",
    "                    point_in_polygon_score = 0\n",
    "                    for xy in np.dstack((agx, agy))[0]:\n",
    "                        point_in_polygon_score += Polygon(lane_seq_polygon).contains(Point(xy))\n",
    "                        if point_in_polygon_score > max_val:\n",
    "                            max_val = point_in_polygon_score\n",
    "                            max_ind = lane_num\n",
    "                    if debug: ax1.plot(cx - offsetx, cy - offsety, f\"{colors[lane_num]}--\", linewidth=2)\n",
    "                    cx, cy = rotate(cx - offsetx, cy - offsety, -theta)\n",
    "                    if debug: ax2.plot(cx, cy, \"g--\", linewidth=2)\n",
    "                            \n",
    "\n",
    "                hold_lanes = np.array(map_info[0])\n",
    "                lane_num = max_ind\n",
    "                wx = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 3].astype(float)\n",
    "                wy = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 4].astype(float)\n",
    "                wwx = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 6].astype(float)\n",
    "                wwy = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 7].astype(float)\n",
    "                # print(np.array(c_lane).shape, \"len of c_lane\")\n",
    "                c = np.array(hold_lanes[(lane_num * 100):((lane_num + 1)*100), 2])\n",
    "                cx = []\n",
    "                cy = []\n",
    "                for pt in c:\n",
    "                    cx.append(pt[0])\n",
    "                    cy.append(pt[1])   \n",
    "                c = np.dstack((cx, cy))[0]\n",
    "                            \n",
    "                            \n",
    "                # cx = [:, 0]\n",
    "                # cy = np.array(hold_lanes[(lane_num * 100):((lane_num + 1)*100), 2])[:, 1]\n",
    "                # print(len(cx), len(cy), \"CHAGGA\")\n",
    "                # plt.plot(wx, wy, \"b\", linewidth=3)\n",
    "                # cx = compute_midpoint_line(np.dstack((wx, wy))[0], np.dstack((wwx, wwy))[0])\n",
    "                # print(np.array(cx).shape, \"shape\")\n",
    "                c = np.dstack((cx, cy))\n",
    "                ag = np.dstack((agx, agy))\n",
    "                o = np.dstack((ox, oy))\n",
    "\n",
    "                spline = Spline2D(c[0][:, 0], c[0][:, 1])\n",
    "                ags = []\n",
    "                agd = []\n",
    "                oss = []\n",
    "                od = []                \n",
    "                cs = []\n",
    "                cd = []\n",
    "                for pos in ag[0]:\n",
    "                    s, d = spline.calc_frenet_position(pos[0], pos[1])\n",
    "                    ags.append(s)\n",
    "                    agd.append(d)\n",
    "                \n",
    "                for pos in o[0]:\n",
    "                    s, d = spline.calc_frenet_position(pos[0], pos[1])\n",
    "                    oss.append(s)\n",
    "                    od.append(d)\n",
    "\n",
    "                for pos in c[0]:\n",
    "                    s, d = spline.calc_frenet_position(pos[0], pos[1])\n",
    "                    cs.append(s)\n",
    "                    cd.append(d)\n",
    "\n",
    "                offset_s, offset_d = ags[-1], agd[-1]\n",
    "                ags = np.array(ags) - offset_s\n",
    "                agd = np.array(agd) - offset_d\n",
    "                oss = np.array(oss) - offset_s\n",
    "                od = np.array(od) - offset_d\n",
    "                cs = np.array(cs) - offset_s\n",
    "                cd = np.array(cd) - offset_d     \n",
    "                    \n",
    "                vs = (np.array(ags)[1:] - np.array(ags)[:-1])/0.1\n",
    "                vd = (np.array(agd)[1:] - np.array(agd)[:-1])/0.1\n",
    "                vs_init = (np.array(ags)[-1] - np.array(oss)[0])/0.1\n",
    "                vd_init = (np.array(agd)[-1] - np.array(od)[0])/0.1                    \n",
    "                \n",
    "                if debug: ax3.plot(ags, agd, color=\"blue\")\n",
    "                if debug: ax3.plot(oss, od, color=\"orange\")\n",
    "                if debug: ax3.plot(cs, cd, color=\"green\")                \n",
    "\n",
    "                ref_line = torch.tensor(c)\n",
    "                traj = torch.tensor(ag)\n",
    "                \n",
    "                # project_to_frenet_frame(traj, ref_line)\n",
    "                if debug: ax1.axis('equal')\n",
    "                if debug: ax2.axis('equal')\n",
    "                if debug: ax3.axis('equal')\n",
    "                \n",
    "                \n",
    "                inp[0::5] = ags\n",
    "                inp[1::5] = agd\n",
    "                inp[2::5] = vs_init\n",
    "                inp[3::5] = vd_init\n",
    "                inp[7::5] = vs\n",
    "                inp[8::5] = vd\n",
    "                inp[4::5] = np.array(tracks)[10:50, 2] - theta # heading\n",
    "                out[:60] = oss\n",
    "                out[60:] = od\n",
    "                c = np.dstack((cs, cd))[0]\n",
    "                traj_inp = np.hstack((agx, agy)).flatten()\n",
    "                traj_out = np.hstack((ox, oy)).flatten()\n",
    "                traj_c = np.hstack((cx, cy)).flatten()\n",
    "                if debug: ax2.plot(agx, agy, color=\"blue\", linewidth=3, zorder=3)\n",
    "                if debug: ax2.plot(ox, oy, color=\"orange\", linewidth=3, zorder=3)                \n",
    "                b_inp = np.array([agx[-1], agy[-1], vx[-1], vy[-1], 0, 0])\n",
    "        return torch.tensor(inp).double(), torch.tensor(out).double(), torch.tensor(traj_inp).double(), torch.tensor(traj_out).double(), torch.tensor(b_inp).double(), torch.tensor(c).double(), torch.tensor(traj_c).double()\n",
    "\n",
    "train_dataset = TrajDataset(DATASET_PATH)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "for _, data in enumerate(train_loader):\n",
    "    inp, out, past, future, inputs, c, traj_c = data\n",
    "    ags = inp[0, 0::5].detach()\n",
    "    agd = inp[0, 1::5].detach()\n",
    "    oss = out[0, :60].detach()\n",
    "    od = out[0, 60:].detach()\n",
    "    cs = c[0,: ,0].detach()\n",
    "    cd = c[0,: ,1].detach()    \n",
    "    agx = past[0, :40].detach()\n",
    "    agy = past[0, 40:].detach()\n",
    "    ox = future[0, :60].detach()\n",
    "    oy = future[0, 60:].detach()    \n",
    "    cx = traj_c[0,:100].detach()\n",
    "    cy = traj_c[0,100:].detach()\n",
    "    # print(traj_c.shape, c.shape, past.shape, future.shape)\n",
    "    # print(c.shape)\n",
    "    # fig, (ax2, ax1) = plt.subplots(1, 2, figsize=(15,5))\n",
    "    # ax1.plot(ags, agd);\n",
    "    # ax1.plot(oss, od);\n",
    "    # ax1.plot(cs, cd, \"g--\");\n",
    "    # ax1.axis('equal')\n",
    "    # ax1.set_title(\"Frenet Frame\")\n",
    "    # ax2.plot(agx, agy);\n",
    "    # ax2.plot(ox, oy);\n",
    "    # ax2.plot(cx, cy, \"g--\");\n",
    "    # ax2.axis('equal')\n",
    "    # ax2.set_title(\"Global Frame\")\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"debug/{_}.png\")\n",
    "    plt.clf()\n",
    "    from IPython.display import clear_output\n",
    "    import time\n",
    "    time.sleep(3)\n",
    "    clear_output(wait=True)\n",
    "    # break\n",
    "    pass\n",
    "# Using PyTorch Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "from av2.geometry.interpolate import compute_midpoint_line, interp_arc\n",
    "from av2.geometry.polyline_utils import centerline_to_polygon\n",
    "from shapely.geometry import LineString, Point, Polygon\n",
    "from spline import Spline2D\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def rotate(gt_x, gt_y,theta):\n",
    "    gt_x_x = [ (gt_x[k] * np.cos(theta) - gt_y[k] * np.sin(theta))  for k in range(len(gt_x))]\n",
    "    gt_y_y = [ (gt_x[k] * np.sin(theta) + gt_y[k] * np.cos(theta))  for k in range(len(gt_x))]\n",
    "    gt_x = gt_x_x\n",
    "    gt_y = gt_y_y\n",
    "    return gt_x, gt_y\n",
    "\n",
    "# Custom Dataset Loader \n",
    "class TrajDataset(Dataset):\n",
    "    \"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "    def __init__(self, dataset_path, source_path):\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.source_path = source_path\n",
    "        self.files = os.listdir(DATASET_PATH)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(os.path.join(self.dataset_path, self.files[idx], f\"{self.files[idx]}.npy\"), allow_pickle=True)\n",
    "        map_info = np.load(os.path.join(self.dataset_path, self.files[idx], f\"lanes_{self.files[idx]}.npy\"), allow_pickle=True)\n",
    "        agent, obstacle_tracks = None, []\n",
    "        # [object_state.position[0], object_state.position[1], object_state.heading, object_state.velocity[0], object_state.velocity[1], timestamps_ns[ind], tck[track.category], vmp[track.object_type]\n",
    "        # 5s of input of agent and 4 obstacles, 5s of output\n",
    "        inp = np.zeros((200))\n",
    "        out = np.zeros((120))\n",
    "        if debug: fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        file = self.files[idx]\n",
    "        static_map_path = os.path.join(self.source_path, file,  f\"log_map_archive_{file}.json\")\n",
    "        scenario_path = os.path.join(self.source_path, file, f\"scenario_{file}.parquet\")\n",
    "        \n",
    "        # lanes = extract_lanes(static_map_path, scenario_path, debug=False, sample_len=100)\n",
    "        focal_track = None\n",
    "        for tracks in arr:\n",
    "            if tracks[0][-2] == 3:\n",
    "                # FOCAL TRACK\n",
    "                agent = tracks\n",
    "                focal_track = tracks\n",
    "        tracks = focal_track\n",
    "        last_obs = np.array(tracks)[-1]\n",
    "        last_obs_x = last_obs[0]\n",
    "        last_obs_y = last_obs[1]\n",
    "        last_obs_vel_x = last_obs[3]\n",
    "        last_obs_vel_y = last_obs[4]\n",
    "        for i in range(np.array(tracks).shape[0], 110):\n",
    "            timestep = (i - np.array(tracks).shape[0] + 1)\n",
    "            tracks.append([last_obs_x + last_obs_vel_x * timestep, last_obs_y + last_obs_vel_y * timestep, last_obs[2], last_obs_vel_x, last_obs_vel_y, i, last_obs[-2], last_obs[-1]])\n",
    "        agx = np.array(tracks)[10:50, 0] # position-x\n",
    "        agy = np.array(tracks)[10:50, 1] # position-y\n",
    "        \n",
    "        offsetx = agx[-1]\n",
    "        offsety = agy[-1]\n",
    "        theta = np.arctan2(agy[-1] - agy[-2], agx[-1] - agx[-2])\n",
    "        ox = np.array(tracks)[50:, 0] # position-x\n",
    "        oy = np.array(tracks)[50:, 1] # position-x\n",
    "        import copy\n",
    "        aagx = copy.deepcopy(agx)\n",
    "        aagy = copy.deepcopy(agy)\n",
    "        oox = copy.deepcopy(ox)\n",
    "        ooy = copy.deepcopy(oy)                \n",
    "        \n",
    "        if debug: ax1.plot(agx - offsetx, agy - offsety, color=\"blue\", linewidth=3, zorder=3)\n",
    "        if debug: ax1.plot(ox - offsetx, oy - offsety, color=\"orange\", linewidth=3, zorder=3)\n",
    "        agx, agy = rotate(agx - offsetx, agy - offsety, -theta)\n",
    "        ox, oy = rotate(ox - offsetx, oy - offsety, -theta)\n",
    "        vx = np.array(tracks)[10:50, 3] # velocity-x\n",
    "        vy = np.array(tracks)[10:50, 4] # velocity-y\n",
    "        vx, vy = rotate(vx, vy, -theta)\n",
    "\n",
    "        # hold_lanes = np.array(map_info[0])\n",
    "        # getting the backbone\n",
    "        static_map = ArgoverseStaticMap.from_json(Path(static_map_path))\n",
    "        backbones = []\n",
    "        for tm in range(0, 40):\n",
    "            min_ind = get_nearest_centerline(agx, agy, static_map, tm=tm)\n",
    "            cx = get_centerline(static_map, min_ind)\n",
    "            lane_seg = static_map.vector_lane_segments[min_ind]\n",
    "            if tm == 0:\n",
    "                backbones.append([min_ind])\n",
    "                continue\n",
    "            last_lane = backbones[-1][-1]\n",
    "            if min_ind == last_lane:\n",
    "                continue\n",
    "            fg = True\n",
    "            for backbone in backbones:\n",
    "                if min_ind in backbone:\n",
    "                    fg = False\n",
    "                if min_ind in static_map.vector_lane_segments[backbone[-1]].successors:\n",
    "                    backbone.append(min_ind)\n",
    "                    fg = False\n",
    "            if fg:\n",
    "                backbones.append([min_ind])\n",
    "            # plt.plot(cx[:, 0], cx[:, 1])\n",
    "\n",
    "        for backbone in backbones:\n",
    "            import random\n",
    "            # color = \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "            for min_ind in backbone:\n",
    "                cx = get_centerline(static_map, min_ind)\n",
    "                # plt.plot(cx[:, 0], cx[:, 1], color=color)\n",
    "\n",
    "        max_backbone = None\n",
    "        max_len = -1e11\n",
    "        for backbone in backbones:\n",
    "            total = 0\n",
    "            for lane in backbone:\n",
    "                cx = get_centerline(static_map, lane)\n",
    "                total += get_polyline_length(cx)\n",
    "            if total > max_len:\n",
    "                max_len = total\n",
    "                max_backbone = backbone\n",
    "\n",
    "        MAX_DIS = 300\n",
    "\n",
    "        hold_lanes = []\n",
    "        import copy\n",
    "\n",
    "        qry_pt = [agx[39], agy[39]]\n",
    "\n",
    "        def BFS(queue, lane_id, visited, hold, static_map):\n",
    "            while len(queue):\n",
    "                [cur, distance, hold] = queue.pop(0)\n",
    "                if distance > MAX_DIS:\n",
    "                    hold_lanes.append(hold)\n",
    "                    continue\n",
    "                successors = static_map.vector_lane_segments[cur].successors\n",
    "                done = False\n",
    "                for successor in successors:\n",
    "                    if visited.get(successor) == None:\n",
    "                        # not visited\n",
    "                        try:\n",
    "                            static_map.vector_lane_segments[successor]\n",
    "                            hold_ = copy.deepcopy(hold)\n",
    "                            hold_.append(successor)\n",
    "                            cx = get_centerline(static_map, successor)\n",
    "                            distance1 = get_distance(qry_pt, cx[-1])\n",
    "                            distance2 = get_distance(qry_pt, cx[0])\n",
    "                            queue.append([successor, max(distance1, distance2), hold_])\n",
    "                            visited[successor] = True\n",
    "                        except:\n",
    "                            done = True\n",
    "                if done:\n",
    "                    hold_lanes.append(hold)\n",
    "                    pass\n",
    "                if len(successors) == 0:\n",
    "                    # end of the line\n",
    "                    hold_lanes.append(hold)\n",
    "                    pass\n",
    "\n",
    "        # hold\n",
    "        visited = {}\n",
    "        for lane in backbone:\n",
    "            queue = []\n",
    "            if visited.get(lane) == None:\n",
    "                visited[lane] = True\n",
    "                cx = get_centerline(static_map, lane)\n",
    "                distance1 = get_distance(qry_pt, cx[-1])\n",
    "                distance2 = get_distance(qry_pt, cx[0])\n",
    "                hold = []\n",
    "                hold.append(lane)\n",
    "                queue.append([lane, max(distance1, distance2), hold])\n",
    "                BFS(queue, lane, visited, hold, static_map)\n",
    "                cnt = 0\n",
    "                for lanes in hold_lanes:\n",
    "                    color = \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "                    for lane_ in lanes:\n",
    "                        # if cnt == 1: print(\"BAZINGA\", lane_)\n",
    "                        cx = get_centerline(static_map, lane_)\n",
    "                        # if debug: plt.plot(cx[:, 0], cx[:, 1], color=color)\n",
    "                    cnt = cnt + 1\n",
    "                    # if debug: plt.scatter(agx[:50], agy[:50], color=\"blue\", zorder=10)\n",
    "                    # if debug: plt.scatter(agx[50:], agy[50:], color=\"orange\", zorder=10)                    \n",
    "                    # # if debug: plt.axis('equal')\n",
    "                    # if debug: plt.xlim([np.min(agx) - 100, np.max(agx) + 100])\n",
    "                    # if debug: plt.ylim([np.min(agy) - 150, np.max(agy) + 150])                \n",
    "                    # if debug: plt.show()\n",
    "                    # if debug: plt.clf()\n",
    "\n",
    "        hold_array = hold_lanes\n",
    "        lanes = []\n",
    "        for lane in hold_array:\n",
    "            lane_information = []\n",
    "            for lane_id in lane:\n",
    "                # if cnt == 1: print(\"LAUWA LAUWA\", lane_id)\n",
    "                wx = [waypt.x for waypt in static_map.vector_lane_segments[lane_id].left_lane_boundary.waypoints]\n",
    "                wy = [waypt.y for waypt in static_map.vector_lane_segments[lane_id].left_lane_boundary.waypoints]\n",
    "                wwx = [waypt.x for waypt in static_map.vector_lane_segments[lane_id].right_lane_boundary.waypoints]\n",
    "                wwy = [waypt.y for waypt in static_map.vector_lane_segments[lane_id].right_lane_boundary.waypoints]\n",
    "                left_boundary = np.dstack((wx, wy))[0]\n",
    "                right_boundary = np.dstack((wwx, wwy))[0]\n",
    "                left_boundary = interp_arc(t=100, points=left_boundary)\n",
    "                right_boundary = interp_arc(t=100, points=right_boundary)\n",
    "                cx = get_centerline(static_map, lane_id)\n",
    "                cx = interp_arc(t=sample_len, points=cx)\n",
    "                is_intersection = static_map.vector_lane_segments[lane_id].is_intersection\n",
    "                lane_type = static_map.vector_lane_segments[lane_id].lane_type.name\n",
    "                left_mark_type = static_map.vector_lane_segments[lane_id].left_mark_type.name\n",
    "                right_mark_type = static_map.vector_lane_segments[lane_id].right_mark_type.name\n",
    "                for ind in range(sample_len):\n",
    "                    lane_information.append([is_intersection, lane_type, cx[ind],\n",
    "                                            left_boundary[ind][0], left_boundary[ind][1], left_mark_type, \n",
    "                                             right_boundary[ind][0], right_boundary[ind][1], right_mark_type, cx[ind][0],  cx[ind][1]])\n",
    "                    pass\n",
    "            lanes.append(lane_information)\n",
    "\n",
    "\n",
    "        max_ind = 0\n",
    "        max_val = -1e11\n",
    "        hold_lanes = np.array(lanes[0])\n",
    "        colors = [\"r\", \"g\", \"r\", \"y\", \"b\", \"r\", \"g\", \"r\", \"y\", \"b\", \"r\", \"g\", \"r\", \"y\", \"b\"]\n",
    "        for lane_num in range(len(hold_lanes)//100):\n",
    "            wx = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 3].astype(float)\n",
    "            wy = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 4].astype(float)\n",
    "            wwx = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 6].astype(float)\n",
    "            wwy = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 7].astype(float)\n",
    "            ccx = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 9].astype(float)\n",
    "            ccy = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 10].astype(float)\n",
    "            plt.plot(ccx, ccy, color=\"green\")\n",
    "            # print(np.array(c_lane).shape, \"len of c_lane\")\n",
    "            c = np.array(hold_lanes[(lane_num * 100):((lane_num + 1)*100), 2])\n",
    "            cx = []\n",
    "            cy = []\n",
    "            for pt in c:\n",
    "                cx.append(pt[0])\n",
    "                cy.append(pt[1])   \n",
    "            c = np.dstack((cx, cy))[0]\n",
    "            print(type(c), c.shape)\n",
    "            lane_seq_polygon = centerline_to_polygon(c)\n",
    "            point_in_polygon_score = 0\n",
    "            for xy in np.dstack((agx, agy))[0]:\n",
    "                point_in_polygon_score += Polygon(lane_seq_polygon).contains(Point(xy))\n",
    "                if point_in_polygon_score > max_val:\n",
    "                    max_val = point_in_polygon_score\n",
    "                    max_ind = lane_num\n",
    "            if debug: ax1.plot(ccx - offsetx, ccy - offsety, f\"{colors[lane_num]}--\", linewidth=2)\n",
    "            cx, cy = rotate(ccx - offsetx, ccy - offsety, -theta)\n",
    "            if debug: ax2.plot(cx, cy, \"g--\", linewidth=2)\n",
    "        plt.plot(aagx, aagy, color=\"blue\")\n",
    "        plt.plot(oox, ooy, color=\"orange\")\n",
    "        plt.show()\n",
    "        hold_lanes = np.array(map_info[0])\n",
    "        lane_num = 0\n",
    "        wx = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 3].astype(float)\n",
    "        wy = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 4].astype(float)\n",
    "        wwx = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 6].astype(float)\n",
    "        wwy = hold_lanes[(lane_num * 100):((lane_num + 1)*100), 7].astype(float)\n",
    "        # print(np.array(c_lane).shape, \"len of c_lane\")\n",
    "        c = np.array(hold_lanes[(lane_num * 100):((lane_num + 1)*100), 2])\n",
    "        cx = []\n",
    "        cy = []\n",
    "        for pt in c:\n",
    "            cx.append(pt[0])\n",
    "            cy.append(pt[1])   \n",
    "        c = np.dstack((cx, cy))[0]\n",
    "\n",
    "\n",
    "        # cx = [:, 0]\n",
    "        # cy = np.array(hold_lanes[(lane_num * 100):((lane_num + 1)*100), 2])[:, 1]\n",
    "        # print(len(cx), len(cy), \"CHAGGA\")\n",
    "        # plt.plot(wx, wy, \"b\", linewidth=3)\n",
    "        # cx = compute_midpoint_line(np.dstack((wx, wy))[0], np.dstack((wwx, wwy))[0])\n",
    "        # print(np.array(cx).shape, \"shape\")\n",
    "        c = np.dstack((cx, cy))\n",
    "        ag = np.dstack((agx, agy))\n",
    "        o = np.dstack((ox, oy))\n",
    "\n",
    "        spline = Spline2D(c[0][:, 0], c[0][:, 1])\n",
    "        ags = []\n",
    "        agd = []\n",
    "        oss = []\n",
    "        od = []                \n",
    "        cs = []\n",
    "        cd = []\n",
    "        for pos in ag[0]:\n",
    "            s, d = spline.calc_frenet_position(pos[0], pos[1])\n",
    "            ags.append(s)\n",
    "            agd.append(d)\n",
    "\n",
    "        for pos in o[0]:\n",
    "            s, d = spline.calc_frenet_position(pos[0], pos[1])\n",
    "            oss.append(s)\n",
    "            od.append(d)\n",
    "\n",
    "        for pos in c[0]:\n",
    "            s, d = spline.calc_frenet_position(pos[0], pos[1])\n",
    "            cs.append(s)\n",
    "            cd.append(d)\n",
    "\n",
    "        offset_s, offset_d = ags[-1], agd[-1]\n",
    "        ags = np.array(ags) - offset_s\n",
    "        agd = np.array(agd) - offset_d\n",
    "        oss = np.array(oss) - offset_s\n",
    "        od = np.array(od) - offset_d\n",
    "        cs = np.array(cs) - offset_s\n",
    "        cd = np.array(cd) - offset_d     \n",
    "\n",
    "        vs = (np.array(ags)[1:] - np.array(ags)[:-1])/0.1\n",
    "        vd = (np.array(agd)[1:] - np.array(agd)[:-1])/0.1\n",
    "        vs_init = (np.array(ags)[-1] - np.array(oss)[0])/0.1\n",
    "        vd_init = (np.array(agd)[-1] - np.array(od)[0])/0.1                    \n",
    "\n",
    "        if debug: ax3.plot(ags, agd, color=\"blue\")\n",
    "        if debug: ax3.plot(oss, od, color=\"orange\")\n",
    "        if debug: ax3.plot(cs, cd, color=\"green\")                \n",
    "\n",
    "        ref_line = torch.tensor(c)\n",
    "        traj = torch.tensor(ag)\n",
    "\n",
    "        # project_to_frenet_frame(traj, ref_line)\n",
    "        if debug: ax1.axis('equal')\n",
    "        if debug: ax2.axis('equal')\n",
    "        if debug: ax3.axis('equal')\n",
    "\n",
    "\n",
    "        inp[0::5] = ags\n",
    "        inp[1::5] = agd\n",
    "        inp[2::5] = vs_init\n",
    "        inp[3::5] = vd_init\n",
    "        inp[7::5] = vs\n",
    "        inp[8::5] = vd\n",
    "        inp[4::5] = np.array(tracks)[10:50, 2] - theta # heading\n",
    "        out[:60] = oss\n",
    "        out[60:] = od\n",
    "        c = np.dstack((cs, cd))[0]\n",
    "        traj_inp = np.hstack((agx, agy)).flatten()\n",
    "        traj_out = np.hstack((ox, oy)).flatten()\n",
    "        traj_c = np.hstack((cx, cy)).flatten()\n",
    "        if debug: ax2.plot(agx, agy, color=\"blue\", linewidth=3, zorder=3)\n",
    "        if debug: ax2.plot(ox, oy, color=\"orange\", linewidth=3, zorder=3)                \n",
    "        b_inp = np.array([agx[-1], agy[-1], vx[-1], vy[-1], 0, 0])\n",
    "        return torch.tensor(inp).double(), torch.tensor(out).double(), torch.tensor(traj_inp).double(), torch.tensor(traj_out).double(), torch.tensor(b_inp).double(), torch.tensor(c).double(), torch.tensor(traj_c).double()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c562111517df06ec79e2a0b366e2ca57c1da3a77768b6967f7ee5330ff1fbc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
