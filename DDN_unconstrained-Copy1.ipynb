{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"./ddn/\")\n",
    "sys.path.append(\"./\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from bernstein import bernstesin_coeff_order10_new\n",
    "from utils import *\n",
    "from ddn.pytorch.node import AbstractDeclarativeNode\n",
    "\n",
    "from argoverse.map_representation.map_api import ArgoverseMap\n",
    "from argoverse.data_loading.argoverse_forecasting_loader import ArgoverseForecastingLoader\n",
    "from argoverse.visualization.visualize_sequences import viz_sequence\n",
    "avm = ArgoverseMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !TMPDIR=/home/vikrant pip install --cache-dir=/home/vikrant/ --build /home/vikrant/ pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernstein_coeff_order10_new(n, tmin, tmax, t_actual):\n",
    "    l = tmax - tmin\n",
    "    t = (t_actual - tmin) / l\n",
    "\n",
    "    P0 = scipy.special.binom(n, 0) * ((1 - t) ** (n - 0)) * t ** 0\n",
    "    P1 = scipy.special.binom(n, 1) * ((1 - t) ** (n - 1)) * t ** 1\n",
    "    P2 = scipy.special.binom(n, 2) * ((1 - t) ** (n - 2)) * t ** 2\n",
    "    P3 = scipy.special.binom(n, 3) * ((1 - t) ** (n - 3)) * t ** 3\n",
    "    P4 = scipy.special.binom(n, 4) * ((1 - t) ** (n - 4)) * t ** 4\n",
    "    P5 = scipy.special.binom(n, 5) * ((1 - t) ** (n - 5)) * t ** 5\n",
    "    P6 = scipy.special.binom(n, 6) * ((1 - t) ** (n - 6)) * t ** 6\n",
    "    P7 = scipy.special.binom(n, 7) * ((1 - t) ** (n - 7)) * t ** 7\n",
    "    P8 = scipy.special.binom(n, 8) * ((1 - t) ** (n - 8)) * t ** 8\n",
    "    P9 = scipy.special.binom(n, 9) * ((1 - t) ** (n - 9)) * t ** 9\n",
    "    P10 = scipy.special.binom(n, 10) * ((1 - t) ** (n - 10)) * t ** 10\n",
    "\n",
    "    P0dot = -10.0 * (-t + 1) ** 9\n",
    "    P1dot = -90.0 * t * (-t + 1) ** 8 + 10.0 * (-t + 1) ** 9\n",
    "    P2dot = -360.0 * t ** 2 * (-t + 1) ** 7 + 90.0 * t * (-t + 1) ** 8\n",
    "    P3dot = -840.0 * t ** 3 * (-t + 1) ** 6 + 360.0 * t ** 2 * (-t + 1) ** 7\n",
    "    P4dot = -1260.0 * t ** 4 * (-t + 1) ** 5 + 840.0 * t ** 3 * (-t + 1) ** 6\n",
    "    P5dot = -1260.0 * t ** 5 * (-t + 1) ** 4 + 1260.0 * t ** 4 * (-t + 1) ** 5\n",
    "    P6dot = -840.0 * t ** 6 * (-t + 1) ** 3 + 1260.0 * t ** 5 * (-t + 1) ** 4\n",
    "    P7dot = -360.0 * t ** 7 * (-t + 1) ** 2 + 840.0 * t ** 6 * (-t + 1) ** 3\n",
    "    P8dot = 45.0 * t ** 8 * (2 * t - 2) + 360.0 * t ** 7 * (-t + 1) ** 2\n",
    "    P9dot = -10.0 * t ** 9 + 9 * t ** 8 * (-10.0 * t + 10.0)\n",
    "    P10dot = 10.0 * t ** 9\n",
    "\n",
    "    P0ddot = 90.0 * (-t + 1) ** 8\n",
    "    P1ddot = 720.0 * t * (-t + 1) ** 7 - 180.0 * (-t + 1) ** 8\n",
    "    P2ddot = 2520.0 * t ** 2 * (-t + 1) ** 6 - 1440.0 * t * (-t + 1) ** 7 + 90.0 * (-t + 1) ** 8\n",
    "    P3ddot = 5040.0 * t ** 3 * (-t + 1) ** 5 - 5040.0 * t ** 2 * (-t + 1) ** 6 + 720.0 * t * (-t + 1) ** 7\n",
    "    P4ddot = 6300.0 * t ** 4 * (-t + 1) ** 4 - 10080.0 * t ** 3 * (-t + 1) ** 5 + 2520.0 * t ** 2 * (-t + 1) ** 6\n",
    "    P5ddot = 5040.0 * t ** 5 * (-t + 1) ** 3 - 12600.0 * t ** 4 * (-t + 1) ** 4 + 5040.0 * t ** 3 * (-t + 1) ** 5\n",
    "    P6ddot = 2520.0 * t ** 6 * (-t + 1) ** 2 - 10080.0 * t ** 5 * (-t + 1) ** 3 + 6300.0 * t ** 4 * (-t + 1) ** 4\n",
    "    P7ddot = -360.0 * t ** 7 * (2 * t - 2) - 5040.0 * t ** 6 * (-t + 1) ** 2 + 5040.0 * t ** 5 * (-t + 1) ** 3\n",
    "    P8ddot = 90.0 * t ** 8 + 720.0 * t ** 7 * (2 * t - 2) + 2520.0 * t ** 6 * (-t + 1) ** 2\n",
    "    P9ddot = -180.0 * t ** 8 + 72 * t ** 7 * (-10.0 * t + 10.0)\n",
    "    P10ddot = 90.0 * t ** 8\n",
    "    90.0 * t ** 8\n",
    "\n",
    "    P = np.hstack((P0, P1, P2, P3, P4, P5, P6, P7, P8, P9, P10))\n",
    "    Pdot = np.hstack((P0dot, P1dot, P2dot, P3dot, P4dot, P5dot, P6dot, P7dot, P8dot, P9dot, P10dot)) / l\n",
    "    Pddot = np.hstack((P0ddot, P1ddot, P2ddot, P3ddot, P4ddot, P5ddot, P6ddot, P7ddot, P8ddot, P9ddot, P10ddot)) / (l ** 2)\n",
    "    return P, Pdot, Pddot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rho_obs = 0.3\n",
    "rho_obs = 1.2\n",
    "rho_eq = 10.0\n",
    "weight_smoothness = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 30\n",
    "t_fin = 5\n",
    "a_obs = 1.0\n",
    "b_obs = 1.0\n",
    "\n",
    "tot_time = np.linspace(0.0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "P, Pdot, Pddot = bernstein_coeff_order10_new(num, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "nvar = np.shape(P)[1]\n",
    "nvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_obs_temp = np.hstack((-10.0, -10.79, -10, -10))\n",
    "# y_obs_temp = np.hstack((10.0, 15.0, 15, 15))\n",
    "x_obs_temp = np.hstack((-2.0, -5.79, 3.0, 4.0))\n",
    "y_obs_temp = np.hstack((-2.0, 2.0, -0.80, 2.0))\n",
    "num_obs = np.shape(x_obs_temp)[0]\n",
    "\n",
    "x_obs = np.ones((num_obs, num)) * x_obs_temp[:, np.newaxis]\n",
    "y_obs = np.ones((num_obs, num)) * y_obs_temp[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_inp_list = []\n",
    "for i in range(num_obs):\n",
    "    obs_inp_list.extend([x_obs_temp[i], y_obs_temp[i], a_obs])\n",
    "\n",
    "obs_inp = np.array(obs_inp_list)\n",
    "# obs_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_obs = np.tile(P, (num_obs, 1))\n",
    "A_eq = np.vstack((P[0], Pdot[0], Pddot[0], P[-1], Pdot[-1], Pddot[-1]))\n",
    "Q_smoothness = np.dot(Pddot.T, Pddot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPTNode(AbstractDeclarativeNode):\n",
    "    def __init__(self, P, Pddot, A_eq, A_obs, Q_smoothness, x_obs, y_obs, num=12, num_obs=4, nvar=11, a_obs=1.0, b_obs=1.0, rho_obs=0.3, rho_eq=10.0, weight_smoothness=10, maxiter=300, eps=1e-7, num_tot=48):\n",
    "        super().__init__()\n",
    "        self.P = torch.tensor(P, dtype=torch.double).to(device)\n",
    "        self.Pddot = torch.tensor(Pddot, dtype=torch.double).to(device)\n",
    "        self.A_eq = torch.tensor(A_eq, dtype=torch.double).to(device)\n",
    "        self.A_obs = torch.tensor(A_obs, dtype=torch.double).to(device)\n",
    "        self.Q_smoothness = torch.tensor(Q_smoothness, dtype=torch.double).to(device)\n",
    "        self.x_obs = torch.tensor(x_obs, dtype=torch.double).to(device)\n",
    "        self.y_obs = torch.tensor(y_obs, dtype=torch.double).to(device)\n",
    "        \n",
    "        self.num = num\n",
    "        self.num_obs = num_obs\n",
    "        self.eps = eps\n",
    "        self.nvar = nvar        \n",
    "        self.a_obs = a_obs\n",
    "        self.b_obs = b_obs        \n",
    "        self.rho_eq = rho_eq\n",
    "        self.num_obs = num_obs\n",
    "        self.maxiter = maxiter\n",
    "        self.num_tot = num_tot\n",
    "        self.rho_obs = rho_obs\n",
    "        self.weight_smoothness = weight_smoothness\n",
    "        \n",
    "    def objective(self, b, lamda_x, lamda_y, y):  \n",
    "        batch_size, _ = b.size()\n",
    "        b = b.transpose(0, 1)\n",
    "        y = y.transpose(0, 1)\n",
    "        lamda_x = lamda_x.transpose(0, 1)\n",
    "        lamda_y = lamda_y.transpose(0, 1)\n",
    "        bx_eq_tensor, by_eq_tensor = torch.split(b, 6, dim=0)\n",
    "        ones_tensor = torch.ones(self.num_tot, batch_size, dtype=torch.double).to(device)\n",
    "\n",
    "        c_x = y[0:self.nvar]\n",
    "        c_y = y[self.nvar:2 * self.nvar]\n",
    "\n",
    "        cost_smoothness_x = 0.5 * self.weight_smoothness * torch.diag(torch.matmul(c_x.T, torch.matmul(self.Q_smoothness, c_x)))\n",
    "        cost_smoothness_y = 0.5 * self.weight_smoothness * torch.diag(torch.matmul(c_y.T, torch.matmul(self.Q_smoothness, c_y)))\n",
    "\n",
    "        cost_eq_x = 0.5 * self.rho_eq * torch.sum((torch.matmul(self.A_eq, c_x) - bx_eq_tensor) ** 2, axis=0)\n",
    "        cost_eq_y = 0.5 * self.rho_eq * torch.sum((torch.matmul(self.A_eq, c_y) - by_eq_tensor) ** 2, axis=0)\n",
    "\n",
    "        cost_x = cost_smoothness_x + cost_eq_x - torch.diag(torch.matmul(lamda_x.transpose(0, 1), c_x))\n",
    "        cost_y = cost_smoothness_y + cost_eq_y - torch.diag(torch.matmul(lamda_y.transpose(0, 1), c_y))\n",
    "\n",
    "        cost = cost_x + cost_y + self.eps * torch.sum(c_x ** 2, axis=0) + self.eps * torch.sum(c_y ** 2, axis=0)# + self.eps * torch.sum(d_obs ** 2, axis=0) + self.eps * torch.sum(alpha_obs ** 2, axis=0) + cost_slack\n",
    "        return cost\n",
    "    \n",
    "    def optimize(self, b, lamda_x, lamda_y):\n",
    "        bx_eq_tensor, by_eq_tensor = torch.split(b, 6, dim=0)\n",
    "        \n",
    "        d_obs = torch.ones(self.num_obs, self.num, dtype=torch.double).to(device)\n",
    "        alpha_obs = torch.zeros(self.num_obs, self.num, dtype=torch.double).to(device)\n",
    "        ones_tensor = torch.ones((self.num_obs, self.num), dtype=torch.double).to(device)\n",
    "        cost_smoothness = self.weight_smoothness * torch.matmul(self.Pddot.T, self.Pddot)\n",
    "        cost = cost_smoothness + self.rho_eq * torch.matmul(self.A_eq.T, self.A_eq)\n",
    "\n",
    "        for i in range(self.maxiter):\n",
    "            lincost_x = -lamda_x - self.rho_eq * torch.matmul(self.A_eq.T, bx_eq_tensor)\n",
    "            lincost_y = -lamda_y - self.rho_eq * torch.matmul(self.A_eq.T, by_eq_tensor)          \n",
    "            \n",
    "            lincost_x = lincost_x.view(-1, 1)\n",
    "            lincost_y = lincost_y.view(-1, 1)\n",
    "            \n",
    "            sol_x, _ = torch.solve(lincost_x, -cost)\n",
    "            sol_y, _ = torch.solve(lincost_y, -cost)\n",
    "\n",
    "            sol_x = sol_x.view(-1)\n",
    "            sol_y = sol_y.view(-1)\n",
    "\n",
    "            x = torch.matmul(self.P, sol_x)\n",
    "            y = torch.matmul(self.P, sol_y)\n",
    "\n",
    "            res_eq_x_vec = torch.matmul(self.A_eq, sol_x) - bx_eq_tensor\n",
    "            res_eq_y_vec = torch.matmul(self.A_eq, sol_y) - by_eq_tensor\n",
    "\n",
    "            lamda_x -= self.rho_eq * torch.matmul(self.A_eq.T, res_eq_x_vec)\n",
    "            lamda_y -= self.rho_eq * torch.matmul(self.A_eq.T, res_eq_y_vec)\n",
    "\n",
    "        sol = torch.cat([sol_x, sol_y])\n",
    "        return sol\n",
    "        \n",
    "    def solve(self, b, lamda_x, lamda_y):\n",
    "        batch_size, _ = b.size()\n",
    "        b = b.transpose(0, 1)\n",
    "        lamda_x = lamda_x.transpose(0, 1)\n",
    "        lamda_y = lamda_y.transpose(0, 1)\n",
    "        y = torch.zeros(batch_size, 2 * self.nvar, dtype=torch.double).to(device)\n",
    "        for i in range(batch_size):\n",
    "            b_cur = b[:, i]\n",
    "            lamda_x_cur = lamda_x[:, i]\n",
    "            lamda_y_cur = lamda_y[:, i]\n",
    "            sol = self.optimize(b_cur, lamda_x_cur, lamda_y_cur)\n",
    "            y[i, :] = sol\n",
    "        return y, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Declarative Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptFunction(torch.autograd.Function):\n",
    "    \"\"\"Generic declarative autograd function.\n",
    "    Defines the forward and backward functions. Saves all inputs and outputs,\n",
    "    which may be memory-inefficient for the specific problem.\n",
    "    \n",
    "    Assumptions:\n",
    "    * All inputs are PyTorch tensors\n",
    "    * All inputs have a single batch dimension (b, ...)\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, problem, *inputs):\n",
    "        output, solve_ctx = torch.no_grad()(problem.solve)(*inputs)\n",
    "        ctx.save_for_backward(output, *inputs)\n",
    "        ctx.problem = problem\n",
    "        ctx.solve_ctx = solve_ctx\n",
    "        return output.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output, *inputs = ctx.saved_tensors\n",
    "        problem = ctx.problem\n",
    "        solve_ctx = ctx.solve_ctx\n",
    "        output.requires_grad = True\n",
    "        inputs = tuple(inputs)\n",
    "        grad_inputs = problem.gradient(*inputs, y=output, v=grad_output,\n",
    "            ctx=solve_ctx)\n",
    "        return (None, *grad_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Declarative Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptLayer(torch.nn.Module):\n",
    "    \"\"\"Generic declarative layer.\n",
    "    \n",
    "    Assumptions:\n",
    "    * All inputs are PyTorch tensors\n",
    "    * All inputs have a single batch dimension (b, ...)\n",
    "    Usage:\n",
    "        problem = <derived class of *DeclarativeNode>\n",
    "        declarative_layer = DeclarativeLayer(problem)\n",
    "        y = declarative_layer(x1, x2, ...)\n",
    "    \"\"\"\n",
    "    def __init__(self, problem):\n",
    "        super(OptLayer, self).__init__()\n",
    "        self.problem = problem\n",
    "        \n",
    "    def forward(self, *inputs):\n",
    "        return OptFunction.apply(self.problem, *inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TrajNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajNet(nn.Module):\n",
    "    def __init__(self, opt_layer, P, input_size=16, hidden_size=64, output_size=12, nvar=11, t_obs=8):\n",
    "        super(TrajNet, self).__init__()\n",
    "        self.P = torch.tensor(P, dtype=torch.double).to(device)\n",
    "        self.nvar = nvar\n",
    "        self.t_obs = t_obs\n",
    "        self.linear1 = nn.Linear(input_size, 64)\n",
    "        self.lstm = nn.LSTMCell(64, 32)\n",
    "        self.linear2 = nn.Linear(64, output_size)\n",
    "        self.opt_layer = opt_layer\n",
    "        self.activation = nn.ReLU()\n",
    "        self.mask = torch.tensor([[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]], dtype=torch.double)\n",
    "    \n",
    "    def forward(self, x, b):\n",
    "        batch_size, _ = x.size()\n",
    "        out = self.activation(self.linear1(x))\n",
    "#         out = self.lstm(out)[0]\n",
    "        b_pred = self.linear2(out)\n",
    "        b_gen = self.mask * b + (1 - self.mask) * b_pred\n",
    "        \n",
    "        print(b_pred.shape)\n",
    "        print(b_gen.shape)\n",
    "        # Run optimization\n",
    "        lamda_x = torch.zeros(batch_size, self.nvar, dtype=torch.double).to(device)\n",
    "        lamda_y = torch.zeros(batch_size, self.nvar, dtype=torch.double).to(device)\n",
    "        sol = self.opt_layer(b_gen, lamda_x, lamda_y)\n",
    "        # Compute final trajectory\n",
    "        x_pred = torch.matmul(self.P, sol[:, :self.nvar].transpose(0, 1))\n",
    "        y_pred = torch.matmul(self.P, sol[:, self.nvar:2*self.nvar].transpose(0, 1))\n",
    "        \n",
    "        x_pred = x_pred.transpose(0, 1)\n",
    "        y_pred = y_pred.transpose(0, 1)\n",
    "        out = torch.cat([x_pred, y_pred], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_node = OPTNode(\n",
    "    P, \n",
    "    Pddot, \n",
    "    A_eq,\n",
    "    A_obs, \n",
    "    Q_smoothness, \n",
    "    x_obs,\n",
    "    y_obs,\n",
    "    num=num, \n",
    "    num_obs=num_obs, \n",
    "    nvar=nvar, \n",
    "    a_obs=a_obs, \n",
    "    b_obs=b_obs, \n",
    "    rho_obs=rho_obs, \n",
    "    rho_eq=rho_eq,\n",
    "    weight_smoothness=weight_smoothness, \n",
    "    maxiter=300, \n",
    "    eps=1e-7, \n",
    "    num_tot=num*num_obs\n",
    ")\n",
    "opt_layer = OptLayer(opt_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elems = 5\n",
    "total_size = 20 * 2 + 4 #+ num_elems * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrajNet(opt_layer, P, total_size)\n",
    "model = model.double()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = torch.randn(10, total_size, dtype=torch.double)\n",
    "y_out = torch.randn(10, 60, dtype=torch.double)\n",
    "b_inp = torch.randn(10, 12, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 44])\n"
     ]
    }
   ],
   "source": [
    "print(x_inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 12])\n",
      "torch.Size([10, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 60])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(x_inp, b_inp)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    def __init__(self, file_name, t_obs=20, dt=1, num_elems = 5):\n",
    "        self.file_name = file_name\n",
    "        self.t_obs = t_obs\n",
    "        self.dt = dt\n",
    "        self.num_elems = num_elems\n",
    "        self.data = []\n",
    "        with open(file_name, 'rb') as f:\n",
    "            gt = pd.read_pickle(f)\n",
    "            self.gt = gt\n",
    "            data = [[[ j[3], j[4]] for j in gt[\"FEATURES\"].values[i]] for i in range(len(gt[\"FEATURES\"].values))  ]\n",
    "            self.data = np.array(data)[:100]\n",
    "#             print(np.array(data).shape)\n",
    "            self.centerlines = gt[\"ORACLE_CENTERLINE\"].values[:100]\n",
    "#             print(self.data.shape)\n",
    "#             print(self.centerlines.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_vel(self, pos):\n",
    "        return (pos[-1] - pos[-2]) / self.dt\n",
    "    \n",
    "    def get_acc(self, vel):\n",
    "        return (vel[-1] - vel[-2]) / self.dt\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data\n",
    "        x_traj = data[idx][:, 0]\n",
    "        x_traj -= x_traj[0]\n",
    "        y_traj = data[idx][:, 1]\n",
    "        y_traj -= y_traj[0]\n",
    "#         plt.plot(x_traj, y_traj)\n",
    "        \n",
    "        x_inp = x_traj[:self.t_obs]\n",
    "        y_inp = y_traj[:self.t_obs]\n",
    "        x_fut = x_traj[self.t_obs:]\n",
    "        y_fut = y_traj[self.t_obs:]\n",
    "        \n",
    "        vx_beg = (x_inp[-1] - x_inp[-2]) / self.dt\n",
    "        vy_beg = (y_inp[-1] - y_inp[-2]) / self.dt\n",
    "\n",
    "        vx_fin = (x_fut[-1] - x_fut[-2]) / self.dt\n",
    "        vy_fin = (y_fut[-1] - y_fut[-2]) / self.dt\n",
    "        vel_acc = np.array([vx_beg, vy_beg, vx_fin, vy_fin])\n",
    "        traj_inp = np.hstack((x_inp, y_inp)).flatten()\n",
    "        idxs = np.round(np.linspace(0, len(self.centerlines[idx]) - 1, self.num_elems)).astype(int)\n",
    "        cx = [self.centerlines[idx][i][0] for i in idxs]\n",
    "        cy = [self.centerlines[idx][i][1] for i in idxs]\n",
    "#         traj_inp = np.hstack((traj_inp, vel_acc))        \n",
    "#         traj_out = np.hstack((x_fut, y_fut)).flatten()\n",
    "#         b_inp = np.array([x_fut[0], vx_beg, 0, x_fut[-1], 0, 0, y_fut[0], vy_beg, 0, y_fut[-1], 0, 0])    \n",
    "\n",
    "        vx_beg = (x_inp[-1] - x_inp[-2]) / self.dt\n",
    "        vy_beg = (y_inp[-1] - y_inp[-2]) / self.dt\n",
    "        \n",
    "        vx_beg_prev = (x_inp[-2] - x_inp[-3]) / self.dt\n",
    "        vy_beg_prev = (y_inp[-2] - y_inp[-3]) / self.dt\n",
    "        \n",
    "        ax_beg = (vx_beg - vx_beg_prev) / self.dt\n",
    "        ay_beg = (vy_beg - vy_beg_prev) / self.dt\n",
    "        \n",
    "        vel_acc_inp = np.array([vx_beg, vy_beg, ax_beg, ay_beg])\n",
    "        \n",
    "        traj_inp = np.hstack((x_inp, y_inp)).flatten()\n",
    "        traj_inp = np.hstack((traj_inp, vel_acc_inp))\n",
    "        traj_out = np.hstack((x_fut, y_fut)).flatten()\n",
    "#         self.mask = torch.tensor([[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]], dtype=torch.double)        \n",
    "        b_inp = np.array([x_inp[-1], vx_beg, ax_beg, 20, 0, 0, y_inp[-1], vy_beg, ay_beg, 10, 0, 0])        \n",
    "        return torch.tensor(traj_inp), torch.tensor(traj_out), torch.tensor(b_inp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-2d911ea6b29c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train_dataset = ArgoverseDataset(\"/datasets/argoverse/sample.pkl\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArgoverseDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/datasets/argoverse/forecasting_features_val.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-135-b3c6de306f53>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, t_obs, dt, num_elems)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FEATURES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FEATURES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#             print(np.array(data).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-135-b3c6de306f53>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FEATURES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FEATURES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#             print(np.array(data).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-135-b3c6de306f53>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FEATURES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FEATURES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#             print(np.array(data).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_dataset = ArgoverseDataset(\"/datasets/argoverse/sample.pkl\")\n",
    "train_dataset = ArgoverseDataset(\"/datasets/argoverse/forecasting_features_val.pkl\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traj(cnt, traj_inp, traj_out, traj_pred, obs=[], b_inp = []):\n",
    "    traj_inp = traj_inp.numpy()\n",
    "    traj_out = traj_out.numpy()\n",
    "    traj_pred = traj_pred.detach().numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax.scatter(traj_inp[:20], traj_inp[20:40], label='Inp traj')\n",
    "    ax.scatter(traj_out[:30], traj_out[30:], label='GT')\n",
    "    ax.scatter(traj_pred[:30], traj_pred[30:], label='Pred')\n",
    "\n",
    "    ax.scatter(b_inp[0], b_inp[6], label='Initial')\n",
    "    ax.scatter(b_inp[3], b_inp[9], label='Final')\n",
    "    ax.legend()\n",
    "    plt.savefig('./results/{}.png'.format(cnt))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i, data in enumerate(train_loader):\n",
    "    cnt = cnt + 1\n",
    "    traj_inp, traj_out, b_inp = data\n",
    "#     print(traj_inp.size(), traj_out.size(), b_inp.size())\n",
    "    out = model(traj_inp, b_inp)\n",
    "#     print(np.hstack((traj_inp[0], traj_out[0])).shape)\n",
    "#     np.save(\"data.npy\", np.hstack((traj_inp[0], traj_out[0])))\n",
    "#     print(traj_inp[0][:20])\n",
    "#     print(traj_inp[0][20:40])\n",
    "#     print(traj_out[0][:30])\n",
    "#     print(b_inp[0])\n",
    "#     print(i)\n",
    "    for ii in range(traj_inp.shape[0]):\n",
    "        plot_traj(ii, traj_inp[ii], traj_out[ii], out[ii], obs=[], b_inp = b_inp[ii])\n",
    "    if cnt > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_inp.size(), traj_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 0, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 0, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 1, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 1, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 2, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 2, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 3, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 3, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 4, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 4, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 5, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 5, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 6, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 6, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 7, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 7, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 8, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 8, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 9, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 9, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 10, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 10, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 11, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 11, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 12, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 12, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 13, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 13, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 14, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 14, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 15, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 15, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 16, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 16, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 17, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 17, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 18, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 18, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 19, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 19, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 20, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 20, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 21, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 21, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 22, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 22, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 23, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 23, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 24, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 24, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 25, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 25, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 26, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 26, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 27, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 27, Mean Loss: 591.8002266694109\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "Epoch: 28, Batch: 0, Loss: 538.7529514255356\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n",
      "torch.Size([20, 12])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-49a1965ad7e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/obstacle.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj_inp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mplot_traj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_obs_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_obs_temp\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_inp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-d241577c6449>\u001b[0m in \u001b[0;36mplot_traj\u001b[0;34m(cnt, traj_inp, traj_out, traj_pred, obs, b_inp)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Final'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./results/{}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3003\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2253\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \"\"\"\n\u001b[1;32m    508\u001b[0m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         mpl.image.imsave(\n\u001b[0m\u001b[1;32m    510\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1616\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"eXIf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m     \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_train_loss = []\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        traj_inp, traj_out, b_inp = data\n",
    "        traj_inp = traj_inp.to(device)\n",
    "        traj_out = traj_out.to(device)\n",
    "        b_inp = b_inp.to(device)\n",
    "\n",
    "        out = model(traj_inp, b_inp)\n",
    "        loss = criterion(out, traj_out)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        cnt = 0\n",
    "        obs = np.load(\"train/obstacle.npy\")\n",
    "        for i in range(traj_inp.size()[0]):\n",
    "            plot_traj(cnt, traj_inp[i], traj_out[i], out[i], {\"x\": x_obs_temp, \"y\": y_obs_temp}, b_inp=b_inp[i])\n",
    "            cnt += 1\n",
    "        \n",
    "        if batch_num % 10 == 0:\n",
    "            print(\"Epoch: {}, Batch: {}, Loss: {}\".format(epoch, batch_num, loss.item()))\n",
    "    \n",
    "    mean_loss = np.mean(train_loss)\n",
    "    epoch_train_loss.append(mean_loss)\n",
    "    print(\"Epoch: {}, Mean Loss: {}\".format(epoch, mean_loss))\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traj(1, traj_inp, traj_out, traj_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    cnt = 0\n",
    "    test_loss = []\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        traj_inp, traj_out, b_inp = data\n",
    "        traj_inp = traj_inp.to(device)\n",
    "        traj_out = traj_out.to(device)\n",
    "        b_inp = b_inp.to(device)\n",
    "\n",
    "        out = model(traj_inp, b_inp)\n",
    "        loss = criterion(out, traj_out)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        obs = np.load(\"train/obstacle.npy\")\n",
    "        print(\"Batch: {}, Loss: {}\".format(batch_num, loss.item()))\n",
    "        for i in range(traj_inp.size()[0]):\n",
    "            plot_traj(cnt, traj_inp[i], traj_out[i], out[i], {\"x\": obs[i][0], \"y\": obs[i][1]})\n",
    "            cnt += 1\n",
    "mean_loss = np.mean(test_loss)\n",
    "print(\"Epoch Mean Test Loss: {}\".format(mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_inp.numpy()[0][:2*num].shape, traj_out.numpy()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_inp[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_out[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sqrt(torch.sum((traj_out[6] - out[6]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = torch.tensor([traj_out[6][1], traj_out[6][23]])\n",
    "fin_pred = torch.tensor([out[6][11], out[6][23]])\n",
    "fin, fin_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sqrt(torch.sum((fin_pred - fin) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sqrt(torch.sum((traj_out[6][-1] - out[6][-1]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(traj_out[6], out[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_traj(cnt, traj_inp, traj_out, traj_pred):\n",
    "    traj_inp = traj_inp.numpy()\n",
    "    traj_out = traj_out.numpy()\n",
    "    traj_pred = traj_pred.numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax.scatter(traj_inp[::2], traj_inp[1::2], label='Inp traj')\n",
    "    ax.scatter(traj_out[:12], traj_out[12:], label='GT')\n",
    "    ax.scatter(traj_out[11], traj_out[23], label='Fin GT')\n",
    "    ax.scatter(traj_pred[:12], traj_pred[12:], label='Pred')\n",
    "    ax.scatter(traj_pred[11], traj_pred[23], label='Fin Pred')\n",
    "    \n",
    "    th = np.linspace(0, 2 * np.pi, 100)\n",
    "    for i in range(0, num_obs):\n",
    "        x_circ = x_obs_temp[i] + a_obs * np.cos(th)\n",
    "        y_circ = y_obs_temp[i] + b_obs * np.sin(th)\n",
    "        ax.plot(x_circ, y_circ, '-k')\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_xlim([-7, 7])\n",
    "    ax.set_ylim([-7, 7])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_traj(0, traj_inp[8], traj_out[8], out[8].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8e207cadf0>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr = np.load('train/test.npy')\n",
    "print(arr.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
