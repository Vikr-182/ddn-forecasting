{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.append(\"/Users/shashanks./Downloads/Installations/ddn/\")\n",
    "sys.path.append(\"./ddn/\")\n",
    "sys.path.append(\"./\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bernstein import bernstein_coeff_order10_new\n",
    "from ddn.pytorch.node import AbstractDeclarativeNode\n",
    "\n",
    "from utils.viz_helpers import plot_traj\n",
    "from utils.metrics import get_ade, get_fde\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(gt_x, gt_y, w = 7):\n",
    "    # denoising\n",
    "    w = w\n",
    "    gt_x_t = []\n",
    "    gt_y_t = []\n",
    "    for iq in range(len(gt_x)):\n",
    "        if iq >= w and iq + w <= len(gt_x):\n",
    "            gt_x_t.append(np.average(gt_x[iq: iq + w]))\n",
    "            gt_y_t.append(np.average(gt_y[iq: iq + w]))\n",
    "        elif iq < w:\n",
    "            okx = np.average(gt_x[w: w + w])\n",
    "            gt_x_t.append(gt_x[0] + (okx - gt_x[0]) * (iq) / w)\n",
    "            oky = np.average(gt_y[w: w + w])\n",
    "            gt_y_t.append(gt_y[0] + (oky - gt_y[0]) * (iq) / w)\n",
    "        else:\n",
    "            okx = np.average(gt_x[len(gt_x) - w:len(gt_x) - w  + w])\n",
    "            oky = np.average(gt_y[len(gt_x) - w: len(gt_x) - w + w])\n",
    "            gt_x_t.append(okx + (gt_x[-1] - okx) * (w - (len(gt_x) - iq)) / w)\n",
    "            gt_y_t.append(oky + (gt_y[-1] - oky) * (w - (len(gt_y) - iq)) / w)                   \n",
    "\n",
    "    gt_x = gt_x_t\n",
    "    gt_y = gt_y_t\n",
    "    return gt_x, gt_y\n",
    "\n",
    "def rotate(gt_x, gt_y,theta):\n",
    "    gt_x_x = [ (gt_x[k] * np.cos(theta) - gt_y[k] * np.sin(theta))  for k in range(len(gt_x))]\n",
    "    gt_y_y = [ (gt_x[k] * np.sin(theta) + gt_y[k] * np.cos(theta))  for k in range(len(gt_x))]\n",
    "    gt_x = gt_x_x\n",
    "    gt_y = gt_y_y\n",
    "    return gt_x, gt_y\n",
    "\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    def __init__(self, data_path, t_obs=16, dt=0.125,centerline_dir=None, include_centerline = False):\n",
    "        self.data = np.load(data_path)\n",
    "        self.data_path = data_path\n",
    "        self.t_obs = t_obs\n",
    "        self.dt = dt\n",
    "        self.include_centerline = include_centerline\n",
    "        self.centerline_dir = centerline_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dt = self.dt\n",
    "        traj = self.data[idx]\n",
    "        x_traj = traj[:, 0]\n",
    "        y_traj = traj[:, 1]\n",
    "        \n",
    "        x_traj -= x_traj[0]\n",
    "        y_traj -= y_traj[0]\n",
    "        \n",
    "        gt_x = x_traj\n",
    "        gt_y = y_traj\n",
    "        \n",
    "        ind = 1\n",
    "        \n",
    "        if idx == ind:\n",
    "            plt.axis('equal')\n",
    "#             plt.scatter(gt_x, gt_y, color='blue', label='noisy')\n",
    "        \n",
    "        gt_x, gt_y = denoise(gt_x, gt_y)\n",
    "        v_x = [ (gt_x[k + 1] - gt_x[k])/dt  for k in range(len(gt_x) - 1)]\n",
    "        v_y = [ (gt_y[k + 1] - gt_y[k])/dt  for k in range(len(gt_y) - 1)]\n",
    "        psi = [ np.arctan2(v_y[k], v_x[k]) for k in range(len(v_x))]  \n",
    "        \n",
    "        if idx == ind:\n",
    "            plt.axis('equal')\n",
    "#             plt.scatter(gt_x, gt_y, color='purple',label='before')\n",
    "        \n",
    "        # till here, gt-> (50, 1), v -> (49, 1), psi -> (31, 1)\n",
    "        \n",
    "        # obtain this -psi\n",
    "        theta = -psi[self.t_obs - 1]\n",
    "        \n",
    "        # rotate by theta\n",
    "        gt_x, gt_y = rotate(gt_x, gt_y, theta)\n",
    "#         gt_x_x = [ (gt_x[k] * np.cos(theta) - gt_y[k] * np.sin(theta))  for k in range(len(gt_x))]\n",
    "#         gt_y_y = [ (gt_x[k] * np.sin(theta) + gt_y[k] * np.cos(theta))  for k in range(len(gt_x))]\n",
    "#         gt_x = gt_x_x\n",
    "#         gt_y = gt_y_y\n",
    "        if idx == ind:\n",
    "            plt.axis('equal')\n",
    "#             plt.scatter(gt_x, gt_y, color='yellow') \n",
    "        v_x = [ (gt_x[k + 1] - gt_x[k])/dt  for k in range(len(gt_x) - 1)]\n",
    "        v_y = [ (gt_y[k + 1] - gt_y[k])/dt  for k in range(len(gt_y) - 1)]\n",
    "        psi = [ np.arctan2(v_y[k], v_x[k]) for k in range(len(v_x))]\n",
    "        psidot = [ (psi[k + 1] - psi[k])/dt for k in range(len(psi) - 1) ]\n",
    "        psi_traj = [i.item() for i in psi]\n",
    "        psidot_traj = [i.item() for i in psidot]\n",
    "    \n",
    "        \n",
    "        x_traj = gt_x\n",
    "        y_traj = gt_y\n",
    "\n",
    "        x_inp = x_traj[:self.t_obs]\n",
    "        y_inp = y_traj[:self.t_obs]\n",
    "        x_fut = x_traj[self.t_obs:]\n",
    "        y_fut = y_traj[self.t_obs:]\n",
    "#         psi_fut = psi_traj[self.t_obs:]\n",
    "#         psidot_fut = psidot_traj[self.t_obs:]\n",
    "\n",
    "        # till here, gt-> (32, 1), v -> (31, 1), psi -> (31, 1), psidot -> (30, 1)\n",
    "        psi_fut = psi_traj[self.t_obs - 1:]\n",
    "        psidot_fut = psi_traj[self.t_obs - 2:]\n",
    "        \n",
    "        vx_traj = v_x\n",
    "        vy_traj = v_y\n",
    "        \n",
    "        vx_beg = vx_traj[self.t_obs]\n",
    "        vy_beg = vy_traj[self.t_obs]\n",
    "        \n",
    "        vx_beg_prev = vx_traj[self.t_obs - 1]\n",
    "        vy_beg_prev = vy_traj[self.t_obs - 1]\n",
    "        \n",
    "        ax_beg = (vx_beg - vx_beg_prev) / self.dt\n",
    "        ay_beg = (vy_beg - vy_beg_prev) / self.dt\n",
    "\n",
    "        vx_fin = v_x[-1]\n",
    "        vy_fin = v_y[-1]\n",
    "        \n",
    "        vx_fin_prev = v_x[-2]\n",
    "        vy_fin_prev = v_y[-2]\n",
    "\n",
    "        ax_fin = (vx_fin - vx_fin_prev) / self.dt\n",
    "        ay_fin = (vy_fin - vy_fin_prev) / self.dt\n",
    "\n",
    "        x_fut = x_traj[self.t_obs:]\n",
    "        y_fut = y_traj[self.t_obs:]\n",
    "\n",
    "        traj_inp = np.vstack((x_inp, y_inp))\n",
    "        traj_inp = np.swapaxes(traj_inp, 0, 1)\n",
    "        if self.include_centerline:\n",
    "            cs = np.load(self.centerline_dir)[idx]\n",
    "            data = np.load(self.data_path)\n",
    "\n",
    "            c_x = cs[:, 0]            \n",
    "            c_y = cs[:, 1]\n",
    "            c_x -= data[idx][0,0]\n",
    "            c_y -= data[idx][0,1]\n",
    "            c_x, c_y = denoise(c_x, c_y)\n",
    "#             if idx == ind:\n",
    "#                 plt.plot(c_x, c_y, color='black', label='grey')\n",
    "            \n",
    "            # rotate by theta\n",
    "            c_x, c_y = rotate(c_x, c_y, theta)\n",
    "            c_x -= c_x[0]\n",
    "            c_y -= c_y[0]\n",
    "            c_x += x_inp[-1]\n",
    "            c_y += y_inp[-1]\n",
    "        \n",
    "#             c_y += y_inp[-1] + 2\n",
    "            c_inp = np.dstack((c_x, c_y)).flatten()\n",
    "            traj_inp = np.hstack((traj_inp, c_inp))\n",
    "\n",
    "        vx_fut = vx_traj[self.t_obs:]\n",
    "        vy_fut = vy_traj[self.t_obs:]\n",
    "        traj_out = np.vstack((x_fut, y_fut))#.flatten()\n",
    "        traj_out = np.swapaxes(traj_out, 0, 1)\n",
    "        \n",
    "        fixed_params = np.array([x_fut[0], y_fut[0], 0, psi_fut[0], psidot_fut[0]])\n",
    "        var_inp = np.array([x_inp[-1], y_inp[-1], psi_fut[-1]])\n",
    "\n",
    "#             print(fixed_params)\n",
    "#             print(var_inp)\n",
    "#         return torch.tensor(traj_inp, dtype=torch.float32).flatten(), torch.tensor(traj_out, dtype=torch.float32).flatten(), torch.tensor(fixed_params), torch.tensor(var_inp)\n",
    "        return torch.tensor(traj_inp, dtype=torch.float32), torch.tensor(traj_out, dtype=torch.float32), torch.tensor(fixed_params), torch.tensor(var_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajNet(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=16, embedding_size = 2, output_size=2, nvar=11, t_obs=8, num_layers = 1):\n",
    "        super(TrajNet, self).__init__()\n",
    "        self.nvar = nvar\n",
    "        self.t_obs = t_obs\n",
    "        self.linear1 = nn.Linear(input_size, embedding_size)\n",
    "#         self.linear2 = nn.Linear(embedding_size, output_size)\n",
    "        self.linear2 = nn.Linear(output_size, embedding_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "        self.lstm1 = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.lstm2 = nn.LSTMCell(embedding_size, hidden_size)        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = nn.ReLU()\n",
    "        self.mask = torch.tensor([[0.0, 0.0, 1.0]], dtype=torch.double).to(device)\n",
    "    \n",
    "    def forward(self, x, fixed_params, var_inp):\n",
    "        batch_size, _, _ = x.size()\n",
    "        out = x\n",
    "        encoder_hidden = (torch.zeros(batch_size, self.hidden_size, dtype=torch.float32), torch.zeros(batch_size, self.hidden_size, dtype=torch.float32))\n",
    "#         hidden = self.lstm1(embedded, hidden)\n",
    "        \n",
    "        for i in range(20):\n",
    "            encoder_input = x[:, i, :]\n",
    "            embedded = self.activation(self.linear1(encoder_input))\n",
    "            encoder_hidden = self.lstm1(embedded, encoder_hidden)\n",
    "        \n",
    "        decoder_input = encoder_input[:, :2]\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        decoder_outputs = torch.zeros(20, 30, 2)\n",
    "        for i in range(30):\n",
    "            embedded = self.activation(self.linear2(decoder_input))\n",
    "            decoder_hidden = self.lstm2(embedded, decoder_hidden)\n",
    "            decoder_output = self.linear3(decoder_hidden[0])\n",
    "            decoder_input = decoder_output\n",
    "            decoder_outputs[:, i, :] = decoder_output\n",
    "        # Run optimization\n",
    "        return decoder_outputs\n",
    "#         out = self.activation(self.linear1(out))\n",
    "#         out = self.activation(self.linear2(out))\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 30\n",
    "t_obs = 20\n",
    "num_elems = 15\n",
    "include_centerline = False\n",
    "name = \"final_without\" if include_centerline else \"final_with\"\n",
    "lr = 0.001\n",
    "\n",
    "train_dataset = ArgoverseDataset(\"/datasets/argoverse/val_data.npy\", centerline_dir=\"/datasets/argoverse/val_centerlines.npy\", t_obs=20, dt=0.3, include_centerline = include_centerline)\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=False, num_workers=0)\n",
    "\n",
    "test_dataset = ArgoverseDataset(\"/datasets/argoverse/val_test_data.npy\", centerline_dir=\"/datasets/argoverse/val_test_centerlines.npy\", t_obs=20, dt=0.3, include_centerline = include_centerline)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=0)\n",
    "\n",
    "offsets_train = np.load(\"/datasets/argoverse/val_offsets.npy\")\n",
    "# offsets_test = np.load(\"/datasets/argoverse/val_offsets_test.npy\")\n",
    "\n",
    "# model = TrajNet(input_size=t_obs * 2 + include_centerline * num_elems * 2, output_size= num * 2)\n",
    "model = TrajNet()\n",
    "model = model\n",
    "model = model.to(device)\n",
    "# model.lstm1.train()\n",
    "# model.lstm2.train()\n",
    "# model.load_state_dict(torch.load(\"./checkpoints/final.ckpt\"))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20, 2]) torch.Size([20, 30, 2])\n",
      "torch.Size([20, 20, 2]) torch.Size([20, 30, 2]) torch.Size([20, 30, 2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_num, data in enumerate(train_loader):\n",
    "    traj_inp, traj_out, fixed_params, var_inp = data\n",
    "    torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=False)\n",
    "    ade = []\n",
    "    fde = []\n",
    "    print(traj_inp.shape, traj_out.shape)\n",
    "    out = model(traj_inp, fixed_params, var_inp)\n",
    "    plt.scatter(traj_inp[1][:40:2], traj_inp[1][1:40:2], label='inp')\n",
    "    plt.scatter(traj_out[1][:60:2], traj_out[1][1:60:2], label='gt')\n",
    "    plt.scatter(out[1][:60:2].detach(), out[1][1:60:2].detach(), label='pred')\n",
    "    print(traj_inp.shape, traj_out.shape, out.shape)\n",
    "#     plt.scatter(traj_inp[0, :, 0], traj_inp[0, :, 1], label='inp')\n",
    "#     plt.scatter(traj_out[0, :, 0].detach(), traj_out[0, :, 1].detach(), label='gt')\n",
    "# #     plt.scatter(traj_inp[1,:,0].detach(), traj_inp[1, :, 1].detach(), label='inp')\n",
    "#     plt.scatter(out[0,:,0].detach(), out[0, :, 1].detach(), label='pred')\n",
    "#     plt.legend()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 149.0938262939453\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 0, Batch: 10, Loss: 162.99925231933594\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 0, Batch: 20, Loss: 162.72589111328125\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 0, Batch: 30, Loss: 86.40250396728516\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 0, Batch: 40, Loss: 163.36776733398438\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 0, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 1, Batch: 0, Loss: 108.8814468383789\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 1, Batch: 10, Loss: 113.47738647460938\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 1, Batch: 20, Loss: 143.75767517089844\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 1, Batch: 30, Loss: 76.092041015625\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 1, Batch: 40, Loss: 161.10287475585938\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 1, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 2, Batch: 0, Loss: 108.92571258544922\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 2, Batch: 10, Loss: 110.6441421508789\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 2, Batch: 20, Loss: 124.61930847167969\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 2, Batch: 30, Loss: 49.81911087036133\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 2, Batch: 40, Loss: 126.02040100097656\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 2, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 3, Batch: 0, Loss: 130.0391845703125\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 3, Batch: 10, Loss: 97.679443359375\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 3, Batch: 20, Loss: 125.2040786743164\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 3, Batch: 30, Loss: 41.302589416503906\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 3, Batch: 40, Loss: 113.1425552368164\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 3, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 4, Batch: 0, Loss: 87.25823211669922\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 4, Batch: 10, Loss: 93.82122802734375\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 4, Batch: 20, Loss: 133.51905822753906\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 4, Batch: 30, Loss: 36.981746673583984\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 4, Batch: 40, Loss: 117.41651153564453\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 4, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 5, Batch: 0, Loss: 98.76708221435547\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 5, Batch: 10, Loss: 108.95797729492188\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 5, Batch: 20, Loss: 99.1283950805664\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 5, Batch: 30, Loss: 33.04054641723633\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 5, Batch: 40, Loss: 103.28966522216797\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 5, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 6, Batch: 0, Loss: 67.79696655273438\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 6, Batch: 10, Loss: 79.35184478759766\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 6, Batch: 20, Loss: 88.16638946533203\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 6, Batch: 30, Loss: 30.845582962036133\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 6, Batch: 40, Loss: 89.7157974243164\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 6, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 7, Batch: 0, Loss: 57.747318267822266\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 7, Batch: 10, Loss: 69.23688507080078\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 7, Batch: 20, Loss: 67.05561065673828\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 7, Batch: 30, Loss: 22.829059600830078\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 7, Batch: 40, Loss: 75.66533660888672\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 7, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 8, Batch: 0, Loss: 87.8731918334961\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 8, Batch: 10, Loss: 110.07086944580078\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 8, Batch: 20, Loss: 106.16710662841797\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 8, Batch: 30, Loss: 33.52942657470703\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 8, Batch: 40, Loss: 87.30047607421875\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 8, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 9, Batch: 0, Loss: 55.690643310546875\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 9, Batch: 10, Loss: 72.13482666015625\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 9, Batch: 20, Loss: 70.56424713134766\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 9, Batch: 30, Loss: 24.841020584106445\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 9, Batch: 40, Loss: 77.82945251464844\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 9, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 10, Batch: 0, Loss: 47.94681167602539\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 10, Batch: 10, Loss: 67.55101013183594\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 10, Batch: 20, Loss: 61.10499954223633\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 10, Batch: 30, Loss: 26.803668975830078\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 10, Batch: 40, Loss: 70.91217803955078\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 10, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 11, Batch: 0, Loss: 43.27339172363281\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 11, Batch: 10, Loss: 65.98932647705078\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 11, Batch: 20, Loss: 60.09505081176758\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 11, Batch: 30, Loss: 22.377946853637695\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 11, Batch: 40, Loss: 65.4692153930664\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 11, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 12, Batch: 0, Loss: 68.0152587890625\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 12, Batch: 10, Loss: 85.33218383789062\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 12, Batch: 20, Loss: 62.41593933105469\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 12, Batch: 30, Loss: 31.70049476623535\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 12, Batch: 40, Loss: 62.61918640136719\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 12, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 13, Batch: 0, Loss: 40.433719635009766\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 13, Batch: 10, Loss: 113.72285461425781\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 13, Batch: 20, Loss: 64.2778549194336\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 13, Batch: 30, Loss: 26.008228302001953\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 13, Batch: 40, Loss: 57.861366271972656\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 13, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 14, Batch: 0, Loss: 56.79245376586914\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 14, Batch: 10, Loss: 57.79104232788086\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 14, Batch: 20, Loss: 57.8705940246582\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 14, Batch: 30, Loss: 14.321098327636719\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 14, Batch: 40, Loss: 57.645912170410156\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 14, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 15, Batch: 0, Loss: 44.30263900756836\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 15, Batch: 10, Loss: 133.32998657226562\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 15, Batch: 20, Loss: 43.288509368896484\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 15, Batch: 30, Loss: 32.89712142944336\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 15, Batch: 40, Loss: 50.641422271728516\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 15, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 16, Batch: 0, Loss: 60.198490142822266\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 16, Batch: 10, Loss: 88.65084838867188\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 16, Batch: 20, Loss: 41.392303466796875\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 16, Batch: 30, Loss: 15.644883155822754\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 16, Batch: 40, Loss: 39.839725494384766\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 16, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 17, Batch: 0, Loss: 46.24445343017578\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 17, Batch: 10, Loss: 73.8055419921875\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 17, Batch: 20, Loss: 77.57654571533203\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 17, Batch: 30, Loss: 17.695960998535156\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 17, Batch: 40, Loss: 58.38371658325195\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 17, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 18, Batch: 0, Loss: 57.93772888183594\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 18, Batch: 10, Loss: 48.969268798828125\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 18, Batch: 20, Loss: 32.6384162902832\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 18, Batch: 30, Loss: 13.009690284729004\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 18, Batch: 40, Loss: 52.42506408691406\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 18, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 19, Batch: 0, Loss: 69.46736145019531\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 19, Batch: 10, Loss: 153.78883361816406\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 19, Batch: 20, Loss: 32.69575881958008\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 19, Batch: 30, Loss: 12.902286529541016\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 19, Batch: 40, Loss: 37.48344039916992\n",
      "ADE: nan FDE: nan\n",
      "Epoch: 19, Mean Loss: nan\n",
      "Mean ADE: nan Mean FDE: nan\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_train_loss = []\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    mean_ade = []\n",
    "    mean_fde = []    \n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        traj_inp, traj_out, fixed_params, var_inp = data\n",
    "        traj_inp = traj_inp.to(device)\n",
    "        traj_out = traj_out.to(device)\n",
    "        fixed_params = fixed_params.to(device)\n",
    "        var_inp = var_inp.to(device)\n",
    "\n",
    "        ade = []\n",
    "        fde = []\n",
    "        out = model(traj_inp, fixed_params, var_inp)\n",
    "        loss = criterion(out, traj_out)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         train_loss.append(loss.item())\n",
    "#         for ii in range(traj_inp.size()[0]):\n",
    "#             gt = [[out[ii][j],out[ii][j + num]] for j in range(len(out[ii])//2)]\n",
    "#             print(out[ii][0])\n",
    "#             pred = [[traj_out[ii][j],traj_out[ii][j + num]] for j in range(len(out[ii])//2)]\n",
    "#             ade.append(get_ade(np.array(traj_out[ii].detach()), np.array(out[ii].detach())))\n",
    "#             fde.append(get_fde(np.array(traj_out[ii].detach()), np.array(out[ii].detach())))\n",
    "#             ade.append(get_ade(np.array(pred), np.array(gt)))\n",
    "#             fde.append(get_fde(np.array(pred), np.array(gt)))\n",
    "#             plot_traj(ii, traj_inp[ii], traj_out[ii], out[ii], {\"x\": [], \"y\": []}, offsets=offsets_train, cities = [], avm=None, center=include_centerline, inp_len=t_obs * 2, c_len = t_obs * 2 + num_elems * 2, num=num, mode=\"test\", batch_num=batch_num)\n",
    "        if batch_num % 10 == 0:\n",
    "            print(\"Epoch: {}, Batch: {}, Loss: {}\".format(epoch, batch_num, loss.item()))\n",
    "            print(\"ADE: {}\".format(np.mean(ade)), \"FDE: {}\".format(np.mean(fde)))\n",
    "    \n",
    "        mean_ade.append(np.mean(ade))\n",
    "        mean_fde.append(np.mean(fde))\n",
    "\n",
    "    mean_loss = np.mean(train_loss)\n",
    "    epoch_train_loss.append(mean_loss)\n",
    "    torch.save(model.state_dict(), \"./checkpoints/{}.ckpt\".format(name))\n",
    "    print(\"Epoch: {}, Mean Loss: {}\".format(epoch, mean_loss))\n",
    "    print(\"Mean ADE: {}\".format(np.mean(mean_ade)), \"Mean FDE: {}\".format(np.mean(mean_fde)))\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Loss: 47.1984977722168\n",
      "Batch: 1, Loss: 43.3056526184082\n",
      "Batch: 2, Loss: 47.52375793457031\n",
      "Batch: 3, Loss: 58.620155334472656\n",
      "Batch: 4, Loss: 62.96497344970703\n",
      "Batch: 5, Loss: 61.43911361694336\n",
      "Batch: 6, Loss: 76.13151550292969\n",
      "Batch: 7, Loss: 72.55301666259766\n",
      "Batch: 8, Loss: 62.78532409667969\n",
      "Batch: 9, Loss: 55.19141387939453\n",
      "Epoch Mean Test Loss: 58.77134208679199\n",
      "Mean ADE: nan Mean FDE: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    cnt = 0\n",
    "    test_loss = []\n",
    "    mean_ade = []\n",
    "    mean_fde = []     \n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        traj_inp, traj_out, fixed_params, var_inp = data\n",
    "        traj_inp = traj_inp.to(device)\n",
    "        traj_out = traj_out.to(device)\n",
    "        fixed_params = fixed_params.to(device)\n",
    "        var_inp = var_inp.to(device)\n",
    "        \n",
    "        ade = []\n",
    "        fde = []        \n",
    "        \n",
    "        out = model(traj_inp, fixed_params, var_inp)\n",
    "        loss = criterion(out, traj_out)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        print(\"Batch: {}, Loss: {}\".format(batch_num, loss.item()))\n",
    "        \n",
    "#         for ii in range(traj_inp.size()[0]):\n",
    "#             gt = [[out[ii][j],out[ii][j + num]] for j in range(len(out[ii])//2)]\n",
    "#             pred = [[traj_out[ii][j],traj_out[ii][j + num]] for j in range(len(out[ii])//2)]\n",
    "#             ade.append(get_ade(np.array(pred), np.array(gt)))\n",
    "#             fde.append(get_fde(np.array(pred), np.array(gt)))                        \n",
    "#             plot_traj(ii, traj_inp[ii], traj_out[ii], out[ii], {\"x\": [], \"y\": []}, offsets=offsets_train, cities = [], avm=None, center=include_centerline, inp_len=num * 2, c_len = num * 2 + num_elems * 2, num=num, mode=\"test\", batch_num=batch_num)\n",
    "\n",
    "        mean_ade.append(np.mean(ade))\n",
    "        mean_fde.append(np.mean(fde))  \n",
    "\n",
    "mean_loss = np.mean(test_loss)\n",
    "print(\"Epoch Mean Test Loss: {}\".format(mean_loss))\n",
    "print(\"Mean ADE: {}\".format(np.mean(mean_ade)), \"Mean FDE: {}\".format(np.mean(mean_fde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_traj(cnt, traj_inp, traj_out, traj_pred, obs, batch_num=0, num = 30, offsets = [], cities = [], avm = None, center = True, mode = \"train\", inp_len=40, c_len=70):\n",
    "    traj_inp = traj_inp.numpy()\n",
    "    traj_out = traj_out.numpy()\n",
    "    traj_pred = traj_pred.detach().numpy()\n",
    "    \n",
    "    lane_centerlines = []\n",
    "    ind = batch_num * 20 + cnt\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    # Get lane centerlines which lie within the range of trajectories\n",
    "    ox = offsets[ind][0] + 2\n",
    "    oy = offsets[ind][1] + 2\n",
    "    ox = 0\n",
    "    oy = 0\n",
    "    if avm is not None:\n",
    "        city = cities[ind]\n",
    "        ox = offsets[ind][0] + 2\n",
    "        oy = offsets[ind][1] + 2\n",
    "        x_max = np.max(np.concatenate((traj_inp[:inp_len:2], traj_out[:num], traj_pred[:num]), axis=0)) + ox\n",
    "        x_min = np.min(np.concatenate((traj_inp[:inp_len:2], traj_out[:num], traj_pred[:num]), axis=0)) + ox\n",
    "        y_max = np.max(np.concatenate((traj_inp[1:inp_len:2], traj_out[num:], traj_pred[num:]), axis=0)) + oy\n",
    "        y_min = np.min(np.concatenate((traj_inp[1:inp_len:2], traj_out[num:], traj_pred[num:]), axis=0)) + oy\n",
    "        \n",
    "        seq_lane_props = avm.city_lane_centerlines_dict[city]\n",
    "        for lane_id, lane_props in seq_lane_props.items():\n",
    "            lane_cl = lane_props.centerline\n",
    "\n",
    "            if (np.min(lane_cl[:, 0]) < x_max and np.min(lane_cl[:, 1]) < y_max and np.max(lane_cl[:, 0]) > x_min and np.max(lane_cl[:, 1]) > y_min):\n",
    "                lane_centerlines.append(lane_cl)\n",
    "\n",
    "        for lane_cl in lane_centerlines:\n",
    "            if True:\n",
    "                ax.plot(lane_cl[:, 0], lane_cl[:, 1], \"--\", color=\"grey\", alpha=1, linewidth=1, zorder=0)\n",
    "\n",
    "    ax.scatter(traj_inp[:inp_len:2] + ox, traj_inp[1:inp_len:2] + oy, color='blue', label='Inp traj')\n",
    "    ax.scatter(traj_out[:num] + ox, traj_out[num:] + oy, color='orange', label='GT')\n",
    "    ax.scatter(traj_pred[:num] + ox, traj_pred[num:] + oy, color='green', label='Pred')\n",
    "\n",
    "    if center:\n",
    "        ax.plot(traj_inp[inp_len:c_len:2] + ox , traj_inp[inp_len + 1:c_len:2] + oy, color='black',label='primary-centerline')\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.axis('equal')\n",
    "    if mode == \"train\":\n",
    "        plt.savefig('./results/{}.png'.format(cnt))\n",
    "    else:\n",
    "        plt.savefig('./results/{}.png'.format(batch_num * 20 + cnt))\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
